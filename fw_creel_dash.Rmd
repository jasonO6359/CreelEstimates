---
title: "FW Creel Point Estimate"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    source_code: embed
    theme:
      version: 4
      bootswatch: default
      bg: "#D0D0D0"
      fg: "#000000"
      navbar-bg: "#1189D9"
      primary: "#1189D9"
runtime: shiny
---

```{r setup, include=FALSE}
#bslib::bs_themer()

library("flexdashboard")
library("tidyverse")
library("shiny")
library("patchwork")
library("gt")

#base endpoints
dwg_base <- list(
  event = "https://data.wa.gov/resource/ui95-axtn.csv",
  effort = "https://data.wa.gov/resource/h9a6-g38s.csv",
  interview = "https://data.wa.gov/resource/rpax-ahqm.csv",
  catch = "https://data.wa.gov/resource/6y4e-8ftk.csv",
  gear = "https://data.wa.gov/resource/d2ks-afhz.csv" #currently unused?
)

#water_body options by proj_name options
#ideally this would be defined directly from a query against strings in the db
proj_levels <- list(
  `R5 Steelhead` = list("Kalama River"),
  `District 13` = list("Skykomish River", "Tokul Creek"),
  `District 14` = list("Cascade River", "Sauk River", "Skagit River")
)

#lookup objects created in build_envi chunk below: 
# -dates of holidays
# -river lon/lat (for day length)
# -sections (for aggregating count/interview locations)
# -tie-in expansions
# -closure files
load("fw_creel_dash_envi.RData")

lu_input <- reactiveValues() #focal river_lonlat, sections, census_exp and closures
creel <- reactiveValues() #data queried from DWG as list of tibbles
pe <- reactiveValues() #intermediate objects wrangled from creel list elements
ests <- reactiveValues() #final objects calc'd from pe & creel

```

```{r build_envi, eval=FALSE}
# # likely will need to build out route to load sections/closures etc on the fly?
# # uncomment to rebuild...
# 
# lu <- list()
# 
# lu$dates_holidays_2015_2030 <- read_lines("input_files/dates_holidays_2015_2030.txt") |>
#   as.Date(format="%Y-%m-%d")
# 
# #single tibble
# lu$river_lonlat <- readr::read_csv("input_files/river_locations_master.csv")
# 
# #list of tibbles
# lu$sections <- list.files("input_files", pattern = "sections_", full.names = T) |>
#   set_names() |> map(readr::read_csv)
# names(lu$sections) <- tools::file_path_sans_ext(basename(names(lu$sections))) |> str_remove("sections_")
# 
# #list of tibbles
# lu$census_expansions <- list.files("input_files", pattern = "ti_expansions_", full.names = T) |>
#   set_names() |> map(readr::read_csv)
# names(lu$census_expansions) <- tools::file_path_sans_ext(basename(names(lu$census_expansions))) |> str_remove("ti_expansions_")
# 
# # # #!! snippet to mod to build closure.csvs for other datasets...
# # # #!! change vals in event_date, s and write_csv
# # # #!! file is date-complete over the focal range
# # # #!! with cols per section, elements coded open==T, closed==F
# # expand_grid(
# #   event_date = seq.Date(as.Date("2021-09-16"), as.Date("2021-11-30"), by = "day"),
# #   s = paste0("open_section_", c(1)),
# #   is_open = TRUE
# #   ) |>
# #   pivot_wider(names_from = s, values_from = is_open) |>
# #   write_csv("input_files/closures_district_river_season_species.csv")
# 
# #list of tibbles
# lu$closures_by_section <- list.files("input_files", pattern = "closures_", full.names = T) |>
#   set_names() |> map(readr::read_csv)
# names(lu$closures_by_section) <- tools::file_path_sans_ext(basename(names(lu$closures_by_section))) |> str_remove("closures_")
# 
# #save.image("fw_creel_dash_envi.RData")

```


Sidebar {.sidebar data-width=350}
============================================

### Controls

```{r input_selectors}
selectInput(inputId = 'proj_name', label = 'Project Name', choices = names(proj_levels)
            , selected = "District 13"
            )

selectizeInput(inputId = 'water_body', label = 'Water Body', choices = proj_levels, multiple = TRUE
               , selected = "Skykomish River"
               )

dateRangeInput(inputId = 'dates', label = "Date range"
               , start = "2021-05-29", end = "2021-07-18" 
               )

selectInput(inputId = 'closures', label = 'Closures', choices = names(lu$closures_by_section), multiple = FALSE
            , selected = "d13_skykomish_summer_chin"
            )
selectInput(inputId = 'sections', label = 'Sections', choices = names(lu$sections), multiple = FALSE
            , selected = "d13_skykomish_summer_chin"
            )
selectInput(inputId = 'census_exp', label = 'Census Expansion LU', choices = names(lu$census_expansions), multiple = FALSE
            , selected = "d13_skykomish_summer_chin"
            )


radioButtons(inputId = 'model_period', label = "Model period", choices = c("Week", "Month")
             , selected = "Week"
             )

radioButtons(inputId = 'index_count_types', label = "Index count types", 
             choices = c("Bank/Boat Anglers", "Vehicle/Trailers Only")
             ,selected = c("Vehicle/Trailers Only")
             )

radioButtons(inputId = 'census_expansion', label = "Census expansion method", 
             choices = c("Direct", "Indirect")
             ,selected = c("Direct")
             )

# #can add option to manually upload ...
# fileInput(inputId = 'sections', label = 'Sections LU', accept = ".csv")

```

### Fetch

```{r dwg_fetch}
#fires the requests on button push
actionButton("fetch", label = "Fetch raw data")


# # ##to uncomment for console dev
# lu_input <- list()
# creel <- list()
# input <- list()
# input$proj_name <- "District 13"
# # input$proj_name <- "District 14"
# input$water_body <- c("Skykomish River")
# input$dates <- c(as.Date("2021-05-29", "%Y-%m-%d"), as.Date("2021-07-18", "%Y-%m-%d"))
# # input$water_body <- "Cascade River"
# # input$dates <- c(as.Date("2021-09-16", "%Y-%m-%d"), as.Date("2021-11-30", "%Y-%m-%d"))
# # input$water_body <- c("Skagit River", "Sauk River")
# # input$dates <- c(as.Date("2021-09-01", "%Y-%m-%d"), as.Date("2021-11-01", "%Y-%m-%d"))
# input$model_period <- "Week"
# input$index_count_types <- "Vehicle/Trailers Only" #c("Vehicle Only","Trailers Only")
# input$census_expansion <- "Direct"
# #
# input$sections <- "d13_skykomish_summer_chin"
# input$census_exp <- "d13_skykomish_summer_chin"
# input$closures <- "d13_skykomish_summer_chin"
# # input$sections <- "d14_cascade_fall_salmon"
# # input$census_exp <- "Cascade_Fall_Salmon_2021"
# # input$sections <- "d14_skagit_fall_salmon_PE"
# # input$census_exp <- "Skagit_Fall_Salmon_2021"


#!!this is "event reactive", so should not trigger on fiddling with inputs
#!!but only when "fetch" button is clicked (see last few lines of chunk)
reactive({

  #!!Lon/lat only used in day-length calc?
  #!!anywhere/anywhy that distinct() would be a problem?
  #!!i.e., anyone realistically using this to run ests on widely spaced rivers?
  lu_input$river_lonlat <- dplyr::filter(
    lu$river_lonlat, River %in% input$water_body) |> 
      dplyr::distinct(River, .keep_all = T)
  
  #!!note the current fetch drops/excludes effort and interview rows
  #!!if no section assigned from section LU
  lu_input$sections <- dplyr::select(
      lu$sections[[input$sections]], 
      water_body_desc, location = location_code, section)

  ## fixes angler type in census expansion table for use with vehicle / trailer counts so it joins to TI_expan table
  if(str_detect(input$index_count_types, "Vehicle|Trailer")) {
    lu_input$census_exp <- lu$census_expansions[[input$census_exp]] |> 
      mutate(
        angler_type = if_else(angler_type == "bank", "total", "boat"),
        cen_exp_meth = input$census_expansion
      )
  } else {
    lu_input$census_exp <- lu$census_expansions[[input$census_exp]] |> 
      mutate(cen_exp_meth = input$census_expansion)
  }
  
  lu_input$closures <- lu$closures_by_section[[input$closures]]

  
  creel$event <- paste0(
    dwg_base$event,
    "?$where=project_name in('", input$proj_name, "')",
    " AND water_body in('", paste0(input$water_body, collapse = "','"), "')",
    " AND event_date between '", input$dates[1],
    "T00:00:00' and '", input$dates[2],
    "T00:00:00'&$limit=100000"
    ) |>
    utils::URLencode() |>
    readr::read_csv(show_col_types = F) |>
    dplyr::select(creel_event_id, water_body, event_date, tie_in_indicator)
  
  if(nrow(creel$event) > 0) {
    
    creel$effort <- paste0(
      dwg_base$effort,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::filter(!is.na(count_type)) |> 
      dplyr::select(-created_datetime, -modified_datetime) |> 
      dplyr::left_join(lu_input$sections, by = c("location")) |> 
      dplyr::filter(!is.na(section))

    creel$interview <- paste0(
      dwg_base$interview,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::rename(location = interview_location) |> 
      dplyr::select(
        -created_datetime, -modified_datetime,
        -state_residence, -zip_code) |> 
      dplyr::left_join(lu_input$sections, by = c("location")) |> 
      dplyr::filter(!is.na(section))
    
    creel$catch <- paste0(
      dwg_base$catch,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::select(interview_id, catch_id, species, run, life_stage, fin_mark, fate, fish_count) |> 
      dplyr::mutate(
        life_stage = replace_na(life_stage, "Adult"), # placeholder pending data corrections in fish apps 
        catch_group = paste(species, life_stage, fin_mark, fate, sep = "_") # fish catch groups to estimate catch of 
      )
    
    #this whole chunk depends on button push, so "lazy" against fiddling
    creel$days <- tibble::tibble(
      event_date = seq.Date(input$dates[1], input$dates[2], by = "day"),
      Day = weekdays(event_date),
      DayType = if_else(
        Day == "Saturday" | Day == "Sunday" | Day %in% lu$dates_holidays_2015_2030,
        "Weekend", "Weekday"),
      DayType_num = if_else(str_detect(DayType, "end"),1,0),
      DayL = suncalc::getSunlightTimes(
        date = event_date,
        tz = "America/Los_Angeles",
         lat = lu_input$river_lonlat$Lat,
         lon = lu_input$river_lonlat$Long,
        keep=c("sunrise", "sunset")
        ) |>
        mutate(DayL = as.numeric((sunset + 3600) - (sunrise - 3600))) |>
        pluck("DayL"),
      Week = as.numeric(format(event_date, "%V")),
      Month = as.numeric(format(event_date, "%m")),
      ModelPeriod = input$model_period,
      time_strata = if_else(ModelPeriod == "Month", Month, Week)
      ) |>
      tibble::rowid_to_column(var = "day_index") |>
      dplyr::left_join(lu_input$closures, by = "event_date")
    
    # excluding specified closures, total number of days by section, weekday/end, and time strata for which to generate estimates
    creel$days_total <- creel$days |>
      pivot_longer(
        cols = starts_with("open_section"), 
        names_to = "section", 
        values_to = "is_open") |>
      filter(is_open == TRUE) |> 
      mutate(section = as.numeric(gsub("^.*_", "", section))) |>
      count(time_strata, DayType, section, name = "N_days")
    
    #!!later right_joins to this below drop any "total" rows...
    creel$days_section_angler_type <- creel$days |>
      select(time_strata, event_date, DayType, starts_with("open_section")) |> 
      mutate(
        section = list(unique(lu_input$sections$section)),
        angler_type = list(c("bank", "boat")) 
      ) |> 
      unnest(cols = section) |> 
      unnest(cols = angler_type)
    
    # # #"days_section_angler_type" also separate_rows option...
    # creel$days |>
    #   mutate(time_strata = if_else(ModelPeriod == "Month", Month, Week)) |>
    #   select(time_strata, event_date, DayType, starts_with("open_section")) |>
    #   mutate(
    #     section = paste0(unique(sections$section), collapse = ","),
    #     angler_type = paste0(c("bank", "boat"), collapse = ",") #is total ever actually needed?
    #   ) |>
    #   separate_rows(section,  sep = ",") |> 
    #   separate_rows(angler_type, sep = ",")

  } else {
    creel$effort <- NULL
    creel$interview <- NULL
    creel$catch <- NULL
  }
}) |> 
  bindEvent(input$fetch)
  
```

### Estimate

```{r calc_pe_ests}
actionButton("estimate", label = "Calculate estimates")

#pe <- list()
#ests <- list()

reactive({
  #### pe$effort_census --------------
  #Aggregate census (tie in) effort counts, associating to closest-in-time index count.
  #take the initial effort_census, with all count_sequence == 1,
  #add/overwrite the count_sequence val with that from closest temporal match from inline/anonymous paired counts object
  pe$effort_census <- dplyr::left_join(
    #begin with focal census data
    creel$effort |> 
      dplyr::filter(tie_in_indicator == 1) |>
      dplyr::select(event_date, location, section, tie_in_indicator, count_type, count_quantity)
    ,
    #reassign count_seq from closest index
    dplyr::left_join(
      creel$effort |> dplyr::filter(tie_in_indicator == 1) |> 
        dplyr::distinct(event_date, section, location, tie_in_indicator, effort_start_time, count_sequence),
      creel$effort |> dplyr::filter(tie_in_indicator == 0) |> 
        dplyr::distinct(event_date, section, tie_in_indicator, effort_start_time, count_sequence),
      by = c("event_date", "section"),
      suffix = c("_cen", "_ind")
      ) |>
      dplyr::group_by(event_date, section, location) |>
      dplyr::slice_min(abs(effort_start_time_cen - effort_start_time_ind), n = 1) |>
      dplyr::ungroup() |>
      dplyr::distinct(event_date, section, location, count_sequence = count_sequence_ind)
    ,
    by = c("event_date", "section", "location")
    ) |>
    dplyr::mutate(
      angler_type = dplyr::case_when(
        stringr::word(count_type, 1) %in% c("Bank","bank","Shore") ~ "bank",
        stringr::word(count_type, 1) %in% c("Boat","boat") ~ "boat" #Note "Boats" plural intentionally excluded
      )
    ) |>
    tidyr::drop_na(angler_type) |> 
    dplyr::group_by(event_date, section, tie_in_indicator, count_sequence, angler_type) |>
    dplyr::summarize(count_census = sum(count_quantity), .groups = "drop") |>
    tidyr::drop_na(count_sequence) |> 
    dplyr::arrange(event_date, section, count_sequence)
  
  #### pe$effort_index --------------
  # filters and aggregates over locations within count_seq & section
  # mutate angler_type here creates a later join-by column
  pe$effort_index <- dplyr::filter(
    creel$effort, 
    tie_in_indicator == 0,
    is.na(no_count_reason),
    !is.na(count_type)
    ) |>
    dplyr::group_by(event_date, section, count_sequence, count_type) |>
    dplyr::summarise(count_index = sum(count_quantity), .groups = "drop") |>
    dplyr::mutate(
      angler_type = dplyr::case_when(
        count_type == "Boat Anglers" ~ "boat",
        count_type == "Bank Anglers" ~ "bank",
        count_type == "Trailers Only" ~ "boat",
        count_type == "Vehicle Only" ~ "total"
      )
    ) |> 
    dplyr::arrange(event_date, section, count_sequence)
  
  #### pe$interview --------------
  # #interview data have angler_count, vehicle_count, trailer_count, angler_type and boat_used
  # #disallow NAs in angler_type, fill missing angler_type from boat_used
#!!maintain static angler_hours_total filter?
#!!could/should switch to: dplyr::filter(angler_hours_total >= input$angler_hours_tot_min)  
#!!make sure fishing_end_time logic is working as intended for eg Kalama
  pe$interview <- dplyr::left_join(
    creel$interview, 
    creel$days |> select(event_date, time_strata, DayType), 
    by = "event_date"
    ) |>
    dplyr::mutate(
      dplyr::across(c(vehicle_count, trailer_count), ~replace_na(., 0)),
      trip_status = replace_na(trip_status, "Unknown"),
      
      angler_type = tolower(angler_type),
      angler_type = dplyr::if_else(is.na(angler_type), boat_used, angler_type),
      angler_type = dplyr::case_when( 
        angler_type == "boat" ~ "boat", #pass through
        angler_type == "bank" ~ "bank", #pass through
        angler_type == "Unk" ~ "bank",  #Kalama, others?
        angler_type == "No" ~ "bank",   #value from boat_used
        angler_type == "Yes" ~ "boat"   #value from boat_used
      ),
      angler_type_ind = as.integer(factor(angler_type)),

      fishing_end_time = dplyr::if_else(
        trip_status == "Incomplete" | is.na(fishing_end_time),
        interview_time,
        fishing_end_time),
      angler_hours = round(as.numeric(fishing_end_time - fishing_start_time) / 3600, 5),
      angler_hours_total = angler_count * angler_hours
    ) |>
    dplyr::filter(angler_hours_total >= 0.5) |> 
    #drop a few unused cols for ease of dev
    dplyr::select(-creel_event_id, -water_body, -project_name, -interview_number,
           -crc_area, -fishing_location, -ends_with("_time"),
           -previously_interviewed, -comment_txt, -water_body_desc
    ) |> 
    dplyr::arrange(event_date, time_strata, section, angler_type, location)
  
  #### pe$interview_and_catch --------------
  # join catch data to interview after inferring complete cases (counts or 0s for all catch_groups encountered)
  # note that interview_ids in creel$interview/pe_interview may have no catch and not be in creel$catch
  # so are consequently coded NA for catch_group; final mutate makes explicit
  #!!should already be distinct on interview_id
  #!!currently filtered to angler_hours >= 0.5 (which also renders gratuitous the first drop_na(angler_hours)?)
  #!!so some rows in creel$catch for "short" interviews may be lost in join 
  pe$interview_and_catch <- left_join(
    pe$interview |> drop_na(angler_hours) |> 
      select(event_date, time_strata, DayType, section, interview_id, angler_type, ends_with("_count"), angler_hours, angler_hours_total) 
    ,
    creel$catch |> 
      group_by(interview_id, catch_group) |> 
      summarise(fish_count = sum(fish_count, na.rm = T), .groups = "drop") |> 
      complete(interview_id, catch_group, fill = list(fish_count = 0))
    ,
    by = "interview_id"
    ) |>
    mutate(
      catch_group = replace_na(catch_group, "no encounter data"),
      fish_count = replace_na(fish_count, 0)
    )
  
  #### pe$effort_interviews_final --------------
  # depending on the types of index counts, reach the calc: mean_daily_TI_expan = mean_daily_effort * TI_expan_final
  # when index counts are already bank & boat, matching census counts,
  #   then this involves joining tie-in expanded census counts of anglers by type (per section)
  #   back against daily mean index counts of anglers expanded by day length
  # when index counts are trailers & vehicles,
  #   then this requires first using interviews to estimate anglers_per_vehicle by angler_type total & boat 
  #   then multiplying anglers_per_vehicle against the trailer & vehicle counts in effort_index, releveled to boat/total
  #   to reach daily effort estimates
  #   and then similarly splitting, releveling and rebinding census to boat/total to allow join with effort_index
  #   to reach TI-expanded counts
  #   and THEN generate object with total, boat and derived-bank, including dealing with case of only-bank (e.g., Cascade)
  
  #!!the calc "mean_daily_effort = count_index_mean * DayL" seems to imply count_index_mean is normalized to per-hour
  #!!but it is just the mean per-day over possibly several index counts per section and angler type
  #!!so it is only a per-hour unit if the count_index values being averaged are already per-hour???
  #!!the count_index values being averaged are summed per count_sequence - is the protocol to only count for an hour?

  if(str_detect(input$index_count_types, "Bank|Boat")) {
    # join census (tie in) counts to index counts
    # calculate mean daily effort multipled by bias term (tie in ratio) from census counts
    pe$effort_interviews_final <- left_join(
      #daily_effort_estimates
      left_join(
        #mean over count_seqs per section-day
        pe$effort_index |> 
          dplyr::group_by(event_date, section, angler_type) |>
          dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop")
        ,
        creel$days |> select(event_date, DayL),
        by = "event_date") |>
        mutate(mean_daily_effort = count_index_mean * DayL) |>
        arrange(event_date, section)
      ,
      #census_counts_all: left join effort index counts to census counts and expand by TI
      left_join(
        #summed by event_date, section, tie_in_indicator, count_sequence, angler_type [bank, boat]
        pe$effort_census,
        #summed by event_date, section, count_sequence, count_type [Bank Ang, Boat Ang, Vehic, Trailr] and derived angler_type [bank, boat, total])
        pe$effort_index,
        by = c("event_date", "section", "count_sequence","angler_type")
      ) |>
        mutate(
          count_index = replace_na(count_index, 0),
          TI_expan = count_census / count_index,
          TI_expan = if_else(is.infinite(TI_expan) | is.nan(TI_expan), NA_real_, TI_expan)
        ) |>
        group_by(section, angler_type) |>
        summarise(
          TI_expan_mean = mean(TI_expan, na.rm=TRUE),
          TI_expan_weighted = sum(count_census) / sum(count_index),
          across(
            c(TI_expan_mean, TI_expan_weighted),
            ~if_else(. == 0, 1, .) |> replace_na(1)
          ),
          .groups = "drop"
        ) |>
        left_join(
          lu_input$census_exp |>
            select(cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
          by = c("angler_type", "section")
        ) |>
        mutate(
          #dealing with e.g. Cascade edge case of nothing to join for an angler_type/section
          #should really be addressed in the Prop_Expansion table...
          cen_exp_meth = replace_na(cen_exp_meth, input$census_expansion),
          p_TI = replace_na(p_TI, 1),
          TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
          TI_expan_final = if_else(
            cen_exp_meth == "Direct" | is.na(cen_exp_meth),
            TI_expan_weighted / p_TI,
            TI_expan_indirect)
        )
      ,
      by = c("section", "angler_type")
    ) |>
      mutate(
        TI_expan_final = replace_na(TI_expan_final, 1),
        mean_daily_TI_expan = mean_daily_effort * TI_expan_final
      )  |>
      select(event_date, section, angler_type, mean_daily_TI_expan) |>
      right_join(creel$days_section_angler_type, by = c("event_date", "section", "angler_type")) |>
      #!!maybe drop this second select() if possible to drop right_join itself?
      select(time_strata, event_date, DayType, section, angler_type, everything()) |>
      mutate(creeled = if_else(!is.na(mean_daily_TI_expan) & open_section_1 == TRUE, "Y", "N")) |>
      arrange(event_date)

  } else if(str_detect(input$index_count_types, "Vehicle|Trailer")) {
      #anglers_per_vehicle from day-section totals amount to arith mean of multiple interviews?
      #presumably this blows up if sum(vehicle_count)==0
      pe$angler_data_from_interviews <- bind_rows(
        pe$interview |>
          group_by(event_date, section) |>
          summarize(
            angler_type = "total",
            angler_hours_total = sum(angler_hours_total),
            anglers_per_vehicle = sum(angler_count) / sum(vehicle_count),
            #anglers_per_index_count_from_interview = daily_sum_angler / daily_sum_index_count_from_interview,
            .groups = "drop")
        ,
        pe$interview |>
          filter(angler_type == "boat") |>
          group_by(event_date, section) |>
          summarize(
            angler_type = "boat",
            angler_hours_total = sum(angler_hours_total),
            anglers_per_vehicle = sum(angler_count) / sum(vehicle_count),
            .groups = "drop")
        )

      pe$daily_effort_estimates <- left_join(
          pe$angler_data_from_interviews
          ,
          pe$effort_index |> 
            dplyr::group_by(event_date, section, angler_type) |>
            dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop")
          ,
          by = c("event_date", "section", "angler_type")) |>
        left_join(creel$days |> select(event_date, DayL), by = "event_date") |>
        mutate(mean_daily_effort = anglers_per_vehicle * count_index_mean * DayL) |>
        arrange(event_date, section)

      #join interview-expanded index counts to census
      pe$census_counts_all <- left_join(
        #census already grouped & summed by event_date, section, tie_in_indicator, count_sequence, and angler_type [bank, boat]
        #but here split out boat, collapse and then reassign angler_type to total & boat
        bind_rows(
          pe$effort_census |>
            group_by(event_date, section, count_sequence) |>
            summarize(count_census = sum(count_census), angler_type = "total", .groups = "drop")
          ,
          pe$effort_census |>
            filter(angler_type == "boat") |>
            group_by(event_date, section, count_sequence) |>
            summarize(count_census = sum(count_census), angler_type = "boat", .groups = "drop")
          )
        ,
        #index via interviews with angler_type [total, boat]
        #using ang/vehicle from interview to expand index counts of vehicles
        #!!most likely an expanding join since interview is already per day-section here
        #!!but effort_index is per count_seq (per day-section)
        #!!so is it correct for this to be left_ rather than full/inner?
        left_join(
          pe$angler_data_from_interviews,
          pe$effort_index,
          by = c("event_date", "section", "angler_type")
        ) |>
          mutate(count_index = anglers_per_vehicle * count_index) |>
          select(event_date, section, count_sequence, angler_type, count_index)
        ,
        by = c("event_date", "section", "count_sequence", "angler_type")
      ) |>
        mutate(
          count_index = replace_na(count_index, 0),
          TI_expan = count_census / count_index,
          TI_expan = if_else(is.infinite(TI_expan) | is.nan(TI_expan), NA_real_, TI_expan)
        ) |>
        group_by(section, angler_type) |>
        summarise(
          TI_expan_mean = mean(TI_expan, na.rm=TRUE),
          TI_expan_weighted = sum(count_census) / sum(count_index),
          across(
            c(TI_expan_mean, TI_expan_weighted),
            ~if_else(. == 0, 1, .) |> replace_na(1)
          ),
          .groups = "drop"
        ) |>
        left_join(
          lu_input$census_exp |>
            select(cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
          by = c("angler_type", "section")
        ) |>
        mutate(
          #dealing with e.g. Cascade edge case of nothing to join for an angler_type/section
          #should really be addressed in the Prop_Expansion table...
          cen_exp_meth = replace_na(cen_exp_meth, input$census_expansion),
          p_TI = replace_na(p_TI, 1),
          TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
          TI_expan_final = if_else(
            cen_exp_meth == "Direct" | is.na(cen_exp_meth),
            TI_expan_weighted / p_TI,
            TI_expan_indirect)
        )

      # join census (tie in) counts to index counts
      # calculate mean daily effort multipled by bias term (tie in ratio) from census counts
      #!!aiming for event_date, angler_type [total, boat, bank (as total-boat)]
      #!!Fails for Cascade - no "boat" in daily_effort_estimates (since no boat angler_type in pe_interview)
      #!!so left_join of census_counts_all provides no "boat" rows
      #!!so pivot wider produces no "boat" col, so mutate cannot find
      #!!however "total - boat" seems potentially troublesome even when both present
      #!!negatives, zeros, near-zero, etc
      #!!is "total" really needed/used?
      #!!   not present for a non-trailer/vehicle index case
      #!!   and just creates additional level that could be dropped against days_section_angler_type obj?
      pe$effort_interviews_prelim <- left_join(
        pe$daily_effort_estimates |> select(event_date, section, angler_type, mean_daily_effort),
        pe$census_counts_all |> select(section, angler_type, TI_expan_final),
        by = c("section", "angler_type")
        ) |>
        mutate(mean_daily_TI_expan = mean_daily_effort * TI_expan_final)

      if(any(pe$interview$angler_type=="boat")) {
        pe$effort_interviews_final <- bind_rows(
          #total and boat
          pe$effort_interviews_prelim |>
            select(event_date, section, angler_type, mean_daily_TI_expan),
          #derived bank
          pe$effort_interviews_prelim |>
            select(event_date, section, angler_type, mean_daily_TI_expan) |>
            pivot_wider(names_from = angler_type, values_from = mean_daily_TI_expan, values_fill = 0) |>
            mutate(
              angler_type = "bank",
              mean_daily_TI_expan = total - boat,
              total = NULL, boat = NULL)
        )
      } else { #only angler_type == "total", coerce "boat" to 0 and total to "bank"
        pe$effort_interviews_final <- bind_rows(
          pe$effort_interviews_prelim |>
            select(event_date, section, angler_type, mean_daily_TI_expan),
          pe$effort_interviews_prelim |>
            select(event_date, section) |>
            mutate(angler_type = "boat", mean_daily_TI_expan = 0),
          pe$effort_interviews_prelim |>
            select(event_date, section, mean_daily_TI_expan) |>
            mutate(angler_type = "bank")
        )
      }
      
      pe$effort_interviews_final <- pe$effort_interviews_final |>
        right_join(creel$days_section_angler_type, by = c("section", "event_date", "angler_type")) |>
        mutate(creeled = if_else(!is.na(mean_daily_TI_expan), "Y", "N")) |>
        select(time_strata, event_date, DayType, section, angler_type, everything()) |>
        arrange(event_date)
  }
  
  # add days objects to the table with index count data
  pe$effort_interviews_final <- pe$effort_interviews_final |>
    drop_na(mean_daily_TI_expan) |>
    left_join(creel$days_total, by = c("time_strata", "DayType", "section")) |>
    left_join(
      # number of days sampled within monitoring period
      pe$effort_interviews_final |>
        filter(!is.na(mean_daily_TI_expan) & creeled == "Y") |>
        count(time_strata, DayType, section, angler_type, name = "n_days"),
      by = c("time_strata", "DayType", "section", "angler_type")) |>
    left_join(
      creel$days_total |>
        group_by(section, DayType) |>
        summarise(N_days_total = sum(N_days), .groups = "drop"),
      by = c("DayType", "section")) |>
    left_join(
      # summarized over time_strata number of days sampled within monitoring period
      pe$effort_interviews_final |>
        filter(!is.na(mean_daily_TI_expan) & creeled == "Y") |>
        count(time_strata, DayType, section, angler_type, name = "n_days") |>
        group_by(section, DayType, angler_type) |>
        summarise(n_days_total = sum(n_days), .groups = "drop"),
      by = c("DayType", "section", "angler_type"))

  pe$effort_interviews_final_strata_mean <- pe$effort_interviews_final |>
    #!!Not including DayType in group_by?
    group_by(time_strata, section, angler_type) |>
    mutate(mean_strata_effort = mean(mean_daily_TI_expan)) |>
    ungroup() |>
    #!!is this complete actually necessary??
    complete(time_strata, section, angler_type, fill = list(mean_strata_effort = 0)) |>
    mutate(
      mean_daily_TI_expan = if_else(
        mean_daily_TI_expan == 0,
        mean_strata_effort,
        mean_daily_TI_expan
      )) |>
    select(time_strata, event_date, DayType, section, angler_type, everything())

  #### reaching dailyCPUE object ------------------------
  # #previously built "angler_hours_summary" object
  # #was mean angler hours by complete strata:  time_strata, DayType, section, angler_type, catch_group
  # #meant for use in "case of non-zero catch but no angler hours to use to calculate CPUE (should be a rare situation)"
  # #e.g.: interview_and_catch |> filter(fish_count>0) |> filter(angler_hours_total<0.5)
  # #but only left_joined back to interview_and_catch
  # #so complete cases unnecessary (since lost in join)
  # #NOW JUST PER_GROUP MUTATING ON to avoid intermediate creation and rejoin
  # angler_hours_strata_mean <- interview_and_catch |>
  #   group_by(time_strata, DayType, section, angler_type, catch_group) |>
  #   summarise(angler_hours_strata_mean = mean(angler_hours_total), .groups = "drop") |>
  #   complete(
  #     time_strata, DayType, section, angler_type, catch_group,
  #     fill = list(angler_hours_strata_mean = 0)
  #     )
  #
  # angler_hours_strata_mean |> filter(angler_hours_strata_mean==0)
  # interview_and_catch |> filter(time_strata==38, DayType=="Weekend", section==1, angler_type=="bank", catch_group=="Bull Trout_Adult_NA_Released")
  #
  # # interview_daily_totals <- left_join(
  # #   interview_and_catch,
  # #   angler_hours_summary,
  # #   by = c("time_strata", "DayType", "section", "angler_type", "catch_group")
  # #   ) |>


  #first add strata mean vals in case of 0 angler_hours_total on a day with non-zero fish_count
  #!!may need to add logic to avoid NaN if below if_else evals false AND any angler_hours_strata_mean==0?
  #next aggregate interviews per day per strata of [week/month-weekend/day-section-bank/boat-catch_group]
  #!!DA: the cpue_rom here is a ratio of sums - are we calling that equivalent to "ratio of the means"?
  pe$interview_daily_totals <- pe$interview_and_catch |>
    group_by(time_strata, DayType, section, angler_type, catch_group) |>
    mutate(
      angler_hours_strata_mean = mean(angler_hours_total),
      cpue_interview = if_else(
        angler_hours_total > 0,
        fish_count / angler_hours_total, #angler_count * angler_hours
        fish_count / angler_hours_strata_mean)
    ) |>
    group_by(time_strata, event_date, DayType, section, angler_type, catch_group) |>
    summarise(
      n_groups = n(),
      catch_daily = sum(fish_count),
      angler_hours_total_daily = sum(angler_hours_total),
      cpue_rom_daily = catch_daily / angler_hours_total_daily, # ratio of the means CPUE estimator
      cpue_mor_daily = mean(cpue_interview),  # mean of ratios CPUE estimator
      .groups = "drop"
    )

  # #calculate mean CPUE values by strata to use on days with known effort but a lack of interviews
  # #further aggregates over per-day obs within a [week/month, weekend/day, bank/boat, catch_group]
  # # cpue_mor_strata_mean is the mean over "daily_totals" obs which are over interview_id per day-otherstrata
  # #the complete() here generates strata levels (assigned 0) not present in interview/catch data
  # #Fisheries Techniques (Jones and Pollock 2012) suggest MOR for roving survey design
  # cpue_strata_mean <- interview_daily_totals |>
  #   group_by(time_strata, DayType, section, angler_type, catch_group) |>
  #   summarise(
  #     cpue_rom_strata_mean = mean(cpue_rom_daily),
  #     cpue_mor_strata_mean = mean(cpue_mor_daily),
  #     .groups = "drop"
  #   ) |>
  #   complete(
  #     time_strata, DayType, section, angler_type, catch_group,
  #     fill = list(cpue_mor_strata_mean = 0, cpue_rom_strata_mean = 0)
  #     )
  #
  #
  # #add implicit missing values of CPUE to dataset using tidyr complete() function
  # interview_daily_totals_complete <- interview_daily_totals |>
  #   complete(event_date, section, angler_type, catch_group,
  #            fill = list(catch_daily = 0)) |>
  #   select(time_strata, event_date, DayType, section, angler_type, catch_group, everything())
  # #but this creates NAs for the other cpue cols besides catch_daily[sum]...
  # #including time_strata in select() creates rows of NA time_strata since not included in complete()
  # #was previously selecting off un-completed cols and then later rejoining creel$days and rebuilding time_strata
  # interview_daily_totals_complete |> summary()
  #
  # #!!DA not sure exactly what is intended/desired here...
  # #!!preferable to do something like a distinct?
  # #!!or just use the rejoin of creel$days to get time_strata & DayType?
  # interview_and_catch |>
  #   distinct(event_date, section, angler_type, catch_group) |>
  #   complete(event_date, section, angler_type, catch_group)
  #
  # #!!and/but/so this currently carries forward the NAs left in interview_daily_totals_complete
  # # join mean_strata_cpue values to table with daily cpue values so we can use the mean strata cpue values on days with known effort but no corresponding interview
  # daily_CPUE <- left_join(
  #   interview_daily_totals_complete,
  #   cpue_strata_mean,
  #   by = c("time_strata", "DayType", "section", "angler_type", "catch_group")
  #   )

  #!!DA pending conversation with EB
  #rather than dailyCPUE as interview_daily_totals >>> interview_daily_totals_complete >>> left_join( interview_daily_totals >>> cpue_summary)
  #just mutate on the fields in cpue_strata_mean
  #and come back to figure out need for complete()
  pe$daily_CPUE <- pe$interview_daily_totals |>
    group_by(time_strata, DayType, section, angler_type, catch_group) |>
    mutate(
      cpue_rom_strata_mean = mean(cpue_rom_daily),
      cpue_mor_strata_mean = mean(cpue_mor_daily)
    ) |>
    ungroup()


  #### ests ingredients -------------
  #!! these first 3 objects are ingredients for subsequent effort and catch summary objects

  pe$daily_effort_cpue_catch <- left_join(
    pe$daily_CPUE,
    pe$effort_interviews_final_strata_mean,
    by = c("time_strata", "event_date", "DayType", "section", "angler_type")
  ) |>
    #!!DA drop both of these?
    mutate(angler_hours_total_daily = replace_na(angler_hours_total_daily, 0)) |>
    filter(angler_type %in% c("bank","boat")) |>
    mutate(
      #!!DA bad test? when would cpue_mor_daily eval NA? I've gotten rid of days/levels from a complete or join somewhere?
      catch_estimate = if_else(
        !is.na(cpue_mor_daily),
        mean_daily_TI_expan * cpue_mor_daily,
        mean_daily_TI_expan * cpue_mor_strata_mean
      ),
      # catch_estimate = if_else(catch_dailysum > 0 & mean_daily_TI_expan == 0, cpue_mor * mean_strata_effort, catch_estimate) # circle bacl to this, issue is days with non-zero catch by no effort
      # catch_estimate_rom = if_else(!is.na(cpue_rom), mean_daily_TI_expan * cpue_rom, mean_daily_TI_expan * mean_strata_cpue_rom), # option to use ratio of the means CPUE estimator
      # catch_estimate = catch_estimate_mor
      across(where(is.numeric), round, 2)
    ) |>
    #!!DA YIKES!?!?
    #!!seems either unnecessary or needs better specification of fields?
    distinct() |>
    # filter(!is.na(mean_daily_TI_expan)) |>
    arrange(catch_group, section, event_date, angler_type)


  # create table with degrees of freedom by section and angler type to apply to time strata estimates
  pe$degrees_freedom <- pe$daily_effort_cpue_catch |>
    distinct(section, angler_type, time_strata, n_days) |>
    group_by(section, angler_type) |>
    summarize(
      min_n_days = min(n_days),
      sum_n_days = sum(n_days),
      degrees_freedom = min_n_days + sum_n_days / 2,
      .groups = "drop"
    )

  #used in final set of objects, could move into pe or make inline?
  ests$degrees_freedom_total <- pe$effort_interviews_final |>
    distinct(section, angler_type, n_days = n_days_total) |>
    group_by(section, angler_type) |>
    summarize(
      min_n_days = min(n_days),
      sum_n_days = sum(n_days),
      degrees_freedom = min_n_days + sum_n_days / 2,
      .groups = "drop"
    )

  # dates object to join back to summary objects to plotting
  #!!takes first day per week per month
  #!!not sure if/how it matters but
  #!!this distinct() associates in month-spanning weeks to the earlier month
  #!!e.g., in 2021 week 39 in both Sep and Oct, gets only to Sep
  #!!also not sure how the col rename will play with a reactive input list...
  pe$days_join_2 <- creel$days |>
    dplyr::group_by(Month, Week) |>
    dplyr::slice(1) |>
    dplyr::ungroup() |>
    dplyr::distinct(Week, .keep_all = TRUE) |>
    dplyr::select(-Week, -Month)

  #### effort summaries  --------------

  #!!how was distinct() meant to play with still-grouped summarize output?
  # calculate effort by day type and angler type strata
  ests$time_strata_effort_by_daytype <- pe$daily_effort_cpue_catch |>
    group_by(section, angler_type, time_strata, DayType, n_days, N_days) |>
    summarize(
      n = n(),
      sum_daily_effort_sampled_days = sum(mean_daily_TI_expan),
      mean_daily_effort = mean(mean_daily_TI_expan),
      variance_daily_effort = var(mean_daily_TI_expan),
      total_effort = mean_daily_effort * N_days,
      variance_total_daily_effort = if_else(
        n_days < N_days,
        (N_days^2) * (variance_daily_effort / n_days) * (1-(n_days/N_days)),
        (N_days^2) * (variance_daily_effort / n_days)
      ),
#!!THIS MAY BE WRONG but need to explicitly specify .groups if otherwise
      .groups = "keep"
    ) |>
    distinct()

  #!!Not sure about left_join on still-grouped summarize output? i.e., with just time_strata dropped?
  #!!the col named "SE" is standard deviation not standard error
  #!!not sure which is desired? if sd, could also use sd()?
  #!!moved filter() up; confirm relative to left_join of degfreedom?
  # Sum effort estimates across day types, retain grouping on angler type
  ests$time_strata_effort_total <- ests$time_strata_effort_by_daytype |>
    filter(angler_type %in% c("bank","boat")) |>
    group_by(section, angler_type, time_strata) |>
    summarise(
      total_effort = sum(total_effort),
      variance = sum(variance_total_daily_effort),
#!!THIS MAY BE WRONG but need to explicitly specify .groups if otherwise
      .groups = "keep"
    ) |>
    left_join(pe$degrees_freedom, by = c("section", "angler_type")) |>
    mutate(
      variance = replace_na(variance,0),
      SE = sqrt(variance),
      CV = SE / total_effort,
      lwr95CI = total_effort - qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
      upr95CI = total_effort + qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
      across(where(is.numeric), round, 2)
    ) |>
    distinct(time_strata, angler_type, .keep_all = TRUE)|>
    left_join(pe$days_join_2, by = "time_strata")

  #!!this gets overwritten below...?
  #!!may be able to drop ungroup if dealt with earlier?
  ests$total_effort <- ungroup(ests$time_strata_effort_total) |>
    summarize(total_effort = sum(total_effort, na.rm = T))

  #### catch summaries  --------------

  #!!as above, concern/questions about (double) distinct()
  #!!and this exits the pipe still grouped...
  # calculate catch by day type and angler type strata
  ests$time_strata_catch_by_daytype <- pe$daily_effort_cpue_catch |>
    filter(!is.na(catch_estimate)) |>
    group_by(section, angler_type, catch_group, time_strata, DayType, n_days, N_days) |>
    summarize(
      total_catch_unexpanded = sum(catch_estimate),
      mean_daily_catch = total_catch_unexpanded / n_days,
      total_catch_expanded_2 = total_catch_unexpanded * N_days,
      total_catch_expanded = mean_daily_catch * N_days,
      variance_catch_estimate = var(catch_estimate),
      n_days = mean(n_days),
      N_days = mean(N_days),
#!!THIS MAY BE WRONG but need to explicitly specify .groups if otherwise
#!!What is going on with the double distinct()??
      .groups = "keep"
      ) |>
    distinct() |>
    mutate(
      variance_catch_estimate = replace_na(variance_catch_estimate, 0),
      variance_total_catch_expanded = if_else(
        n_days < N_days,
        (N_days^2) * (variance_catch_estimate / n_days) * (1-(n_days/N_days)),
        (N_days^2) * (variance_catch_estimate / n_days))
    ) |>
    distinct()

  # cannot calculate variance for estimates when n = 1 for daytype strata within a week
  # Sum catch estimates across day types, retain grouping on angler type
  ests$time_strata_catch_total <- ests$time_strata_catch_by_daytype |>
    filter(angler_type %in% c("bank", "boat")) |>
    group_by(section, time_strata, catch_group, angler_type) |>
    summarise(
      total_catch = sum(total_catch_expanded),
      variance = sum(variance_total_catch_expanded),
#!!THIS MAY BE WRONG but need to explicitly specify .groups if otherwise
      .groups = "keep"
    ) |>
    left_join(pe$degrees_freedom, by = c("section", "angler_type")) |>
    mutate(
      variance = replace_na(variance, 0),
      SE = sqrt(variance),
      CV = SE / total_catch,
      lwr95CI = total_catch - qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
      upr95CI = total_catch + qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
      across(where(is.numeric), round, 2)
    ) |>
    distinct() |>
    arrange(section, catch_group, time_strata) |>
    left_join(pe$days_join_2, by = "time_strata")

  #!!as above for ests$total_effort, currently getting overwritten below
  ests$total_catch <- ests$time_strata_catch_total |>
    group_by(section, catch_group) |>
    summarize(total_catch = sum(total_catch), .groups = "drop")

  #### totals -------

  #!!from unnamed chunk L1540
  #!!DA looks like this may only be for weekly? at least the first mutate seems wrong for monthly strata?
  # EB circle back to this for calculating CPUE / HPUE and associated uncertainty over time period of interest
  ests$cpue_time_strata <- dplyr::left_join(
    ests$time_strata_catch_total  |>
      dplyr::select(
        section, time_strata, angler_type, catch_group,
        total_catch, variance, SE, CV, lwr95CI, upr95CI
      ) |>
      mutate(daily_catch_estimate = total_catch / 7)
    ,
    ests$time_strata_effort_total |>
      dplyr::select(
        section, time_strata, angler_type,
        total_effort, variance, SE, CV, lwr95CI, upr95CI),
    by = c("section","angler_type","time_strata"),
    suffix = c("_catch", "_effort")
    ) |>
    mutate(
      across(where(is.numeric), round, 2),
      cpue_time_strata = replace_na(total_catch / total_effort, 0),
      cpue_lwr95_time_strata = replace_na(lwr95CI_catch / lwr95CI_effort, 0),
      cpue_upr95_time_strata = replace_na(upr95CI_catch / upr95CI_effort, 0)
    ) |>
#!! really??
    distinct() |>
    left_join(pe$days_join_2, by = "time_strata")

  #!!DA on L1689 assigned to estimates list then (possibly) overwrites the previously created non-list version
  # Adding together time strata specific effort estimates and associated variance and calculating SE, CV, and 95% CI's
  ests$total_effort <- ests$time_strata_effort_total |>
    dplyr::select(-c(min_n_days, sum_n_days, degrees_freedom)) |>
    dplyr::left_join(ests$degrees_freedom_total, by = c("section", "angler_type")) |>
    dplyr::group_by(section, angler_type) |>
    dplyr::summarise(
      total_effort = sum(total_effort),
      variance = sum(variance),
      SE = sqrt(variance),
      CV = SE / total_effort,
      lwr95CI = total_effort - qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
      upr95CI = total_effort + qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
#!!This "drop" may be incorrect depending on the intent of the following distinct()
#!!but if so we should be explicit about the group intent with "keep" or "drop_last"
      .groups = "drop"
    ) |>
    dplyr::distinct() |>
    dplyr::mutate(across(where(is.numeric), round, 2)) |>
    dplyr::arrange(section)

  # Adding together time_strata catch estimates and associated variance and calculating SE, CV, and 95% CI's
  ests$total_catch <- ests$time_strata_catch_total |>
    dplyr::select(-c(min_n_days, sum_n_days, degrees_freedom)) |>
    dplyr::left_join(ests$degrees_freedom_total, by = c("section", "angler_type")) |>
    dplyr::filter(angler_type %in% c("bank", "boat")) |>
    dplyr::mutate(variance = replace_na(variance, 0)) |>
    dplyr::group_by(catch_group, section, angler_type) |>
    dplyr::summarise(
      total_catch = sum(total_catch),
      variance = sum(variance),
      SE = sqrt(variance),
      CV = SE / total_catch,
      lwr95CI = total_catch - qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
      upr95CI = total_catch + qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
#!!As immediately above, this "drop" may be incorrect depending on the intent of the following distinct()
#!!but if so we should be explicit about the group intent with "keep" or "drop_last"
      .groups = "drop"
    ) |>
    dplyr::distinct() |>
    dplyr::mutate(across(where(is.numeric), round, 2)) |>
    dplyr::arrange(section, catch_group)

}) |> 
  bindEvent(input$estimate)
```


Data from DWG
============================================

Event and Days
--------------------------------------------

### Event

```{r gt_creel_event}
render_gt({ 
  if(!is.null(creel$event)) {
    creel$event |> count(water_body, tie_in_indicator) 
    }
  })
```

### Days

```{r gt_creel_days}
render_gt({ 
  if(!is.null(creel$days_total)) {
  creel$days_total |> pivot_wider(names_from = DayType, values_from = N_days)
  }
})
```


Effort
--------------------------------------------

### Effort

```{r gt_creel_effort}
render_gt({ 
  if(!is.null(creel$event)) {
    creel$effort |> count(water_body, section, tie_in_indicator, location)
  }
})
```

Interview
--------------------------------------------

### Interview

```{r gt_creel_interview}
render_gt({ head(creel$interview) })
```

Catch
--------------------------------------------

### Catch

```{r gt_creel_catch}
render_gt({ head(creel$catch) })
```


Effort
============================================

Census
--------------------------------------------

### Census counts

```{r}
#render_gt({ pe$effort_census })

renderPlot({
  if(!is.null(pe$effort_census)) { #creel$effort
    pe$effort_census |>
      ggplot(aes(event_date, count_census, fill = factor(count_sequence))) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + angler_type, scales = "free", labeller = label_wrap_gen(multi_line = F))
  }
})

```

Index
--------------------------------------------

### Index counts

```{r}
renderPlot({
  if(!is.null(pe$effort_index)) { #creel$effort
    pe$effort_index |>
      ggplot(aes(event_date, count_index, fill = factor(count_sequence))) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + count_type + angler_type, scales = "free", labeller = label_wrap_gen(multi_line = F))
  }
})

```

Index daily mean
--------------------------------------------

### Index daily mean

```{r}
# renderPlot({
#   if(!is.null(pe$effort_index_daily_mean)) { #creel$effort
#     pe$effort_index_daily_mean |>
#       ggplot(aes(event_date, count_index_mean, fill = angler_type)) +
#       geom_col(position = position_dodge()) +
#       facet_wrap(~section + angler_type, scales = "free", labeller = label_wrap_gen(multi_line = F))
#   }
# })

```

Interview
============================================

Interview
--------------------------------------------

### Interview

```{r}
renderPlot({
  if(!is.null(pe$interview)) { #creel$interview
    pe$interview |>
      mutate(event_date = format(event_date, "%m-%d")) |> 
      ggplot(aes(event_date, angler_hours_total, fill = angler_type)) +
      geom_boxplot(position = position_dodge(), outlier.shape = NA) +
      geom_jitter(width = 0.5) +
      scale_x_discrete(guide = guide_axis(angle = 90)) +
      facet_wrap(~section + angler_type, scales = "free", labeller = label_wrap_gen(multi_line = F), ncol = 1) 
  }
})

```

Catch
--------------------------------------------

### Catch

```{r}
renderPlot({
  if(!is.null(pe$interview_and_catch)) { #creel$interview
    pe$interview_and_catch |>
      group_by(event_date, time_strata, section, angler_type, catch_group) |> 
      summarise(fish_count = sum(fish_count), .groups = "drop") |> 
      # separate(catch_group, into = c("species", "life_stage", "mark", "fate"), sep = "_", remove = T, fill = "right") |> 
      # pivot_wider(names_from = c(life_stage, mark, fate), values_from = fish_count)
      ggplot(aes(event_date, catch_group, size = fish_count, color = fish_count)) +
      geom_point() +
      scale_size_area() + scale_color_binned() +
      scale_x_date("") + scale_y_discrete("") +
      facet_wrap(~section + angler_type, scales = "fixed", labeller = label_wrap_gen(multi_line = F))
  }
})

```

Estimates
============================================

### total effort
```{r}
# renderValueBox({
#   if(!is.null(ests$total_effort)){
#     valueBox(ests$total_effort |> filter(angler_type == "bank") |> pluck("total_effort") |> round())
#   }
# })

render_gt({
  if(!is.null(ests$total_effort)){
    ests$total_effort
  }
})

```

### total catch
```{r}
render_gt({
  if(!is.null(ests$total_catch)){
    ests$total_catch
  }
})

```

About
============================================

Anything to cite/link to?

WDFW gathers fishing information from anglers around the state: <a href="https://wdfw.wa.gov/fishing/reports/creel"> https://wdfw.wa.gov/fishing/reports/creel</a>
