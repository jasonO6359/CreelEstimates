---
title: "FW Creel Point Estimate"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    source_code: embed
    theme:
      version: 4
      bootswatch: default
      bg: "#D0D0D0"
      fg: "#000000"
      navbar-bg: "#1189D9"
      primary: "#1189D9"
runtime: shiny
---

```{r setup, include=FALSE}
#bslib::bs_themer()

library("flexdashboard")
library("tidyverse")
library("shiny")
library("patchwork")
library("gt")

#base endpoints
dwg_base <- list(
  event = "https://data.wa.gov/resource/ui95-axtn.csv",
  effort = "https://data.wa.gov/resource/h9a6-g38s.csv",
  interview = "https://data.wa.gov/resource/rpax-ahqm.csv",
  catch = "https://data.wa.gov/resource/6y4e-8ftk.csv",
  gear = "https://data.wa.gov/resource/d2ks-afhz.csv" #currently unused?
)

#water_body options by proj_name options
proj_levels <- list(
  `R5 Steelhead` = list("Kalama River"),
  `District 13` = list("Skykomish River", "Tokul Creek"),
  `District 14` = list("Cascade River", "Sauk River", "Skagit River")
)

#lookup objects created below
load("fw_creel_dash_envi.RData")

creel <- reactiveValues() #will hold resulting data objects ##event = NULL, effort = NULL, interview = NULL, catch = NULL

```

```{r build_envi, eval=FALSE}
# # uncomment to rebuild...
# 
# dates_holidays_2015_2030 <- read_lines("input_files/dates_holidays_2015_2030.txt") |>
#   as.Date(format="%Y-%m-%d")
# 
# # river_loc_all <- list.files("input_files", pattern = "River.Location", full.names = T) |>
# #   set_names() |>
# #   map(readr::read_csv)
# river_loc_all <- readr::read_csv("input_files/river_locations_master.csv")
# 
# #excludes "master"; read_csv("input_files/lut_water_body_location_master_2022_01_28.csv") |> distinct(water_body_desc)
# sections_all <- list.files("input_files", pattern = "lut_water_body_location_", full.names = T)[-8] |>
#   set_names() |>
#   map(readr::read_csv)
# 
# census_expansion_all <- list.files("input_files", pattern = "Proportional", full.names = T) |>
#   set_names() |>
#   map(readr::read_csv)
# 
# #names(river_loc_all) <- tools::file_path_sans_ext(basename(names(river_loc_all)))
# names(sections_all) <- tools::file_path_sans_ext(basename(names(sections_all))) #|> str_remove("lut_water_body_location_")
# names(census_expansion_all) <- tools::file_path_sans_ext(basename(names(census_expansion_all))) #|> str_remove("lut_Proportional_Expansions_for_Tie_In_")
# 
# #save.image("fw_creel_dash_envi.RData")

```


Controls {.sidebar data-width=350}
============================================

### knobs

```{r input_selectors}
selectInput(inputId = 'proj_name', label = 'Project Name', choices = names(proj_levels)
            , selected = "District 14"
            )

selectizeInput(inputId = 'water_body', label = 'Water Body', choices = proj_levels, multiple = TRUE
               , selected = "Cascade River"
               )

dateRangeInput(inputId = 'dates', label = "Date range"
               , start = "2021-09-16", end = "2021-10-16" 
               )


selectInput(inputId = 'sections', label = 'Sections', choices = names(sections_all), multiple = FALSE
            , selected = "lut_water_body_location_d14_cascade_fall_salmon"
            )
# selectInput(inputId = 'river_loc', label = 'River Lat/Lon', choices = names(river_loc_all), multiple = FALSE
#             , selected = "lut_River.Locations_2019-01-07"
#             )
selectInput(inputId = 'census_exp', label = 'Census Expansion LU', choices = names(census_expansion_all), multiple = FALSE
            , selected = "lut_Proportional_Expansions_for_Tie_In_Sections_Cascade_Fall_Salmon_2021"
            )


radioButtons(inputId = 'model_period', label = "Model period", choices = c("Week", "Month")
             , selected = "Week"
             )

radioButtons(inputId = 'index_count_types', label = "Index count types", 
             choices = c("Bank/Boat Anglers", "Vehicle/Trailers Only")
             ,selected = c("Vehicle/Trailers Only")
             )

radioButtons(inputId = 'census_expansion', label = "Census expansion method", 
             choices = c("Direct", "Indirect")
             ,selected = c("Direct")
             )

# #can add option to manually upload ...
# fileInput(inputId = 'sections', label = 'Sections LU', accept = ".csv")

```

### fetch

```{r dwg_fetch}
actionButton("fetch", label = "Fetch raw data")

#fire the requests on button push
#!! note this excludes effort and interview rows
#!! with no section assigned from section LU

# creel <- list()
# input <- list()
# input$proj_name <- "District 14"
# # input$water_body <- "Cascade River"
# # input$dates <- c(as.Date("2021-09-16", "%Y-%m-%d"), as.Date("2021-11-30", "%Y-%m-%d"))
# input$water_body <- c("Skagit River", "Sauk River")
# input$dates <- c(as.Date("2021-09-01", "%Y-%m-%d"), as.Date("2021-11-01", "%Y-%m-%d"))
# input$model_period <- "Week"
# input$index_count_types <- "Vehicle/Trailers Only" #c("Vehicle Only","Trailers Only")
# input$census_expansion <- "Direct"
# # 
# # input$sections <- "lut_water_body_location_d14_cascade_fall_salmon"
# # #input$river_loc <- "lut_River.Locations_2019-01-07"
# # input$census_exp <- "lut_Proportional_Expansions_for_Tie_In_Sections_Cascade_Fall_Salmon_2021"
# input$sections <- "lut_water_body_location_d14_skagit_fall_salmon_PE"
# input$census_exp <- "lut_Proportional_Expansions_for_Tie_In_Sections_Skagit_Fall_Salmon_2021"
# sections <- dplyr::select(sections_all[[input$sections]], water_body_desc, location = location_code, section)
# #river_loc <- river_loc_all[[input$river_loc]]
# river_loc <- dplyr::filter(river_loc_all, River %in% input$water_body) |>
#     distinct(District, .keep_all = T)
# census_exp <- if(str_detect(input$index_count_types, "Vehicle|Trailer")) {
#     census_expansion_all[[input$census_exp]] |>
#       mutate(
#         angler_type = if_else(angler_type == "bank", "total", "boat"),
#         cen_exp_meth = input$census_expansion)
#   } else {
#     census_expansion_all[[input$census_exp]] |>
#       mutate(cen_exp_meth = input$census_expansion)
#     }


  
sections <- reactive({
  dplyr::select(sections_all[[input$sections]], water_body_desc, location = location_code, section)
})

#!!NOT YET GENERIC TO MULTIPLE WATER_BODY(s) AND ROWS IN MASTER 
#!!ONLY USED IN DAY-LENGTH CALCULATION? WORK AROUND IS JUST SLICE(1)
river_loc <- reactive({
  #river_loc_all[[input$river_loc]]
  dplyr::filter(river_loc_all, River %in% input$water_body) |> 
    distinct(River, .keep_all = T) #anywhere this would actually be an issue?
})

census_exp <- reactive({
  ## fix angler type in census expansion table for use with vehicle / trailer counts so it joins to TI_expan table
  if(str_detect(input$index_count_types, "Vehicle|Trailer")) {
    census_expansion_all[[input$census_exp]] |> 
      mutate(
        angler_type = if_else(angler_type == "bank", "total", "boat"),
        cen_exp_meth = input$census_expansion
        )
  } else {
    census_expansion_all[[input$census_exp]] |> 
      mutate(cen_exp_meth = input$census_expansion)
    }
})

#this is "event reactive", so should not trigger on fiddling with inputs
#but only when "fetch" button is clicked (see last few lines of chunk)
reactive({
  creel$event <- paste0(
    dwg_base$event,
    "?$where=project_name in('", input$proj_name, "')",
    " AND water_body in('", paste0(input$water_body, collapse = "','"), "')",
    " AND event_date between '", input$dates[1],
    "T00:00:00' and '", input$dates[2],
    "T00:00:00'&$limit=100000"
    ) |>
    utils::URLencode() |>
    readr::read_csv(show_col_types = F) |>
    dplyr::select(creel_event_id, water_body, event_date, tie_in_indicator)
  
  if(nrow(creel$event) > 0) {
    
    creel$effort <- paste0(
      dwg_base$effort,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::filter(!is.na(count_type)) |> 
      dplyr::select(-created_datetime, -modified_datetime) |> 
#      dplyr::left_join(sections, by = c("location")) |> 
      dplyr::left_join(sections(), by = c("location")) |> 
      dplyr::filter(!is.na(section))

    creel$interview <- paste0(
      dwg_base$interview,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::rename(location = interview_location) |> 
      dplyr::select(
        -created_datetime, -modified_datetime,
        -state_residence, -zip_code) |> 
#      dplyr::left_join(sections, by = c("location")) |> 
      dplyr::left_join(sections(), by = c("location")) |> 
      dplyr::filter(!is.na(section))
    
    creel$catch <- paste0(
      dwg_base$catch,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::select(interview_id, catch_id, species, run, life_stage, fin_mark, fate, fish_count) |> 
      dplyr::mutate(
        life_stage = replace_na(life_stage, "Adult"), # placeholder pending data corrections in fish apps 
        catch_group = paste(species, life_stage, fin_mark, fate, sep = "_") # fish catch groups to estimate catch of 
      )
    
    ##seems somewhat inefficient to (potentially) rebuild, but takes a reactive dependence on input$dates and river_loc...
    #and this whole chunk depends on button push, so "lazy" against fiddling
    creel$days <- tibble::tibble(
      event_date = seq.Date(input$dates[1], input$dates[2], by = "day"),
      Day = weekdays(event_date),
      DayType = if_else(
        Day == "Saturday" | Day == "Sunday" | Day %in% dates_holidays_2015_2030,
        "Weekend", "Weekday"),
      DayType_num = if_else(str_detect(DayType, "end"),1,0),
      DayL = suncalc::getSunlightTimes(
        date = event_date,
        tz = "America/Los_Angeles",
#         lat = river_loc$Lat,
#         lon = river_loc$Long,
        lat = river_loc()$Lat,
        lon = river_loc()$Long,
        keep=c("dawn", "dusk")
      ) |>
        mutate(DayL = as.numeric(dusk - dawn)) |>
        pluck("DayL"),
      Week = as.numeric(format(event_date, "%V")),
      Month = as.numeric(format(event_date, "%m")),
      ModelPeriod = input$model_period
    ) |>
      tibble::rowid_to_column(var = "day_index") |>
      #make open section cols (only those actually used, not all in LU)
      left_join(
        expand_grid(
          event_date = seq.Date(input$dates[1], input$dates[2], by = "day"),
          s = paste0("open_section_", sort(unique(creel$effort$section))),
          closure_code = TRUE
        ) |>
          pivot_wider(names_from = s, values_from = closure_code)
        ,
        by = "event_date")

    #closures, super ugly, needs rethinking
    creel$days <- rows_upsert(
      creel$days,
      bind_rows(
        # 2022 Upper Skagit Chinook
        # tibble(section = "1", closure_begin = "2021-05-31", closure_end = "2021-05-31")

        # 2021 Skagit winter steelhead closure dates
        # tibble(section = "1,2", closure_begin = "2021-02-03", closure_end = "2021-02-05"),
        # tibble(section = "1,2", closure_begin = "2021-02-10", closure_end = "2021-02-12"),
        # tibble(section = "1,2", closure_begin = "2021-02-17", closure_end = "2021-02-19"),
        # tibble(section = "1,2", closure_begin = "2021-02-24", closure_end = "2021-02-26"),
        # tibble(section = "1,2", closure_begin = "2021-03-03", closure_end = "2021-03-05"),
        # tibble(section = "1,2", closure_begin = "2021-03-10", closure_end = "2021-03-12"),
        # tibble(section = "1,2", closure_begin = "2021-03-17", closure_end = "2021-03-19"),
        # tibble(section = "1,2", closure_begin = "2021-03-24", closure_end = "2021-03-26"),
        # tibble(section = "1,2", closure_begin = "2021-03-31", closure_end = "2021-04-02"),
        # tibble(section = "1,2", closure_begin = "2021-04-07", closure_end = "2021-04-09")
        # tibble(section = "1", closure_begin = "2016-04-30", closure_end = "2016-04-30") # placeholder closure date; need to supply at least one

        # kalama
        # tibble(section = "1,2,3", closure_begin = "2016-04-30", closure_end = "2016-04-30")
        # placeholder closure date; need to supply at least onedate here because we use open / closed dates to determine times_strata estimation periods (field n_days further down in code)

        # # Cascade
        # tibble(section = "1", closure_begin = "2021-09-18", closure_end = "2021-09-18"), # river out due to flows
        # tibble(section = "1", closure_begin = "2021-09-19", closure_end = "2021-09-20"), # treaty fishery closure
        # tibble(section = "1", closure_begin = "2021-09-26", closure_end = "2021-09-27"), # treaty fishery closure
        # tibble(section = "1", closure_begin = "2021-10-03", closure_end = "2021-10-04"), # treaty fishery closure
        # tibble(section = "1", closure_begin = "2021-11-13", closure_end = "2021-11-14"), # river out due to flows
        # tibble(section = "1", closure_begin = "2021-11-17", closure_end = "2021-11-18") # river out due to flows

        #Skagit fall salmon?
        tibble(section = "2,3", closure_begin = "2021-08-19", closure_end = "2021-08-31"),
        tibble(section = "2", closure_begin = "2021-09-01", closure_end = "2021-09-01"), # treaty fishery closure
        tibble(section = "2", closure_begin = "2021-09-07", closure_end = "2021-09-09"), # treaty fishery closure
        tibble(section = "2", closure_begin = "2021-09-14", closure_end = "2021-09-16"), # treaty fishery closure
        tibble(section = "1,2,3", closure_begin = "2021-09-18", closure_end = "2021-09-18"), # river out due to flows
        tibble(section = "2", closure_begin = "2021-10-05", closure_end = "2021-10-06"), # treaty fishery closure
        tibble(section = "2", closure_begin = "2021-10-12", closure_end = "2021-10-13"), # treaty fishery closure
        tibble(section = "2", closure_begin = "2021-10-19", closure_end = "2021-10-20"), # treaty fishery closure
        tibble(section = "1,2,3", closure_begin = "2021-11-13", closure_end = "2021-11-14"), # river out due to flows
        tibble(section = "1,2,3", closure_begin = "2021-11-17", closure_end = "2021-11-18") # river out due to flows
        
        ## other Skagit fall salmon?
        # tibble(section = "3,4,5", closure_begin = "2021-08-19", closure_end = "2021-08-31"),
        # tibble(section = "3", closure_begin = "2021-09-01", closure_end = "2021-09-01"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-09-07", closure_end = "2021-09-09"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-09-14", closure_end = "2021-09-16"), # treaty fishery closure
        # tibble(section = "1,2,3,4,5", closure_begin = "2021-09-18", closure_end = "2021-09-18"), # river out due to flows
        # tibble(section = "3", closure_begin = "2021-10-05", closure_end = "2021-10-06"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-10-12", closure_end = "2021-10-13"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-10-19", closure_end = "2021-10-20"), # treaty fishery closure
        # tibble(section = "1,2,3,4,5", closure_begin = "2021-11-13", closure_end = "2021-11-14"), # river out due to flows
        # tibble(section = "1,2,3,4,5", closure_begin = "2021-11-17", closure_end = "2021-11-18") # river out due to flows
      ) |>
        rowwise() |>
        mutate(closure_date = paste(seq.Date(as.Date(closure_begin), as.Date(closure_end), by = "day"), collapse = ",")) |>
        separate_rows(closure_date, sep = ",") |>
        select(event_date = closure_date, section) |>
        mutate(
          event_date = as.Date(event_date),
          closure_code = FALSE # TB - The 1e-06 is needed to keep the model from crashing ?log-normal parameters cant be 0
        ) |>
        separate_rows(section, sep = ",") |>
        pivot_wider(names_from = section, names_prefix = "open_section_", values_from = closure_code) |>
        mutate(across(starts_with("open_section_"), ~replace_na(., TRUE)))
      ,
      by ="event_date"
    )

  } else {
    creel$effort <- NULL
    creel$interview <- NULL
    creel$catch <- NULL
  }
}) |> 
  bindEvent(input$fetch)
  
```

### wrangling and calcs

```{r prep_effort_interview}
#Aggregate census (tie in) effort counts, associating to closest-in-time index count.
#take the initial effort_census, with all count_sequence == 1,
#add/overwrite the count_sequence val with that from closest temporal match from inline/anonymous paired counts object

#pe_effort_census <- reactive({
pe_effort_census <-
  dplyr::left_join(
    creel$effort |> 
      dplyr::filter(tie_in_indicator == 1) |>
      dplyr::select(event_date, water_body, water_body_desc, location, section, tie_in_indicator, count_type, count_quantity)
    ,
    #reassign count_seq from closest index
    dplyr::left_join(
      creel$effort |> dplyr::filter(tie_in_indicator == 1) |> dplyr::distinct(event_date, section, location, tie_in_indicator, effort_start_time, count_sequence),
      creel$effort |> dplyr::filter(tie_in_indicator == 0) |> dplyr::distinct(event_date, section, location, tie_in_indicator, effort_start_time, count_sequence),
      by = c("event_date", "section"),
      suffix = c("_cen", "_ind")
      ) |>
      dplyr::group_by(event_date, section, location_cen) |>
      dplyr::slice_min(abs(effort_start_time_cen - effort_start_time_ind), n = 1) |>
      dplyr::ungroup() |>
      dplyr::distinct(event_date, section, location = location_cen, count_sequence = count_sequence_ind)
    ,
    by = c("event_date", "section", "location")
  ) |>
    dplyr::left_join(creel$days, by = "event_date") |>
    dplyr::mutate(
      angler_type = dplyr::case_when(
        stringr::word(count_type, 1) %in% c("Bank","bank","Shore") ~ "bank",
        stringr::word(count_type, 1) %in% c("Boat","boat") ~ "boat" #Note "Boats" plural intentionally excluded
      )
    ) |>
    dplyr::filter(!is.na(angler_type)) |>
    dplyr::group_by(event_date, section, tie_in_indicator, count_sequence, angler_type) |>
    dplyr::summarize(count_census = sum(count_quantity), .groups = "drop") |>
    dplyr::arrange(event_date, section, count_sequence) |>
    tidyr::drop_na(count_sequence)
#})

# #combines several intermediates from CreelPointEstimate_Dev
# #mutate angler_type here creates a later join-by column
# pe_effort_index <- reactive({
pe_effort_index <-
  dplyr::filter(
    creel$effort, 
    tie_in_indicator == 0,
    is.na(no_count_reason),
    !is.na(count_type)
    #,count_type %in% input$index_count_types
    ) |>
  dplyr::group_by(event_date, section, count_sequence, count_type) |>
  dplyr::summarise(count_index = sum(count_quantity), .groups = "drop") |>
  dplyr::mutate(
    angler_type = dplyr::case_when(
      count_type == "Boat Anglers" ~ "boat",
      count_type == "Bank Anglers" ~ "bank",
      count_type == "Trailers Only" ~ "boat",
      count_type == "Vehicle Only" ~ "total"
    )
  ) |> 
  dplyr::arrange(event_date, section, count_sequence)
#})

#pe_effort_index_daily_mean <- reactive({
#   pe_effort_index() |> 
pe_effort_index_daily_mean <- pe_effort_index |> 
  dplyr::group_by(event_date, section, angler_type) |>
  dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop")
# })


# #interview data have angler_count, vehicle_count, trailer_count, angler_type and boat_used
# #Disallow NAs in angler_type, fill missing angler_type from boat_used
# #!!Does this actually need row-wise time_strata?
# #!!Maintain angler_hours_total filter?
# #!!lots of extra cols still at this point...
#pe_interview <- reactive({
pe_interview <- 
  left_join(creel$interview, creel$days, by = "event_date") |>
  mutate(
    across(c(vehicle_count, trailer_count), ~replace_na(., 0)),
    trip_status = replace_na(trip_status, "Unknown"),
    
    angler_type = tolower(angler_type),
    angler_type = if_else(is.na(angler_type), boat_used, angler_type),
    angler_type = case_when( 
      angler_type == "boat" ~ "boat", #pass through
      angler_type == "bank" ~ "bank", #pass through
      angler_type == "Unk" ~ "bank",  #Kalama, others?
      angler_type == "No" ~ "bank",   #value from boat_used
      angler_type == "Yes" ~ "boat"   #value from boat_used
      ),
    angler_type_ind = as.integer(factor(angler_type)),
    
    fishing_end_time = if_else(
      trip_status == "Incomplete" | is.na(fishing_end_time),
      interview_time,
      fishing_end_time),
    angler_hours = round(as.numeric(fishing_end_time - fishing_start_time) / 3600, 5),
    angler_hours_total = angler_count * angler_hours,
    time_strata = if_else(ModelPeriod == "Month", Month, Week)
  ) |>
  filter(angler_hours_total >= 0.5)
#})


# join catch data to interview after inferring complete cases (counts or 0s for all catch_groups encountered)
#!!should already be distinct on interview_id
#!!currently filtered to angler_hours >= 0.5
#!!so some rows in creel$catch for "short" interviews may be lost in join 
#!!note also that interview_ids in creel$interview/pe_interview may have no catch and not be in creel$catch
#!!so are consequently coded NA for catch_group
# setdiff(creel$catch$interview_id, pe_interview$interview_id)  #lost in the join, due to "short" angler_hours
# setdiff(creel$interview$interview_id, creel$catch$interview_id) #no catch, so no catch_group(s) to assign
# interview_and_catch |> filter(is.na(catch_group))
#!!added final mutate as an option to code level as something...

#pe_interview_and_catch <- reactive({
pe_interview_and_catch <- 
  left_join(
    pe_interview |> drop_na(angler_hours) 
#    pe_interview() |> drop_na(angler_hours) 
    ,
    creel$catch |> 
      group_by(interview_id, catch_group) |> 
      summarise(fish_count = sum(fish_count, na.rm = T), .groups = "drop") |> 
      pivot_wider(
        names_from = catch_group,
        values_from = fish_count,
        values_fill = 0) |> 
      pivot_longer(
        cols = -interview_id, 
        names_to = "catch_group", 
        values_to = "fish_count"
      ) 
    , 
    by = "interview_id"
  ) |> #filter(is.na(catch_group)) |> select(interview_id, total_group_count, starts_with("angler_"), catch_group, fish_count)
  mutate(
    catch_group = replace_na(catch_group, "no encounter data"),
    fish_count = replace_na(fish_count, 0)
  ) |> 
  #drop a few unused cols for ease of dev
  select(-creel_event_id, -water_body, -project_name, -interview_number,
         -crc_area, -fishing_location, -ends_with("_time"),
         -c(trip_guided:water_body_desc),
         -day_index, -Day, -c(DayType_num:angler_type_ind)
         )
#})

```

*NOT YET SHINY*

```{r effort_interview_final, eval = FALSE}

#!!is angler_type total ever actually needed/used?
#!!right_joins to this below drop any "total" rows...
days_join <- creel$days |>
  mutate(time_strata = if_else(ModelPeriod == "Month", Month, Week)) |> 
  select(time_strata, event_date, DayType, starts_with("open_section")) |> 
  mutate(
    section = list(unique(sections$section)),
    angler_type = list(c("bank", "boat")) 
  ) |> 
  unnest(cols = section) |> 
  unnest(cols = angler_type)

# # #"days_join" also separate_rows option?
# creel$days |>
#   mutate(time_strata = if_else(ModelPeriod == "Month", Month, Week)) |>
#   select(time_strata, event_date, DayType, starts_with("open_section")) |>
#   mutate(
#     section = paste0(unique(sections$section), collapse = ","),
#     angler_type = paste0(c("bank", "boat"), collapse = ",") #is total ever actually needed?
#   ) |>
#   separate_rows(section,  sep = ",") |> 
#   separate_rows(angler_type, sep = ",")


#!!The first block in the index_count_types test joins tie-in expanded census counts of anglers by type (per section)
#!!back against daily mean index counts of anglers expanded by day length
#!!the calc "mean_daily_effort = count_index_mean * DayL" seems to imply count_index_mean is normalized to per-hour
#!!but it is just the mean per-day over possibly several index counts per section and angler type
#!!so it is only a per-hour unit if the count_index values being averaged are already per-hour???
#!!the count_index values being averaged are summed per count_sequence - is the protocol to only count for an hour?

if(str_detect(input$index_count_types, "Bank|Boat")) {
  # join census (tie in) counts to index counts 
  # calculate mean daily effort multipled by bias term (tie in ratio) from census counts
  effort_interviews_final <- left_join(
    #daily_effort_estimates
    left_join(
      pe_effort_index_daily_mean, 
      creel$days |> select(event_date, DayL),
      by = "event_date") |> 
      mutate(mean_daily_effort = count_index_mean * DayL) |>
      arrange(event_date, section)
    ,
    #census_counts_all: left join index effort counts to census counts 
    left_join(
      pe_effort_census, #summed by event_date, section, tie_in_indicator, count_sequence, angler_type [bank, boat]
      pe_effort_index, #summed by event_date, section, count_sequence, count_type [Bank Ang, Boat Ang, Vehic, Trailr] and derived angler_type [bank, boat, total])
      by = c("event_date", "section", "count_sequence","angler_type")
    ) |>
      mutate(
        count_index = replace_na(count_index, 0),
        TI_expan = count_census / count_index,
        TI_expan = if_else(is.infinite(TI_expan) | is.nan(TI_expan), NA_real_, TI_expan)
      ) |> 
      group_by(section, angler_type) |> 
      summarise(
        TI_expan_mean = mean(TI_expan, na.rm=TRUE),
        TI_expan_weighted = sum(count_census) / sum(count_index),
        across(
          c(TI_expan_mean, TI_expan_weighted),
          ~if_else(. == 0, 1, .) |> replace_na(1)
        ),
        .groups = "drop"
      ) |> 
      left_join(
        census_exp |> 
          select(cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
        by = c("angler_type", "section")
      ) |>
      mutate(
        #dealing with e.g. Cascade edge case of nothing to join for an angler_type/section
        #should really be addressed in the Prop_Expansion table...
        cen_exp_meth = replace_na(cen_exp_meth, input$census_expansion),
        p_TI = replace_na(p_TI, 1),
        TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
        TI_expan_final = if_else(
          cen_exp_meth == "Direct" | is.na(cen_exp_meth),
          TI_expan_weighted / p_TI,
          TI_expan_indirect)
      )
    , 
    by = c("section", "angler_type")
  ) |>
    mutate(
      TI_expan_final = replace_na(TI_expan_final, 1),
      mean_daily_TI_expan = mean_daily_effort * TI_expan_final
    )  |>
    select(event_date, section, angler_type, mean_daily_TI_expan) |> 
    right_join(days_join, by = c("event_date", "section", "angler_type")) |>
#!!maybe drop this second select() if possible to drop right_join itself?
    select(time_strata, event_date, DayType, section, angler_type, everything()) |> 
    mutate(
      creeled = if_else(!is.na(mean_daily_TI_expan) & open_section_1 == TRUE, "Y", "N")
    ) |> 
    arrange(event_date)
  
} else {
  if(str_detect(input$index_count_types, "Vehicle|Trailer")) { 

    #anglers_per_vehicle from day-section totals amount to arith mean of multiple interviews?
    #presumably this blows up if sum(vehicle_count)==0
    angler_data_from_interviews <- bind_rows(
      pe_interview |>
        group_by(event_date, section) |> 
        summarize(
          angler_hours_total = sum(angler_hours_total),
          anglers_per_vehicle = sum(angler_count) / sum(vehicle_count),
          #anglers_per_index_count_from_interview = daily_sum_angler / daily_sum_index_count_from_interview,
          angler_type = "total",
          .groups = "drop")
      ,
      pe_interview |> 
        filter(angler_type == "boat") |>
        group_by(event_date, section) |> 
        summarize(
          angler_hours_total = sum(angler_hours_total),
          anglers_per_vehicle = sum(angler_count) / sum(vehicle_count),
          angler_type = "boat",
          .groups = "drop")
    ) 
    
    daily_effort_estimates <- angler_data_from_interviews  |>
      left_join(pe_effort_index_daily_mean, by = c("event_date", "section", "angler_type")) |>
      left_join(creel$days |> select(event_date, DayL), by = "event_date") |> 
      mutate(mean_daily_effort = anglers_per_vehicle * count_index_mean * DayL) |>
      arrange(event_date, section) 
    # |> filter(!is.na(mean_index_count)) #EB: circle back on this

    #join interview-expanded index counts to census
    census_counts_all <- left_join(
      #census already grouped & summed by event_date, section, tie_in_indicator, count_sequence, angler_type [bank, boat]
      #but here split, collapse and then reassign angler_type to total & boat
      bind_rows(
        pe_effort_census |> 
          group_by(event_date, section, count_sequence) |> 
          summarize(count_census = sum(count_census), angler_type = "total", .groups = "drop")
        ,
        pe_effort_census |> 
          filter(angler_type == "boat") |>
          group_by(event_date, section, count_sequence) |> 
          summarize(count_census = sum(count_census), angler_type = "boat", .groups = "drop")
      )
      ,
      #index via interviews with angler_type [total, boat]
      #using ang/vehicle from interview to expand index counts of vehicles
      #!!most likely an expanding join since interview is already per day-section here
      #!!but effort_index is per count_seq (per day-section)
      #!!so is it correct for this to be left_ rather than full/inner?
      left_join(
        angler_data_from_interviews,
        pe_effort_index, #|> select(-count_type), 
        by = c("event_date", "section", "angler_type")
        ) |> 
        mutate(count_index = anglers_per_vehicle * count_index) |> 
        select(event_date, section, count_sequence, angler_type, count_index)
      ,
      by = c("event_date", "section", "count_sequence", "angler_type")
      ) |>
      mutate(
        count_index = replace_na(count_index, 0),
        TI_expan = count_census / count_index,
        TI_expan = if_else(is.infinite(TI_expan) | is.nan(TI_expan), NA_real_, TI_expan)
      ) |> 
      group_by(section, angler_type) |> 
      summarise(
        TI_expan_mean = mean(TI_expan, na.rm=TRUE),
        TI_expan_weighted = sum(count_census) / sum(count_index),
        across(
          c(TI_expan_mean, TI_expan_weighted),
          ~if_else(. == 0, 1, .) |> replace_na(1)
          ),
        .groups = "drop"
      ) |> 
      left_join(
        census_exp |> select(cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
        by = c("angler_type", "section")
        ) |>
      mutate(
        #dealing with e.g. Cascade edge case of nothing to join for an angler_type/section
        #should really be addressed in the Prop_Expansion table...
        cen_exp_meth = replace_na(cen_exp_meth, input$census_expansion),
        p_TI = replace_na(p_TI, 1),
        TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
        TI_expan_final = if_else(
          cen_exp_meth == "Direct" | is.na(cen_exp_meth),
          TI_expan_weighted / p_TI,
          TI_expan_indirect)
      )
    
    # join census (tie in) counts to index counts 
    
    # calculate mean daily effort multipled by bias term (tie in ratio) from census counts
    #!!aiming for event_date, angler_type [total, boat, bank (as total-boat)]
    #!!Fails for Cascade - no "boat" in daily_effort_estimates (since no boat angler_type in pe_interview)
    #!!so left_join of census_counts_all provides no "boat" rows
    #!!so pivot wider produces no "boat" col, so mutate cannot find
    #!!however "total - boat" seems potentially troublesome even when both present
    #!!negatives, zeros, near-zero, etc
    #!!is "total" really needed/used? 
    #!!   not present for a non-trailer/vehicle index case
    #!!   and just creates additional level that could be dropped against days_join obj?
    effort_interviews_prelim <- left_join(
      daily_effort_estimates |> select(event_date, section, angler_type, mean_daily_effort),
      census_counts_all |> select(section, angler_type, TI_expan_final),
      by = c("section", "angler_type")
    ) |> 
      mutate(mean_daily_TI_expan = mean_daily_effort * TI_expan_final) 
    
    if(any(pe_interview$angler_type=="boat")) {
      effort_interviews_final <- bind_rows(
        #total and boat
        effort_interviews_prelim |> 
          select(event_date, section, angler_type, mean_daily_TI_expan),
        #derived bank
        effort_interviews_prelim |> 
          select(event_date, section, angler_type, mean_daily_TI_expan) |> 
          pivot_wider(names_from = angler_type, values_from = mean_daily_TI_expan, values_fill = 0) |>
          mutate(
            angler_type = "bank", 
            mean_daily_TI_expan = total - boat,
            total = NULL, boat = NULL)
      ) |> 
        right_join(days_join, by = c("section", "event_date", "angler_type")) |> 
        mutate(creeled = if_else(!is.na(mean_daily_TI_expan), "Y", "N")) |> 
        select(time_strata, event_date, DayType, section, angler_type, everything()) |> 
        arrange(event_date)
    } else { #only angler_type == "total", coerce "boat" to 0 and "bank" to total
      effort_interviews_final <- bind_rows(
        effort_interviews_prelim |> 
          select(event_date, section, angler_type, mean_daily_TI_expan),
        effort_interviews_prelim |> 
          select(event_date, section) |> 
          mutate(angler_type = "boat", mean_daily_TI_expan = 0),
        effort_interviews_prelim |> 
          select(event_date, section, mean_daily_TI_expan) |> 
          mutate(angler_type = "bank")
      ) |> 
        right_join(days_join, by = c("section", "event_date", "angler_type")) |> 
        mutate(creeled = if_else(!is.na(mean_daily_TI_expan), "Y", "N")) |> 
        select(time_strata, event_date, DayType, section, angler_type, everything()) |> 
        arrange(event_date)
    }
    
  }
}

```

```{r effort_interview_final_with_days_total_sampled, eval = FALSE}
# excluding specified closures, total number of days by section, weekday/end, and time strata for which to generate estimates
creel$days_total <- creel$days |>
  pivot_longer(
    cols = starts_with("open_section"), 
    names_to = "section", 
    values_to = "closure_value") |>
  filter(closure_value == TRUE) |> 
  mutate(
    section = as.numeric(gsub("^.*_", "", section)),
    time_strata = if_else(ModelPeriod == "Month", Month, Week)
    ) |>
  count(time_strata, DayType, section, name = "N_days")

# number of days sampled within monitoring period
creel$days_sampled <- effort_interviews_final |>
  filter(!is.na(mean_daily_TI_expan) & creeled == "Y") |> 
  count(time_strata, DayType, section, angler_type, name = "n_days")


# add these objects to the table with index count data
effort_interviews_final <- effort_interviews_final |> 
  drop_na(mean_daily_TI_expan) |> 
  left_join(creel$days_total,
    by = c("time_strata", "DayType", "section")) |> 
  left_join(creel$days_sampled,
    by = c("time_strata", "DayType", "section", "angler_type")) |>
  left_join(
    creel$days_total |> 
      group_by(section, DayType) |> 
      summarise(N_days_total = sum(N_days), .groups = "drop"),
    by = c("DayType", "section")) |> 
  left_join(
    creel$days_sampled |> 
      group_by(section, DayType, angler_type) |> 
      summarise(n_days_total = sum(n_days), .groups = "drop"),
    by = c("DayType", "section", "angler_type")) 


# #!!previously 'effort_join' with the CPUE object construction...
# #!!why wouldn't this be group_by and mutate rather than left_join of a summarized?
# effort_join <- left_join(
#   effort_interviews_final,
#   effort_interviews_final |> 
#     #!!Not including DayType in group_by?
#     group_by(time_strata, section, angler_type) |>
#     summarise(mean_strata_effort = mean(mean_daily_TI_expan), .groups = "drop") |>
#     complete(time_strata, section, angler_type, fill = list(mean_strata_effort = 0))
#   ,
#   by = c("time_strata","section", "angler_type")
# ) |> 
#   mutate(mean_daily_TI_expan = if_else(mean_daily_TI_expan == 0, mean_strata_effort, mean_daily_TI_expan))

effort_interviews_final_strata_mean <- effort_interviews_final |> 
#!!Not including DayType in group_by?
  group_by(time_strata, section, angler_type) |>
  mutate(mean_strata_effort = mean(mean_daily_TI_expan)) |>
  ungroup() |> 
#!!is this complete actually necessary??
  complete(time_strata, section, angler_type, fill = list(mean_strata_effort = 0)) |> 
  mutate(
    mean_daily_TI_expan = if_else(
      mean_daily_TI_expan == 0, 
        mean_strata_effort,
        mean_daily_TI_expan
      )) |> 
  select(time_strata, event_date, DayType, section, angler_type, everything())


```

```{r interview_catch_daily_CPUE, eval = FALSE}

# #previously built "angler_hours_summary" object
# #was mean angler hours by complete strata:  time_strata, DayType, section, angler_type, catch_group
# #meant for use in "case of non-zero catch but no angler hours to use to calculate CPUE (should be a rare situation)"
# #e.g.: interview_and_catch |> filter(fish_count>0) |> filter(angler_hours_total<0.5)
# #but only left_joined back to interview_and_catch
# #so complete cases unnecessary (since lost in join)
# #NOW JUST PER_GROUP MUTATING ON to avoid intermediate creation and rejoin
# angler_hours_strata_mean <- interview_and_catch |>
#   group_by(time_strata, DayType, section, angler_type, catch_group) |>
#   summarise(angler_hours_strata_mean = mean(angler_hours_total), .groups = "drop") |>
#   complete(
#     time_strata, DayType, section, angler_type, catch_group,
#     fill = list(angler_hours_strata_mean = 0)
#     )
# 
# angler_hours_strata_mean |> filter(angler_hours_strata_mean==0)
# interview_and_catch |> filter(time_strata==38, DayType=="Weekend", section==1, angler_type=="bank", catch_group=="Bull Trout_Adult_NA_Released")
# 
# # interview_daily_totals <- left_join(
# #   interview_and_catch,
# #   angler_hours_summary,
# #   by = c("time_strata", "DayType", "section", "angler_type", "catch_group")
# #   ) |> 


#first add strata mean vals in case of 0 angler_hours_total on a day with non-zero fish_count
#!!may need to add logic to avoid NaN if below if_else evals false AND any angler_hours_strata_mean==0?
#next aggregate interviews per day per strata of [week/month-weekend/day-section-bank/boat-catch_group]
#!!DA: the cpue_rom here is a ratio of sums - are we calling that equivalent to "ratio of the means"?
interview_daily_totals <- pe_interview_and_catch |>
  group_by(time_strata, DayType, section, angler_type, catch_group) |>
  mutate(angler_hours_strata_mean = mean(angler_hours_total)) |> 
  ungroup() |>
  mutate(
    cpue_interview = if_else(
      angler_hours_total > 0,
      fish_count / angler_hours_total, #angler_count * angler_hours
      fish_count / angler_hours_strata_mean)
  ) |>
  group_by(time_strata, event_date, DayType, section, angler_type, catch_group) |>
  summarise(
    n_groups = n(),
    catch_daily = sum(fish_count),
    angler_hours_total_daily = sum(angler_hours_total),
    cpue_rom_daily = catch_daily / angler_hours_total_daily, # ratio of the means CPUE estimator
    cpue_mor_daily = mean(cpue_interview),  # mean of ratios CPUE estimator
    .groups = "drop"
  )

# #calculate mean CPUE values by strata to use on days with known effort but a lack of interviews 
# #further aggregates over per-day obs within a [week/month, weekend/day, bank/boat, catch_group]
# # cpue_mor_strata_mean is the mean over "daily_totals" obs which are over interview_id per day-otherstrata
# #the complete() here generates strata levels (assigned 0) not present in interview/catch data 
# #Fisheries Techniques (Jones and Pollock 2012) suggest MOR for roving survey design
# cpue_strata_mean <- interview_daily_totals |>
#   group_by(time_strata, DayType, section, angler_type, catch_group) |>
#   summarise(
#     cpue_rom_strata_mean = mean(cpue_rom_daily),
#     cpue_mor_strata_mean = mean(cpue_mor_daily), 
#     .groups = "drop"
#   ) |>
#   complete(
#     time_strata, DayType, section, angler_type, catch_group,
#     fill = list(cpue_mor_strata_mean = 0, cpue_rom_strata_mean = 0)
#     )
# 
# 
# #add implicit missing values of CPUE to dataset using tidyr complete() function
# interview_daily_totals_complete <- interview_daily_totals |>
#   complete(event_date, section, angler_type, catch_group,
#            fill = list(catch_daily = 0)) |> 
#   select(time_strata, event_date, DayType, section, angler_type, catch_group, everything())
# #but this creates NAs for the other cpue cols besides catch_daily[sum]... 
# #including time_strata in select() creates rows of NA time_strata since not included in complete()
# #was previously selecting off un-completed cols and then later rejoining creel$days and rebuilding time_strata
# interview_daily_totals_complete |> summary()
# 
# #!!DA not sure exactly what is intended/desired here...
# #!!preferable to do something like a distinct?
# #!!or just use the rejoin of creel$days to get time_strata & DayType?
# interview_and_catch |> 
#   distinct(event_date, section, angler_type, catch_group) |> 
#   complete(event_date, section, angler_type, catch_group)
# 
# #!!and/but/so this currently carries forward the NAs left in interview_daily_totals_complete
# # join mean_strata_cpue values to table with daily cpue values so we can use the mean strata cpue values on days with known effort but no corresponding interview
# daily_CPUE <- left_join(
#   interview_daily_totals_complete, 
#   cpue_strata_mean, 
#   by = c("time_strata", "DayType", "section", "angler_type", "catch_group")
#   )


#!!DA pending conversation with EB
#rather than dailyCPUE as interview_daily_totals >>> interview_daily_totals_complete >>> left_join( interview_daily_totals >>> cpue_summary)
#just mutate on the fields in cpue_strata_mean
#and come back to figure out need for complete()
daily_CPUE <- interview_daily_totals |>
  group_by(time_strata, DayType, section, angler_type, catch_group) |>
  mutate(
    cpue_rom_strata_mean = mean(cpue_rom_daily),
    cpue_mor_strata_mean = mean(cpue_mor_daily)
  ) |>
  ungroup()

```

```{r estimates, eval = FALSE}
#!!DA first 3 objects are ingredients for subsequent effort and catch summary objects

#### ingredients -------------
daily_effort_cpue_catch <- left_join(
  daily_CPUE, 
  effort_interviews_final_strata_mean,
  by = c("time_strata", "event_date", "DayType", "section", "angler_type")
  ) |>
#!!DA drop both of these?
  mutate(angler_hours_total_daily = replace_na(angler_hours_total_daily, 0)) |> 
  filter(angler_type %in% c("bank","boat")) |>
  mutate(
#!!DA bad test? when would cpue_mor_daily eval NA? I've gotten rid of days/levels from a complete or join somewhere?
    catch_estimate = if_else(
      !is.na(cpue_mor_daily),
      mean_daily_TI_expan * cpue_mor_daily,
      mean_daily_TI_expan * cpue_mor_strata_mean
      ),
    
    # catch_estimate = if_else(catch_dailysum > 0 & mean_daily_TI_expan == 0, cpue_mor * mean_strata_effort, catch_estimate) # circle bacl to this, issue is days with non-zero catch by no effort
    # catch_estimate_rom = if_else(!is.na(cpue_rom), mean_daily_TI_expan * cpue_rom, mean_daily_TI_expan * mean_strata_cpue_rom), # option to use ratio of the means CPUE estimator
    # catch_estimate = catch_estimate_mor
    across(where(is.numeric), round, 2)
    ) |>
#!!DA YIKES!?!?
#!!seems either unnecessary or needs better specification of fields?
  distinct() |>
  # filter(!is.na(mean_daily_TI_expan)) |> 
  arrange(catch_group, section, event_date, angler_type) 


# create table with degrees of freedom by section and angler type to apply to time strata estimates
degrees_freedom <- daily_effort_cpue_catch |>
  distinct(section, angler_type, time_strata, n_days) |> 
  group_by(section, angler_type) |> 
  summarize(
    min_n_days = min(n_days),
    sum_n_days = sum(n_days),
    degrees_freedom = min_n_days + sum_n_days / 2,
    .groups = "drop"
  )

# dates object to join back to summary objects to plotting
#!!takes first day per week per month
#!!not sure if/how it matters but 
#!!this distinct() associates in month-spanning weeks to the earlier month
#!!e.g., in 2021 week 39 in both Sep and Oct, gets only to Sep 
#!!also not sure how the col rename will play with a reactive input list...
days_join_2 <- creel$days |> 
  group_by(Month, Week) |>
  slice(1) |>
  ungroup() |> 
  distinct(Week, .keep_all = TRUE) |> 
  rename(time_strata = input$model_period)

#### effort summaries  --------------

#!!how is distinct() meant to play with still-grouped summarize output?
# calculate effort by day type and angler type strata
time_strata_effort_by_daytype <- daily_effort_cpue_catch |>
  group_by(section, angler_type, time_strata, DayType, n_days, N_days) |> 
  summarize(
    n = n(),
    sum_daily_effort_sampled_days = sum(mean_daily_TI_expan),
    mean_daily_effort = mean(mean_daily_TI_expan),
    variance_daily_effort = var(mean_daily_TI_expan),
    total_effort = mean_daily_effort * N_days,
    variance_total_daily_effort = if_else(
      n_days < N_days,
      (N_days^2) * (variance_daily_effort / n_days) * (1-(n_days/N_days)),
      (N_days^2) * (variance_daily_effort / n_days)
      )
    ) |> 
  distinct()

#!!sure about left_join on still-grouped summarize output? i.e., with just time_strata dropped?
#!!the col named "SE" is standard deviation not standard error
#!!not sure which is desired? if sd, could also use sd()?
# Sum effort estimates across day types, retain grouping on angler type 
time_strata_effort_total <- time_strata_effort_by_daytype |>
  group_by(section, angler_type, time_strata) |> 
  summarise(
    total_effort = sum(total_effort),
    variance = sum(variance_total_daily_effort)
    ) |> 
 left_join(degrees_freedom, by = c("section", "angler_type")) |> 
  mutate(
    variance = if_else(is.na(variance),0,variance),
    SE = sqrt(variance),
    CV = SE / total_effort,
    lwr95CI = total_effort - qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
    upr95CI = total_effort + qt(1-(0.05/2),degrees_freedom)*(variance^0.5)
  ) |> 
  distinct(time_strata, angler_type, .keep_all = TRUE)|> 
  mutate_if(is.numeric, round, 2) |> 
  filter(angler_type %in% c("bank","boat")) |>
  left_join(days_join_2, by = "time_strata") 

#!!this shows up on L1389 and then again L1689/1708
#!!may be able to drop ungroup if dealt with earlier?
total_effort <- ungroup(time_strata_effort_total) |> 
  summarize(total_effort = sum(total_effort, na.rm = T))


#### catch summaries  --------------

#!!as above, concern/questions about (double) distinct()
#!!and this exits the pipe still grouped...
# calculate catch by day type and angler type strata
time_strata_catch_by_daytype <- daily_effort_cpue_catch |>
  filter(!is.na(catch_estimate)) |> 
  group_by(section, angler_type, catch_group, time_strata, DayType, n_days, N_days) |> 
  summarize(
    total_catch_unexpanded = sum(catch_estimate),
    mean_daily_catch = total_catch_unexpanded / n_days,
    total_catch_expanded_2 = total_catch_unexpanded * N_days,
    total_catch_expanded = mean_daily_catch * N_days,
    variance_catch_estimate = var(catch_estimate),
    n_days = mean(n_days),
    N_days = mean(N_days)) |> 
  distinct() |> 
  mutate(
    variance_catch_estimate = replace_na(variance_catch_estimate, 0),
    variance_total_catch_expanded = if_else(n_days < N_days, (N_days^2) * (variance_catch_estimate / n_days) * (1-(n_days/N_days)),  (N_days^2) * (variance_catch_estimate / n_days))
  ) |> 
  distinct()

# cannot calculate variance for estimates when n = 1 for daytype strata within a week
# Sum catch estimates across day types, retain grouping on angler type 
time_strata_catch_total <- time_strata_catch_by_daytype |>
  group_by(section, time_strata, catch_group, angler_type) |> 
  summarise(
    total_catch = sum(total_catch_expanded),
    variance = sum(variance_total_catch_expanded)
  ) |> 
  left_join(degrees_freedom, by = c("section", "angler_type")) |>
  mutate(
    variance = if_else(is.na(variance), 0, variance),
    SE = sqrt(variance),
    CV = SE / total_catch,
    lwr95CI = total_catch - qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
    upr95CI = total_catch + qt(1-(0.05/2),degrees_freedom)*(variance^0.5)
  ) |>
  distinct() |> 
  mutate_if(is.numeric, round, 2) |> 
  filter(angler_type %in% c("bank", "boat")) |> 
  arrange(section, catch_group, time_strata) |>
  left_join(days_join_2, by = "time_strata") 

total_catch <- time_strata_catch_total |> 
  group_by(section, catch_group) |> 
  summarize(total_catch = sum(total_catch))

#### other summary stuff -------

#!!DA looks like this may only be for weekly? at least the first mutate seems wrong for monthly strata?
#!!only minimal mods, since likely to change further pending upstream questions
#from unnamed chunk L1540
# EB circle back to this for calculating CPUE / HPUE and associated uncertainty over time period of interest 
cpue_time_strata <- time_strata_catch_total  |>
  select(
    section, time_strata, angler_type,
    total_catch,
    catch_variance = variance,
    catch_SE = SE,
    catch_CV = CV,
    catch_lwr95CI = lwr95CI,
    catch_upr95CI = upr95CI
  ) |>
  mutate(daily_catch_estimate = total_catch / 7) |> 
  left_join(
    time_strata_effort_total |> 
      select(
        section, time_strata, angler_type,
        total_effort,
        effort_lwr95CI = lwr95CI,
        effort_upr95CI = upr95CI,
        effort_SE = SE,
        effort_CV = CV),
    by = c("section","angler_type","time_strata")) |> 
  mutate(
    across(where(is.numeric), round, 2),
    cpue_time_strata = replace_na(total_catch / total_effort, 0),
    cpue_lwr95_time_strata = catch_lwr95CI / effort_lwr95CI,
    cpue_upr95_time_strata = catch_upr95CI / effort_upr95CI,
    cpue_lwr95_time_strata = if_else(is.na(cpue_lwr95_time_strata),0, cpue_lwr95_time_strata),
    cpue_upr95_time_strata = if_else(is.na(cpue_upr95_time_strata),0, cpue_upr95_time_strata)) |> 
  distinct() |>
  left_join(days_join_2, by = "time_strata") 



degrees_freedom_total <- effort_interviews_final |> 
  distinct(section, angler_type, n_days_total) |>
  rename(n_days = n_days_total) |> 
  group_by(section, angler_type) |> 
  summarize(
    min_n_days = min(n_days),
    sum_n_days = sum(n_days),
    degrees_freedom = min_n_days + sum_n_days / 2
  )

#!!DA on L1689 assigned to estimates list then (possibly) overwrites the previously created non-list version 
# Adding together time strata specific effort estimates and associated variance and calculating SE, CV, and 95% CI's
total_effort <- time_strata_effort_total |>
  select(-c(min_n_days, sum_n_days, degrees_freedom)) |> 
  left_join(degrees_freedom_total, by = c("section", "angler_type")) |> 
  group_by(section, angler_type) |> 
  summarise(
    total_effort = sum(total_effort),
    variance = sum(variance),
    SE = sqrt(variance),
    CV = SE / total_effort,
    lwr95CI = total_effort - qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
    upr95CI = total_effort + qt(1-(0.05/2),degrees_freedom)*(variance^0.5)
  ) |>
  distinct() |> 
  mutate_if(is.numeric, round, 2) |> 
  arrange(section)


# Adding together time_strata catch estimates and associated variance and calculating SE, CV, and 95% CI's
total_catch <- time_strata_catch_total |>
  select(-c(min_n_days, sum_n_days, degrees_freedom)) |> 
  left_join(degrees_freedom_total, by = c("section", "angler_type")) |> 
  mutate(variance = replace_na(variance, 0)) |> 
  group_by(catch_group, section, angler_type) |> 
  summarise(
    total_catch = sum(total_catch),
    variance = sum(variance),
    SE = sqrt(variance),
    CV = SE / total_catch,
    lwr95CI = total_catch - qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
    upr95CI = total_catch + qt(1-(0.05/2),degrees_freedom)*(variance^0.5)
  ) |>
  distinct() |> 
  mutate_if(is.numeric, round, 2) |> 
  filter(angler_type %in% c("bank", "boat")) |> 
  arrange(section, catch_group)


```

Data
============================================

```{r eval=FALSE}
# renderPrint(input$proj_name)
# renderPrint(input$water_body)
# renderPrint({paste(input$dates[1], "to", input$dates[2])})
```

Event and Days
--------------------------------------------

### Event

```{r gt_creel_event}
render_gt({ head(creel$event) })
```

### Days

```{r gt_creel_days}
#renderPrint({str(days)})
render_gt({ head(creel$days) })
```


Effort
--------------------------------------------

### Effort

```{r gt_creel_effort}
render_gt({ head(creel$effort) })
```

Interview
--------------------------------------------

### Interview

```{r gt_creel_interview}
render_gt({ head(creel$interview) })
```

Catch
--------------------------------------------

### Catch

```{r gt_creel_catch}
render_gt({ head(creel$catch) })
```


Effort/Interview
============================================

Effort
--------------------------------------------

### Index counts

```{r}
#renderPrint({str(creel$effort)})

# renderPlot({
#   if(!is.null(creel$effort)) {
#     creel$effort |>
#       group_by(tie_in_indicator, section, event_date) |>
#       summarise(count_quantity = sum(count_quantity), .groups = "drop") |>
#       ggplot(aes(event_date, count_quantity, fill = section)) +
#       geom_col() +
#       facet_wrap(~tie_in_indicator, scales = "free")
#   }
# })

#renderPrint({str(pe_effort_census())})

renderPlot({
  if(!is.null(creel$effort)) {
    pe_effort_index() |>
      ggplot(aes(event_date, count_quantity, fill = factor(count_sequence))) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + count_type, scales = "free")
  }
})

```

### Index daily mean

```{r}
renderPlot({
  if(!is.null(creel$effort)) {
    pe_effort_index_daily_mean() |>
      ggplot(aes(event_date, count_quantity, fill = count_type)) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + count_type, scales = "free")
  }
})

```

Interview
--------------------------------------------

### Interview

```{r}
renderPlot({
  if(!is.null(creel$interview)) {
    pe_interview() |>
      ggplot(aes(event_date, angler_hours_total, fill = angler_type)) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + angler_type, scales = "free")
  }
})

```

### Interview

```{r}
renderPlot({
  if(!is.null(creel$interview)) {
    pe_interview() |>
      ggplot(aes(angler_count, angler_hours_total, fill = angler_type)) +
      geom_point(position = position_dodge()) +
      facet_wrap(~section + angler_type, scales = "free")
  }
})

```

Catch
============================================


About
============================================

Anything to cite/link to?

WDFW gathers fishing information from anglers around the state:
(https://wdfw.wa.gov/fishing/reports/creel)[https://wdfw.wa.gov/fishing/reports/creel]
