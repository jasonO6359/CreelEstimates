---
title: "FW Creel Point Estimate"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    source_code: embed
    theme:
      version: 4
      bootswatch: default
      bg: "#D0D0D0"
      fg: "#000000"
      navbar-bg: "#1189D9"
      primary: "#1189D9"
runtime: shiny
---

```{r setup, include=FALSE}
#bslib::bs_themer()

library("flexdashboard")
library("tidyverse")
library("shiny")
library("patchwork")
library("gt")

#base endpoints
dwg_base <- list(
  event = "https://data.wa.gov/resource/ui95-axtn.csv",
  effort = "https://data.wa.gov/resource/h9a6-g38s.csv",
  interview = "https://data.wa.gov/resource/rpax-ahqm.csv",
  catch = "https://data.wa.gov/resource/6y4e-8ftk.csv",
  gear = "https://data.wa.gov/resource/d2ks-afhz.csv" #currently unused?
)

#water_body options by proj_name options
proj_levels <- list(
  `R5 Steelhead` = list("Kalama River"),
  `District 13` = list("Skykomish River", "Tokul Creek"),
  `District 14` = list("Cascade River", "Sauk River", "Skagit River")
)

#lookup objects created below
load("fw_creel_dash_envi.RData")

creel <- reactiveValues() #will hold resulting data objects ##event = NULL, effort = NULL, interview = NULL, catch = NULL

```

```{r build_envi, eval=FALSE}
# # uncomment to rebuild...
# 
# dates_holidays_2015_2030 <- read_lines("input_files/dates_holidays_2015_2030.txt") |>
#   as.Date(format="%Y-%m-%d")
# 
# # river_loc_all <- list.files("input_files", pattern = "River.Location", full.names = T) |>
# #   set_names() |>
# #   map(readr::read_csv)
# river_loc_all <- readr::read_csv("input_files/river_locations_master.csv")
# 
# #excludes "master"; read_csv("input_files/lut_water_body_location_master_2022_01_28.csv") |> distinct(water_body_desc)
# sections_all <- list.files("input_files", pattern = "lut_water_body_location_", full.names = T)[-8] |>
#   set_names() |>
#   map(readr::read_csv)
# 
# census_expansion_all <- list.files("input_files", pattern = "Proportional", full.names = T) |>
#   set_names() |>
#   map(readr::read_csv)
# 
# #names(river_loc_all) <- tools::file_path_sans_ext(basename(names(river_loc_all)))
# names(sections_all) <- tools::file_path_sans_ext(basename(names(sections_all))) #|> str_remove("lut_water_body_location_")
# names(census_expansion_all) <- tools::file_path_sans_ext(basename(names(census_expansion_all))) #|> str_remove("lut_Proportional_Expansions_for_Tie_In_")
# 
# #save.image("fw_creel_dash_envi.RData")

```


Controls {.sidebar data-width=350}
============================================

###

```{r input_selectors}
selectInput(inputId = 'proj_name', label = 'Project Name', choices = names(proj_levels)
            , selected = "District 14"
            )

selectizeInput(inputId = 'water_body', label = 'Water Body', choices = proj_levels, multiple = TRUE
               , selected = "Cascade River"
               )

dateRangeInput(inputId = 'dates', label = "Date range"
               , start = "2021-09-16", end = "2021-10-16" 
               )


selectInput(inputId = 'sections', label = 'Sections', choices = names(sections_all), multiple = FALSE
            , selected = "lut_water_body_location_d14_cascade_fall_salmon"
            )
# selectInput(inputId = 'river_loc', label = 'River Lat/Lon', choices = names(river_loc_all), multiple = FALSE
#             , selected = "lut_River.Locations_2019-01-07"
#             )
selectInput(inputId = 'census_exp', label = 'Census Expansion LU', choices = names(census_expansion_all), multiple = FALSE
            , selected = "lut_Proportional_Expansions_for_Tie_In_Sections_Cascade_Fall_Salmon_2021"
            )


radioButtons(inputId = 'model_period', label = "Model period", choices = c("Week", "Month")
             , selected = "Week"
             )

radioButtons(inputId = 'index_count_types', label = "Index count types", 
             choices = c("Bank/Boat Anglers", "Vehicle/Trailers Only")
             ,selected = c("Vehicle/Trailers Only")
             )

radioButtons(inputId = 'census_expansion', label = "Census expansion method", 
             choices = c("Direct", "Indirect")
             ,selected = c("Direct")
             )

# #can add option to manually upload ...
# fileInput(inputId = 'sections', label = 'Sections LU', accept = ".csv")

```

###

```{r dwg_fetch}
actionButton("fetch", label = "Fetch raw data")

#fire the requests on button push
#!! note this excludes effort and interview rows
#!! with no section assigned from section LU

# creel <- list()
# input <- list()
# input$proj_name <- "District 14"
# input$water_body <- "Cascade River"
# input$dates <- c(as.Date("2021-09-16", "%Y-%m-%d"), as.Date("2021-10-16", "%Y-%m-%d"))
# input$model_period <- "Week"
# input$index_count_types <- "Vehicle/Trailers Only" #c("Vehicle Only","Trailers Only")
# input$census_expansion <- "Direct"
# 
# input$sections <- "lut_water_body_location_d14_cascade_fall_salmon"
# #input$river_loc <- "lut_River.Locations_2019-01-07"
# input$census_exp <- "lut_Proportional_Expansions_for_Tie_In_Sections_Cascade_Fall_Salmon_2021"
# sections <- dplyr::select(sections_all[[input$sections]], water_body_desc, location = location_code, section)
# #river_loc <- river_loc_all[[input$river_loc]]
# river_loc <- dplyr::filter(river_loc_all, River %in% input$water_body)
# census_exp <- if(str_detect(input$index_count_types, "Vehicle|Trailer")) {
#     census_expansion_all[[input$census_exp]] |>
#       mutate(
#         angler_type = if_else(angler_type == "bank", "total", "boat"),
#         cen_exp_meth = input$census_expansion)
#   } else {
#     census_expansion_all[[input$census_exp]] |> 
#       mutate(cen_exp_meth = input$census_expansion)
#     }


  
sections <- reactive({
  dplyr::select(sections_all[[input$sections]], water_body_desc, location = location_code, section)
})

#!!NOT YET GENERIC TO MULTIPLE WATER_BODY(s) AND ROWS IN MASTER 
#!!ONLY USED IN DAY-LENGTH CALCULATION? WORK AROUND IS JUST SLICE(1)
river_loc <- reactive({
  #river_loc_all[[input$river_loc]]
  dplyr::filter(river_loc_all, River %in% input$water_body)
})

census_exp <- reactive({
  ## fix angler type in census expansion table for use with vehicle / trailer counts so it joins to TI_expan table
  if(str_detect(input$index_count_types, "Vehicle|Trailer")) {
    census_expansion_all[[input$census_exp]] |> 
      mutate(
        angler_type = if_else(angler_type == "bank", "total", "boat"),
        cen_exp_meth = input$census_expansion
        )
  } else {
    census_expansion_all[[input$census_exp]] |> 
      mutate(cen_exp_meth = input$census_expansion)
    }
})

#this is "event reactive", so should not trigger on fiddling with inputs
#but only when "fetch" button is clicked (see last few lines of chunk)
reactive({
  creel$event <- paste0(
    dwg_base$event,
    "?$where=project_name in('", input$proj_name, "')",
    " AND water_body in('", paste0(input$water_body, collapse = "','"), "')",
    " AND event_date between '", input$dates[1],
    "T00:00:00' and '", input$dates[2],
    "T00:00:00'&$limit=100000"
    ) |>
    utils::URLencode() |>
    readr::read_csv(show_col_types = F) |>
    dplyr::select(creel_event_id, water_body, event_date, tie_in_indicator)
  
  if(nrow(creel$event) > 0) {
    
    creel$effort <- paste0(
      dwg_base$effort,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::filter(!is.na(count_type)) |> 
      dplyr::select(-created_datetime, -modified_datetime) |> 
#      dplyr::left_join(sections, by = c("location")) |> 
      dplyr::left_join(sections(), by = c("location")) |> 
      dplyr::filter(!is.na(section))

    creel$interview <- paste0(
      dwg_base$interview,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::rename(location = interview_location) |> 
      dplyr::select(
        -created_datetime, -modified_datetime,
        -state_residence, -zip_code) |> 
#      dplyr::left_join(sections, by = c("location")) |> 
      dplyr::left_join(sections(), by = c("location")) |> 
      dplyr::filter(!is.na(section))
    
    creel$catch <- paste0(
      dwg_base$catch,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::select(interview_id, catch_id, species, run, life_stage, fin_mark, fate, fish_count) |> 
      dplyr::mutate(
        life_stage = replace_na(life_stage, "Adult"), # placeholder pending data corrections in fish apps 
        catch_group = paste(species, life_stage, fin_mark, fate, sep = "_") # fish catch groups to estimate catch of 
      )
    
    ##seems somewhat inefficient to (potentially) rebuild, but takes a reactive dependence on input$dates and river_loc...
    #and this whole chunk depends on button push, so "lazy" against fiddling
    creel$days <- tibble::tibble(
      event_date = seq.Date(input$dates[1], input$dates[2], by = "day"),
      Day = weekdays(event_date),
      DayType = if_else(
        Day == "Saturday" | Day == "Sunday" | Day %in% dates_holidays_2015_2030,
        "Weekend", "Weekday"),
      DayType_num = if_else(str_detect(DayType, "end"),1,0),
      DayL = suncalc::getSunlightTimes(
        date = event_date,
        tz = "America/Los_Angeles",
#         lat = river_loc$Lat,
#         lon = river_loc$Long,
        lat = river_loc()$Lat,
        lon = river_loc()$Long,
        keep=c("dawn", "dusk")
      ) |>
        mutate(DayL = as.numeric(dusk - dawn)) |>
        pluck("DayL"),
      Week = as.numeric(format(event_date, "%V")),
      Month = as.numeric(format(event_date, "%m")),
      ModelPeriod = input$model_period
    ) |>
      tibble::rowid_to_column(var = "day_index") |>
      #make open section cols (only those actually used, not all in LU)
      left_join(
        expand_grid(
          event_date = seq.Date(input$dates[1], input$dates[2], by = "day"),
          s = paste0("open_section_", sort(unique(creel$effort$section))),
          closure_code = TRUE
        ) |>
          pivot_wider(names_from = s, values_from = closure_code)
        ,
        by = "event_date")

    #closures, super ugly, needs rethinking
    creel$days <- rows_upsert(
      creel$days,
      bind_rows(
        # 2022 Upper Skagit Chinook
        # tibble(section = "1", closure_begin = "2021-05-31", closure_end = "2021-05-31")

        # 2021 Skagit winter steelhead closure dates
        # tibble(section = "1,2", closure_begin = "2021-02-03", closure_end = "2021-02-05"),
        # tibble(section = "1,2", closure_begin = "2021-02-10", closure_end = "2021-02-12"),
        # tibble(section = "1,2", closure_begin = "2021-02-17", closure_end = "2021-02-19"),
        # tibble(section = "1,2", closure_begin = "2021-02-24", closure_end = "2021-02-26"),
        # tibble(section = "1,2", closure_begin = "2021-03-03", closure_end = "2021-03-05"),
        # tibble(section = "1,2", closure_begin = "2021-03-10", closure_end = "2021-03-12"),
        # tibble(section = "1,2", closure_begin = "2021-03-17", closure_end = "2021-03-19"),
        # tibble(section = "1,2", closure_begin = "2021-03-24", closure_end = "2021-03-26"),
        # tibble(section = "1,2", closure_begin = "2021-03-31", closure_end = "2021-04-02"),
        # tibble(section = "1,2", closure_begin = "2021-04-07", closure_end = "2021-04-09")
        # tibble(section = "1", closure_begin = "2016-04-30", closure_end = "2016-04-30") # placeholder closure date; need to supply at least one

        # kalama
        # tibble(section = "1,2,3", closure_begin = "2016-04-30", closure_end = "2016-04-30")
        # placeholder closure date; need to supply at least onedate here because we use open / closed dates to determine times_strata estimation periods (field n_days further down in code)

        # Cascade
        tibble(section = "1", closure_begin = "2021-09-18", closure_end = "2021-09-18"), # river out due to flows
        tibble(section = "1", closure_begin = "2021-09-19", closure_end = "2021-09-20"), # treaty fishery closure
        tibble(section = "1", closure_begin = "2021-09-26", closure_end = "2021-09-27"), # treaty fishery closure
        tibble(section = "1", closure_begin = "2021-10-03", closure_end = "2021-10-04"), # treaty fishery closure
        tibble(section = "1", closure_begin = "2021-11-13", closure_end = "2021-11-14"), # river out due to flows
        tibble(section = "1", closure_begin = "2021-11-17", closure_end = "2021-11-18") # river out due to flows

        #other Skagit?
        # tibble(section = "2,3", closure_begin = "2021-08-19", closure_end = "2021-08-31"),
        # tibble(section = "2", closure_begin = "2021-09-01", closure_end = "2021-09-01"), # treaty fishery closure
        # tibble(section = "2", closure_begin = "2021-09-07", closure_end = "2021-09-09"), # treaty fishery closure
        # tibble(section = "2", closure_begin = "2021-09-14", closure_end = "2021-09-16"), # treaty fishery closure
        # tibble(section = "1,2,3", closure_begin = "2021-09-18", closure_end = "2021-09-18"), # river out due to flows
        # tibble(section = "2", closure_begin = "2021-10-05", closure_end = "2021-10-06"), # treaty fishery closure
        # tibble(section = "2", closure_begin = "2021-10-12", closure_end = "2021-10-13"), # treaty fishery closure
        # tibble(section = "2", closure_begin = "2021-10-19", closure_end = "2021-10-20"), # treaty fishery closure
        # tibble(section = "1,2,3", closure_begin = "2021-11-13", closure_end = "2021-11-14"), # river out due to flows
        # tibble(section = "1,2,3", closure_begin = "2021-11-17", closure_end = "2021-11-18") # river out due to flows

        # tibble(section = "3,4,5", closure_begin = "2021-08-19", closure_end = "2021-08-31"),
        # tibble(section = "3", closure_begin = "2021-09-01", closure_end = "2021-09-01"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-09-07", closure_end = "2021-09-09"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-09-14", closure_end = "2021-09-16"), # treaty fishery closure
        # tibble(section = "1,2,3,4,5", closure_begin = "2021-09-18", closure_end = "2021-09-18"), # river out due to flows
        # tibble(section = "3", closure_begin = "2021-10-05", closure_end = "2021-10-06"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-10-12", closure_end = "2021-10-13"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-10-19", closure_end = "2021-10-20"), # treaty fishery closure
        # tibble(section = "1,2,3,4,5", closure_begin = "2021-11-13", closure_end = "2021-11-14"), # river out due to flows
        # tibble(section = "1,2,3,4,5", closure_begin = "2021-11-17", closure_end = "2021-11-18") # river out due to flows
      ) |>
        rowwise() |>
        mutate(closure_date = paste(seq.Date(as.Date(closure_begin), as.Date(closure_end), by = "day"), collapse = ",")) |>
        separate_rows(closure_date, sep = ",") |>
        select(event_date = closure_date, section) |>
        mutate(
          event_date = as.Date(event_date),
          closure_code = FALSE # TB - The 1e-06 is needed to keep the model from crashing ?log-normal parameters cant be 0
        ) |>
        separate_rows(section, sep = ",") |>
        pivot_wider(names_from = section, names_prefix = "open_section_", values_from = closure_code) |>
        mutate(across(starts_with("open_section_"), ~replace_na(., TRUE)))
      ,
      by ="event_date"
    )

  } else {
    creel$effort <- NULL
    creel$interview <- NULL
    creel$catch <- NULL
  }
}) |> 
  bindEvent(input$fetch)
  
```


Data
============================================

```{r eval=FALSE}
# renderPrint(input$proj_name)
# renderPrint(input$water_body)
# renderPrint({paste(input$dates[1], "to", input$dates[2])})
```

Event and Days
--------------------------------------------

### Event

```{r}
render_gt({ head(creel$event) })
```

### Days

```{r}
#renderPrint({str(days)})
render_gt({ head(creel$days) })
```


Effort
--------------------------------------------

### Effort

```{r}
render_gt({ head(creel$effort) })
```

Interview
--------------------------------------------

### Interview

```{r}
render_gt({ head(creel$interview) })
```

Catch
--------------------------------------------

### Catch

```{r}
render_gt({ head(creel$catch) })
```


Effort/Interview
============================================

```{r prep_effort_interview, include = FALSE}
#Aggregate census (tie in) effort counts, associating to closest-in-time index count.
#take the initial effort_census, with all count_sequence == 1,
#add/overwrite the count_sequence val with that from closest temporal match from inline/anonymous paired counts object

#could remove the left_join of days? appears to only be used here for day_index, which used only for stan?
#or leave with idea that an endpoint of this could be objects ready for stan?

pe_effort_census <- reactive({
  dplyr::left_join(
    creel$effort |> 
      dplyr::filter(tie_in_indicator == 1) |>
      dplyr::select(event_date, water_body, water_body_desc, location, section, tie_in_indicator, count_type, count_quantity)
    ,
    #reassign count_seq from closest index
    dplyr::left_join(
      creel$effort |> dplyr::filter(tie_in_indicator == 1) |> dplyr::distinct(event_date, section, location, tie_in_indicator, effort_start_time, count_sequence),
      creel$effort |> dplyr::filter(tie_in_indicator == 0) |> dplyr::distinct(event_date, section, location, tie_in_indicator, effort_start_time, count_sequence),
      by = c("event_date", "section"),
      suffix = c("_cen", "_ind")
      ) |>
      dplyr::group_by(event_date, section, location_cen) |>
      dplyr::slice_min(abs(effort_start_time_cen - effort_start_time_ind), n = 1) |>
      dplyr::ungroup() |>
      dplyr::distinct(event_date, section, location = location_cen, count_sequence = count_sequence_ind)
    ,
    by = c("event_date", "section", "location")
  ) |>
    dplyr::left_join(creel$days, by = "event_date") |>
    dplyr::mutate(
      angler_type = dplyr::case_when(
        stringr::word(count_type, 1) %in% c("Bank","bank","Shore") ~ "bank",
        stringr::word(count_type, 1) %in% c("Boat","boat") ~ "boat" #Note "Boats" plural intentionally excluded
      )
    ) |>
    dplyr::filter(!is.na(angler_type)) |>
    dplyr::group_by(event_date, day_index, section, tie_in_indicator, count_sequence, angler_type) |>
    dplyr::summarize(count_census = sum(count_quantity), .groups = "drop") |>
    dplyr::arrange(event_date, section, count_sequence) |>
    tidyr::drop_na(count_sequence) #-> pe_effort_census
})

#combines several intermediates from CreelPointEstimate_Dev
#mutate here creates a later join-by column
pe_effort_index <- reactive({
  dplyr::filter(
    creel$effort, 
    tie_in_indicator == 0,
    is.na(no_count_reason),
    !is.na(count_type)
    #,count_type %in% input$index_count_types
    ) |>
  dplyr::group_by(event_date, section, count_sequence, count_type) |>
  dplyr::summarise(count_index = sum(count_quantity), .groups = "drop") |>
  dplyr::mutate(
    angler_type = dplyr::case_when(
      count_type == "Boat Anglers" ~ "boat",
      count_type == "Bank Anglers" ~ "bank",
      count_type == "Trailers Only" ~ "boat",
      count_type == "Vehicle Only" ~ "total"
    )
  ) |> 
  dplyr::arrange(event_date, section, count_sequence) #-> pe_effort_index
})

pe_effort_index_daily_mean <- reactive({
  pe_effort_index() |> 
  #pe_effort_index |> 
  dplyr::group_by(event_date, section, angler_type) |>
  dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop") #-> pe_effort_index_daily_mean
})


#interview data have angler_count, vehicle_count, trailer_count, angler_type and boat_used
#Disallow NAs in angler_type, fill missing angler_type from boat_used
#!!Does this actually need row-wise time_strata? and why not just call model_period?
#!!Maintain angler_hours_total filter?
#!!lots of extra cols still at this point...
pe_interview <- reactive({
  left_join(creel$interview, creel$days, by = "event_date") |>
  mutate(
    across(c(vehicle_count, trailer_count), ~replace_na(., 0)),
    trip_status = replace_na(trip_status, "Unknown"),
    
    angler_type = tolower(angler_type),
    angler_type = if_else(is.na(angler_type), boat_used, angler_type),
    angler_type = case_when( 
      angler_type == "boat" ~ "boat", #pass through
      angler_type == "bank" ~ "bank", #pass through
      angler_type == "Unk" ~ "bank",  #Kalama, others?
      angler_type == "No" ~ "bank",   #value from boat_used
      angler_type == "Yes" ~ "boat"   #value from boat_used
      ),
    angler_type_ind = as.integer(factor(angler_type)),
    
    fishing_end_time = if_else(
      trip_status == "Incomplete" | is.na(fishing_end_time),
      interview_time,
      fishing_end_time),
    angler_hours = round(as.numeric(fishing_end_time - fishing_start_time) / 3600, 5),
    angler_hours_total = angler_count * angler_hours,
    time_strata = input$model_period
  ) |>
  filter(angler_hours_total >= 0.5) #-> pe_interview
})
```


```{r eval = FALSE}

#!!DA START HERE
#!!and from L782 in CreelPointEstimate_Dev
#!!but note conditional continues/extends at L824-941 and L941-1067
if(str_detect(input$index_count_types, "Bank|Boat")) {
  
  daily_effort_estimates <- left_join(
    pe_effort_index_daily_mean, 
    select(creel$days, event_date, DayL),
    by = "event_date") |> 
    mutate(mean_daily_effort = DayL * count_index_mean) |>
    arrange(event_date, section)

##STILL CLEANING... 

# left join index effort counts to census counts 
census_counts_all <- left_join(
  pe_effort_census, #grouped & summed by event_date, day_index, section, tie_in_indicator, count_sequence, angler_type [bank, boat]
  pe_effort_index, #grouped & summed by event_date, section, count_sequence, count_type [Bank Ang, Boat Ang, Vehic, Trailr] and derived angler_type [bank, boat, total])
  by = c("event_date", "section", "count_sequence","angler_type")
  ) |>
  mutate(
    count_index = replace_na(count_index, 0),
    TI_expan = count_census / count_index,
    TI_expan = if_else(is.infinite(TI_expan) | is.nan(TI_expan), NA_real_, TI_expan)
  ) |> 
  group_by(section, angler_type) |> 
  summarise(
    TI_expan_mean = mean(TI_expan, na.rm=TRUE),
    TI_expan_weighted = sum(count_census) / sum(count_index),
    across(
      c(TI_expan_mean, TI_expan_weighted),
      ~if_else(. == 0, 1, .) |> replace_na(1)
    ),
    .groups = "drop"
  ) |> 
  left_join(
    select(census_exp, cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
    by = c("angler_type", "section")
  ) |>
  mutate(
    #dealing with e.g. Cascade edge case of nothing to join for an angler_type/section
    #should really be addressed in the Prop_Expansion table...
    cen_exp_meth = replace_na(cen_exp_meth, input$census_expansion),
    p_TI = replace_na(p_TI, 1),
    TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
    TI_expan_final = if_else(
      cen_exp_meth == "Direct" | is.na(cen_exp_meth),
      TI_expan_weighted / p_TI,
      TI_expan_indirect)
  )

  # join census (tie in) counts to index counts 
  # calculate mean daily effort multipled by bias term (tie in ratio) from census counts
effort_interviews_final <- daily_effort_estimates |>
  left_join(census_counts_all, by = c("section", "angler_type")) |>
  mutate(
    TI_expan_final = if_else(is.na(TI_expan_final), 1, TI_expan_final) 
    ,
    mean_daily_TI_expan = mean_daily_effort * TI_expan_final
  )  |>
  select(section, event_date, angler_type, mean_daily_TI_expan) |> 
  right_join(days_join, by = c("section", "event_date", "angler_type")) |>
  mutate(
    creeled = if_else(!is.na(mean_daily_TI_expan) & open_section_1 == TRUE, "Y", "N")
  ) |> 
  arrange(event_date)

  
} else {
  if(str_detect(input$index_count_types, "Vehicle|Trailer")) { 

    #anglers_per_vehicle from day-section totals amount to arith mean of multiple interviews?
    #presumably this blows up if sum(vehicle_count)==0
    angler_data_from_interviews <- bind_rows(
      pe_interview |>
        group_by(event_date, section) |> 
        summarize(
          angler_hours_total = sum(angler_hours_total),
          anglers_per_vehicle = sum(angler_count) / sum(vehicle_count),
          #anglers_per_index_count_from_interview = daily_sum_angler / daily_sum_index_count_from_interview,
          angler_type = "total",
          .groups = "drop")
      ,
      pe_interview |> 
        filter(angler_type == "boat") |>
        group_by(event_date, section) |> 
        summarize(
          angler_hours_total = sum(angler_hours_total),
          anglers_per_vehicle = sum(angler_count) / sum(vehicle_count),
          angler_type = "boat",
          .groups = "drop")
    ) 
    
    daily_effort_estimates <- angler_data_from_interviews  |>
      left_join(pe_effort_index_daily_mean, by = c("event_date", "section", "angler_type")) |>
      left_join(select(creel$days, event_date, DayL), by = "event_date") |> 
      mutate(
        #mean_daily_effort = DayL * anglers_per_index_count_from_interview * count_index_mean
        mean_daily_effort = DayL * anglers_per_vehicle * count_index_mean
        ) |>
      arrange(event_date, section) |> 
      filter(!is.na(mean_index_count)) #EB: circle back on this 
    

    #join index counts to census
    census_counts_all <- left_join(
      #census already grouped & summed by event_date, day_index, section, tie_in_indicator, count_sequence, angler_type [bank, boat]
      #but here split, collapse and then reassign angler_type to total & boat
      bind_rows(
        pe_effort_census |> 
          group_by(event_date, section, count_sequence) |> 
          summarize(count_census = sum(count_census), angler_type = "total", .groups = "drop")
        ,
        pe_effort_census |> 
          filter(angler_type == "boat") |>
          group_by(event_date, section, count_sequence) |> 
          summarize(count_census = sum(count_census), angler_type = "boat", .groups = "drop")
      )
      ,
      #index via interviews with angler_type [total, boat]
      #using ang/vehicle from interview to expand index counts of vehicles
      #most likely an expanding join since interview is already per day-section here but effort_index is per count_seq (per day-section)
      #correct for this to be left_ rather than full/inner?
      left_join(
        angler_data_from_interviews,
        pe_effort_index, #|> select(-count_type), 
        by = c("event_date", "section", "angler_type")
        ) |> 
        mutate(count_index = anglers_per_vehicle * count_index) |> 
        select(event_date, section, count_sequence, angler_type, count_index)
      ,
      by = c("event_date", "section", "count_sequence", "angler_type")
      ) |>
      mutate(
        count_index = replace_na(count_index, 0),
        TI_expan = count_census / count_index,
        TI_expan = if_else(is.infinite(TI_expan) | is.nan(TI_expan), NA_real_, TI_expan)
      ) |> 
      group_by(section, angler_type) |> 
      summarise(
        TI_expan_mean = mean(TI_expan, na.rm=TRUE),
        TI_expan_weighted = sum(count_census) / sum(count_index),
        across(
          c(TI_expan_mean, TI_expan_weighted),
          ~if_else(. == 0, 1, .) |> replace_na(1)
          ),
        .groups = "drop"
      ) |> 
      left_join(
        select(census_exp, cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
        by = c("angler_type", "section")
        ) |>
      mutate(
        #dealing with e.g. Cascade edge case of nothing to join for an angler_type/section
        #should really be addressed in the Prop_Expansion table...
        cen_exp_meth = replace_na(cen_exp_meth, input$census_expansion),
        p_TI = replace_na(p_TI, 1),
        TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
        TI_expan_final = if_else(
          cen_exp_meth == "Direct" | is.na(cen_exp_meth),
          TI_expan_weighted / p_TI,
          TI_expan_indirect)
      )
    
##!! DA HERE 4/25 to finish Vehicle/Trailer only clause
# join census (tie in) counts to index counts 

# calculate mean daily effort multipled by bias term (tie in ratio) from census counts
effort_interviews_totalandboat <- daily_effort_estimates |>
  ungroup() |> 
  left_join(census_counts_all, by = c("section", "angler_type")) |> 
  # select(-c(time_strata)) |> 
  mutate(
    mean_daily_TI_expan = mean_daily_effort * TI_expan_final
  ) 

# subtract boat effort from the total effort to estimate bank effort. 

effort_interviews_bank_1 <- effort_interviews_totalandboat |>
  select(section, event_date, angler_type, mean_daily_TI_expan) |>
  pivot_wider(names_from = angler_type, values_from = mean_daily_TI_expan, values_fill = 0) |>
  mutate(
    mean_daily_TI_expan_bank = total - boat
  )
  
# joining estimated bank effort to initial table with total and boat hours and then using distinct call to filter to only the newly derived bank hours while retaining the other table data needed to bind this data back to the initial dataset 
effort_interviews_bank_2 <- effort_interviews_totalandboat |>
  left_join(effort_interviews_bank_1, by = c("section", "event_date")) |>
  distinct(section, event_date, mean_daily_TI_expan_bank, .keep_all = TRUE) |>
  mutate(
    angler_type = "bank"
  ) |>
  select(-c(mean_daily_TI_expan, total, boat)) |>
  rename(
    mean_daily_TI_expan = mean_daily_TI_expan_bank
  )

# Binding the bank hours back to the initial table
effort_interviews_final <- effort_interviews_totalandboat |> 
  bind_rows(effort_interviews_bank_2) |> 
  ungroup() |> 
  # right_join(days_join, by = c("section", "event_date", "angler_type")) |> 
  right_join(days_join) |> 
  mutate(
    creeled = if_else(!is.na(mean_daily_TI_expan), "Y", "N")
  ) |> 
  arrange(event_date)
    
  }
}


#kalama
days_join <- creel$days |>
  select(event_date, DayType, Month, Week, ModelPeriod, open_section_1) |>
  mutate(
    time_strata = if_else(ModelPeriod == "Month", Month, Week),
    at_1 = "bank", at_2 = "boat"
  ) |>
  pivot_longer(cols = c(at_1,at_2), values_to = "angler_type") |>
  select(-name) |>
  mutate(s1 = 1, s2 = 2, s3 = 3
  ) |>
  pivot_longer(cols = c(s1,s2,s3), values_to = "section") |>
  select(-name)
# Skagit winter steelhead 2021
# point_estimate_data_prelim$days_join <- d_days |> 
#   select(event_date, DayType, Month, Week, ModelPeriod, open_section_1) |> 
#   mutate(
#     time_strata = if_else(ModelPeriod == "Month", Month, Week),
#     at_1 = "bank", at_2 = "boat", at_3 = "total"
#   ) |> 
#   pivot_longer(cols = c(at_1,at_2,at_3), values_to = "angler_type") |> 
#   select(-name) |> 
#   mutate(s1 = 1, s2 = 2
#   ) |> 
#   pivot_longer(cols = c(s1,s2), values_to = "section") |> 
#   select(-name)



####
### TEMP FROM CPE_DEV ###
####
if(str_detect(index_count_types, c("Bank Anglers", "Boat Anglers"))) {

point_estimate_data_prelim$Daily_effort_per_count_groups <- point_estimate_data_prelim$Daily_effort_per_count_index_counts |>
  left_join(d_days, by = "event_date") |> 
  mutate(
    angler_type = if_else(count_type == "Boat Anglers", "boat", "bank")
  ) |> 
  select(-count_type) 
  
# index count derived estimates of angler counts

point_estimate_data_prelim$effort_counts_for_census_join <- point_estimate_data_prelim$Daily_effort_per_count_groups |> 
  rename(index_count =  sum_index_count) |> 
  select(event_date, section, DayL, count_sequence, angler_type, index_count)
  
# left join effort counts to census counts 

# calculate boat anglers counted per census count
point_estimate_data_prelim$census_counts_both_types <- point_estimate_data_prelim$effort_census |>
  group_by(event_date, section, angler_type, day_index, count_sequence) |> 
  summarize(
    count_quantity = sum(count_quantity)
  )


point_estimate_data_prelim$census_counts_all <- point_estimate_data_prelim$census_counts_both_types |> 
   select(
    event_date, section, count_sequence, 
    census_count = count_quantity, angler_type
  ) |> 
  left_join(point_estimate_data_prelim$effort_counts_for_census_join, by = c("event_date", "section", "count_sequence","angler_type")) |>
  mutate(
  index_count = replace_na(index_count, 0), #skagit salmon fall fix, check against bank / boat index counts 
  TI_expan = census_count / index_count,
  TI_expan = ifelse(!is.infinite(TI_expan), TI_expan, NA),
  TI_expan = ifelse(!is.nan(TI_expan), TI_expan, NA)) |> 
  filter(!is.nan(TI_expan)) |> 
  group_by(section, angler_type) |> 
  summarise(
    sum_census_anglers = sum(census_count),
    sum_index_anglers = sum(index_count),
    TI_expan_mean = mean(TI_expan, na.rm=TRUE),
    TI_expan_weighted = sum(census_count) / sum(index_count)) |> 
  mutate(
    TI_expan_weighted = if_else(TI_expan_weighted == 0, 1, TI_expan_weighted),
    TI_expan_mean = if_else(TI_expan_mean == 0, 1, TI_expan_mean)
  ) |> 
  left_join(lut$census_expansion, by = c("angler_type", "section")) |>
  rename(TI_expan_indirect = Indirect_TI_Expan) |> 
  mutate(
    census_expansion_method = params$census_expansion,
    TI_expan_mean = replace_na(TI_expan_mean, 1),
    TI_expan_weighted = replace_na(TI_expan_weighted, 1),
    TI_expan_direct = TI_expan_weighted / p_TI) |> 
  mutate(
    TI_expan_final = ifelse(census_expansion_method == "direct", TI_expan_direct, TI_expan_indirect)
  ) 


# join census (tie in) counts to index counts 

# calculate mean daily effort multipled by bias term (tie in ratio) from census counts

point_estimate_data_prelim$effort_interviews_bank_boat <- point_estimate_data_prelim$daily_effort_estimates |>
  ungroup() |> 
  left_join(point_estimate_data_prelim$census_counts_all, by = c("section", "angler_type")) |>
  mutate(
    TI_expan_final = if_else(is.na(TI_expan_final), 1, TI_expan_final) 
  ) |> 
  mutate(
    mean_daily_TI_expan = mean_daily_effort * TI_expan_final
  ) 


point_estimate_data_prelim$effort_interviews_final <- point_estimate_data_prelim$effort_interviews_bank_boat |>
  select(section, event_date, angler_type, mean_daily_TI_expan) |> 
  right_join(point_estimate_data_prelim$days_join, by = c("section", "event_date", "angler_type")) |>
  mutate(
    creeled = if_else(!is.na(mean_daily_TI_expan) & open_section_1 == TRUE, "Y", "N")
  ) |> 
  arrange(event_date)
  
  
      }else{
      if(str_detect(index_count_types, c("Vehicle Only", "Trailers Only"))){
        
point_estimate_data_prelim$Daily_effort_per_count_groups <- point_estimate_data_prelim$Daily_effort_per_count_index_counts |>
  mutate(
    angler_type = if_else(count_type == "Trailers Only", "boat", "total")
  ) |> 
  select(-count_type) 
  
# index count derived estimates of angler counts

point_estimate_data_prelim$effort_counts_for_census_join <- point_estimate_data_prelim$angler_data_from_interviews |> 
  left_join(point_estimate_data_prelim$Daily_effort_per_count_groups, by = c("event_date", "section", "angler_type")) |> 
  mutate(
    index_count = anglers_per_index_count_from_interview * sum_index_count
  ) |> 
  ungroup() |> 
  select(event_date, section, count_sequence, angler_type, index_count)
  
# left join effort counts to census counts 

# calculate total anglers counted per census count (boat + bank anglers) 
point_estimate_data_prelim$census_counts_total <- point_estimate_data_prelim$effort_census |> 
  group_by(event_date, section, count_sequence) |> 
  summarize(count_quantity = sum(count_quantity)) |>
  mutate(angler_type = "total")

# calculate boat anglers counted per census count
point_estimate_data_prelim$census_counts_boat <- point_estimate_data_prelim$effort_census |>
  filter(angler_type == "boat") |>
  group_by(event_date, section, count_sequence) |>
  summarize(count_quantity = sum(count_quantity)) |>
  mutate(angler_type = "boat")
    
# Bind these together so we have categories for 1) total hours to match with anglers per vehicle and 2) boat hours to match with anglers per trailer 
# calculate bias term ratios (ratio of census counts to angler count estimates from index counts)
# as-is using data grouped by section; needt to add functionality for census data collected at finer spatial / temporal scales


point_estimate_data_prelim$census_counts_all  <-  
  bind_rows(
    point_estimate_data_prelim$census_counts_total,
    point_estimate_data_prelim$census_counts_boat
    ) |> 
   select(
    event_date, section, count_sequence, 
    census_count = count_quantity, angler_type
  ) |> 
  left_join(point_estimate_data_prelim$effort_counts_for_census_join, by = c("event_date", "section", "count_sequence","angler_type")) |>
  mutate(
  index_count = replace_na(index_count, 0), #skagit salmon fall fix, check against bank / boat index counts 
  TI_expan = census_count / index_count,
  TI_expan = ifelse(!is.infinite(TI_expan), TI_expan, NA),
  TI_expan = ifelse(!is.nan(TI_expan), TI_expan, NA)) |> 
  filter(!is.nan(TI_expan)) |> 
  group_by(section, angler_type) |> 
  summarise(
    sum_census_anglers = sum(census_count),
    sum_index_anglers = sum(index_count),
    TI_expan_mean = mean(TI_expan, na.rm=TRUE),
    TI_expan_weighted = sum(census_count) / sum(index_count)) |> 
  mutate(
    TI_expan_weighted = if_else(TI_expan_weighted == 0, 1, TI_expan_weighted),
    TI_expan_mean = if_else(TI_expan_mean == 0, 1, TI_expan_mean)
  ) |> 
  left_join(lut$census_expansion, by = c("angler_type", "section")) |>
  rename(TI_expan_indirect = Indirect_TI_Expan) |> 
  mutate(
    census_expansion_method = params$census_expansion,
    TI_expan_mean = replace_na(TI_expan_mean, 1),
    TI_expan_weighted = replace_na(TI_expan_weighted, 1),
    TI_expan_direct = TI_expan_weighted / p_TI) |> 
  mutate(
    TI_expan_final = ifelse(census_expansion_method == "direct", TI_expan_direct, TI_expan_indirect)
  ) 


# join census (tie in) counts to index counts 

# calculate mean daily effort multipled by bias term (tie in ratio) from census counts
point_estimate_data_prelim$effort_interviews_totalandboat <- point_estimate_data_prelim$daily_effort_estimates |>
  ungroup() |> 
  left_join(point_estimate_data_prelim$census_counts_all, by = c("section", "angler_type")) |> 
  # select(-c(time_strata)) |> 
  mutate(
    mean_daily_TI_expan = mean_daily_effort * TI_expan_final
  ) 

# subtract boat effort from the total effort to estimate bank effort. 

point_estimate_data_prelim$effort_interviews_bank_1 <- point_estimate_data_prelim$effort_interviews_totalandboat |>
  select(section, event_date, angler_type, mean_daily_TI_expan) |>
  pivot_wider(names_from = angler_type, values_from = mean_daily_TI_expan, values_fill = 0) |>
  mutate(
    mean_daily_TI_expan_bank = total - boat
  )
  
# joining estimated bank effort to initial table with total and boat hours and then using distinct call to filter to only the newly derived bank hours while retaining the other table data needed to bind this data back to the initial dataset 
point_estimate_data_prelim$effort_interviews_bank_2 <- point_estimate_data_prelim$effort_interviews_totalandboat |>
  left_join(point_estimate_data_prelim$effort_interviews_bank_1, by = c("section", "event_date")) |>
  distinct(section, event_date, mean_daily_TI_expan_bank, .keep_all = TRUE) |>
  mutate(
    angler_type = "bank"
  ) |>
  select(-c(mean_daily_TI_expan, total, boat)) |>
  rename(
    mean_daily_TI_expan = mean_daily_TI_expan_bank
  )

# Binding the bank hours back to the initial table
point_estimate_data_prelim$effort_interviews_final <- point_estimate_data_prelim$effort_interviews_totalandboat |> 
  bind_rows(point_estimate_data_prelim$effort_interviews_bank_2) |> 
  ungroup() |> 
  # right_join(days_join, by = c("section", "event_date", "angler_type")) |> 
  right_join(point_estimate_data_prelim$days_join) |> 
  mutate(
    creeled = if_else(!is.na(mean_daily_TI_expan), "Y", "N")
  ) |> 
  arrange(event_date)
      }
      }


```


### Index counts

```{r}
#renderPrint({str(creel$effort)})

# renderPlot({
#   if(!is.null(creel$effort)) {
#     creel$effort |>
#       group_by(tie_in_indicator, section, event_date) |>
#       summarise(count_quantity = sum(count_quantity), .groups = "drop") |>
#       ggplot(aes(event_date, count_quantity, fill = section)) +
#       geom_col() +
#       facet_wrap(~tie_in_indicator, scales = "free")
#   }
# })

#renderPrint({str(pe_effort_census())})

renderPlot({
  if(!is.null(creel$effort)) {
    pe_effort_index() |>
      ggplot(aes(event_date, count_quantity, fill = factor(count_sequence))) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + count_type, scales = "free")
  }
})

```

### Index daily mean

```{r}
renderPlot({
  if(!is.null(creel$effort)) {
    pe_effort_index_daily_mean() |>
      ggplot(aes(event_date, count_quantity, fill = count_type)) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + count_type, scales = "free")
  }
})

```

Interview
--------------------------------------------

### Interview

```{r}
renderPlot({
  if(!is.null(creel$interview)) {
    pe_interview() |>
      ggplot(aes(event_date, angler_hours_total, fill = angler_type)) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + angler_type, scales = "free")
  }
})

```

### Interview

```{r}
renderPlot({
  if(!is.null(creel$interview)) {
    pe_interview() |>
      ggplot(aes(angler_count, angler_hours_total, fill = angler_type)) +
      geom_point(position = position_dodge()) +
      facet_wrap(~section + angler_type, scales = "free")
  }
})

```

Catch
============================================


About
============================================

Anything to cite/link to?

WDFW gathers fishing information from anglers around the state:
(https://wdfw.wa.gov/fishing/reports/creel)[https://wdfw.wa.gov/fishing/reports/creel]
