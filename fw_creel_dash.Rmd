---
title: "FW Creel Point Estimate"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    source_code: embed
    theme:
      version: 4
      bootswatch: default
      bg: "#D0D0D0"
      fg: "#000000"
      navbar-bg: "#1189D9"
      primary: "#1189D9"
runtime: shiny
---

```{r setup, include=FALSE}
#bslib::bs_themer()

library("flexdashboard")
library("tidyverse")
library("shiny")
library("patchwork")
library("gt")

#base endpoints
dwg_base <- list(
  event = "https://data.wa.gov/resource/ui95-axtn.csv",
  effort = "https://data.wa.gov/resource/h9a6-g38s.csv",
  interview = "https://data.wa.gov/resource/rpax-ahqm.csv",
  catch = "https://data.wa.gov/resource/6y4e-8ftk.csv",
  gear = "https://data.wa.gov/resource/d2ks-afhz.csv" #currently unused?
)

#water_body options by proj_name options
proj_levels <- list(
  `R5 Steelhead` = list("Kalama River"),
  `District 13` = list("Skykomish River", "Tokul Creek"),
  `District 14` = list("Cascade River", "Sauk River", "Skagit River")
)

#lookup objects created below
load("fw_creel_dash_envi.RData")

creel <- reactiveValues() #will hold resulting data objects ##event = NULL, effort = NULL, interview = NULL, catch = NULL

```

```{r build_envi, eval=FALSE}
# # uncomment to rebuild...
# 
# dates_holidays_2015_2030 <- read_lines("input_files/dates_holidays_2015_2030.txt") |>
#   as.Date(format="%Y-%m-%d")
# 
# # river_loc_all <- list.files("input_files", pattern = "River.Location", full.names = T) |>
# #   set_names() |>
# #   map(readr::read_csv)
# river_loc_all <- readr::read_csv("input_files/river_locations_master.csv")
# 
# #excludes "master"; read_csv("input_files/lut_water_body_location_master_2022_01_28.csv") |> distinct(water_body_desc)
# sections_all <- list.files("input_files", pattern = "lut_water_body_location_", full.names = T)[-8] |>
#   set_names() |>
#   map(readr::read_csv)
# 
# census_expansion_all <- list.files("input_files", pattern = "Proportional", full.names = T) |>
#   set_names() |>
#   map(readr::read_csv)
# 
# #names(river_loc_all) <- tools::file_path_sans_ext(basename(names(river_loc_all)))
# names(sections_all) <- tools::file_path_sans_ext(basename(names(sections_all))) #|> str_remove("lut_water_body_location_")
# names(census_expansion_all) <- tools::file_path_sans_ext(basename(names(census_expansion_all))) #|> str_remove("lut_Proportional_Expansions_for_Tie_In_")
# 
# #save.image("fw_creel_dash_envi.RData")

```


Controls {.sidebar data-width=350}
============================================

###

```{r input_selectors}
selectInput(inputId = 'proj_name', label = 'Project Name', choices = names(proj_levels)
            , selected = "District 14"
            )

selectizeInput(inputId = 'water_body', label = 'Water Body', choices = proj_levels, multiple = TRUE
               , selected = "Cascade River"
               )

dateRangeInput(inputId = 'dates', label = "Date range"
               , start = "2021-09-16", end = "2021-10-16" 
               )


selectInput(inputId = 'sections', label = 'Sections', choices = names(sections_all), multiple = FALSE
            , selected = "lut_water_body_location_d14_cascade_fall_salmon"
            )
selectInput(inputId = 'river_loc', label = 'River Lat/Lon', choices = names(river_loc_all), multiple = FALSE
            , selected = "lut_River.Locations_2019-01-07"
            )
selectInput(inputId = 'census_exp', label = 'Census Expansion', choices = names(census_expansion_all), multiple = FALSE
            , selected = "lut_Proportional_Expansions_for_Tie_In_Sections_Cascade_Fall_Salmon_2021"
            )


radioButtons(inputId = 'model_period', label = "Model period", choices = c("Week", "Month")
             , selected = "Week"
             )

checkboxGroupInput(inputId = 'index_count_types', label = "Index count types", 
             choices = c(
               "Bank Anglers","Boat Anglers",
                "Vehicle Only","Trailers Only"),
             selected = c("Vehicle Only","Trailers Only")
             )


# #can add option to manually upload ...
# fileInput(inputId = 'sections', label = 'Sections LU', accept = ".csv")

```

###

```{r dwg_fetch}
actionButton("fetch", label = "Fetch raw data")

#fire the requests on button push
#!! note this excludes effort and interview rows
#!! with no section assigned from section LU

# creel <- list()
# input <- list()
# input$proj_name <- "District 14"
# input$water_body <- "Cascade River"
# input$dates <- c(as.Date("2021-09-16", "%Y-%m-%d"), as.Date("2021-10-16", "%Y-%m-%d"))
# 
# input$sections <- "lut_water_body_location_d14_cascade_fall_salmon"
# input$river_loc <- "lut_River.Locations_2019-01-07"
# input$census_exp <- "lut_Proportional_Expansions_for_Tie_In_Sections_Cascade_Fall_Salmon_2021"
# sections <- dplyr::select(sections_all[[input$sections]], water_body_desc, location = location_code, section)
# river_loc <- river_loc_all[[input$river_loc]]
# census_exp <- census_expansion_all[[input$census_exp]]

# input$model_period <- "Week"
# input$index_count_types <- c("Vehicle Only","Trailers Only")

  
sections <- reactive({
  dplyr::select(sections_all[[input$sections]], water_body_desc, location = location_code, section)
})

river_loc <- reactive({
  #river_loc_all[[input$river_loc]]
  dplyr::filter(river_loc_all, River %in% input$water_body)
    
})

census_exp <- reactive({
  census_expansion_all[[input$census_exp]]
})

#this is "event reactive", so should not trigger on fiddling with inputs
#but only when "fetch" button is clicked (see last few lines of chunk)
reactive({
  creel$event <- paste0(
    dwg_base$event,
    "?$where=project_name in('", input$proj_name, "')",
    " AND water_body in('", paste0(input$water_body, collapse = "','"), "')",
    " AND event_date between '", input$dates[1],
    "T00:00:00' and '", input$dates[2],
    "T00:00:00'&$limit=100000"
    ) |>
    utils::URLencode() |>
    readr::read_csv(show_col_types = F) |>
    dplyr::select(creel_event_id, water_body, event_date, tie_in_indicator)
  
  if(nrow(creel$event) > 0) {
    
    creel$effort <- paste0(
      dwg_base$effort,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::filter(!is.na(count_type)) |> 
      dplyr::select(-created_datetime, -modified_datetime) |> 
      # dplyr::left_join(sections, by = c("location")) |> 
      dplyr::left_join(sections(), by = c("location")) |> 
      dplyr::filter(!is.na(section))

    creel$interview <- paste0(
      dwg_base$interview,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::rename(location = interview_location) |> 
      dplyr::select(
        -created_datetime, -modified_datetime,
        -state_residence, -zip_code) |> 
      # dplyr::left_join(sections, by = c("location")) |> 
      dplyr::left_join(sections(), by = c("location")) |> 
      dplyr::filter(!is.na(section))
    
    creel$catch <- paste0(
      dwg_base$catch,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::select(interview_id, catch_id, species, run, life_stage, fin_mark, fate, fish_count) |> 
      dplyr::mutate(
        life_stage = replace_na(life_stage, "Adult"), # placeholder pending data corrections in fish apps 
        catch_group = paste(species, life_stage, fin_mark, fate, sep = "_") # fish catch groups to estimate catch of 
      )
    
    ##seems somewhat inefficient to (potentially) rebuild, but takes a reactive dependence on input$dates and river_loc...
    #and this whole chunk depends on button push, so "lazy" against fiddling
    creel$days <- tibble::tibble(
      event_date = seq.Date(input$dates[1], input$dates[2], by = "day"),
      Day = weekdays(event_date),
      DayType = if_else(
        Day == "Saturday" | Day == "Sunday" | Day %in% dates_holidays_2015_2030,
        "Weekend", "Weekday"),
      DayType_num = if_else(str_detect(DayType, "end"),1,0),
      DayL = suncalc::getSunlightTimes(
        date = event_date,
        tz = "America/Los_Angeles",
        # lat = river_loc$Lat,
        # lon = river_loc$Long,
        lat = river_loc()$Lat,
        lon = river_loc()$Long,
        keep=c("dawn", "dusk")
      ) |>
        mutate(DayL = as.numeric(dusk - dawn)) |>
        pluck("DayL"),
      Week = as.numeric(format(event_date, "%V")),
      Month = as.numeric(format(event_date, "%m")),
      ModelPeriod = input$model_period
    ) |>
      tibble::rowid_to_column(var = "day_index") |>
      #make open section cols (only those actually used, not all in LU)
      left_join(
        expand_grid(
          event_date = seq.Date(input$dates[1], input$dates[2], by = "day"),
          s = paste0("open_section_", sort(unique(creel$effort$section))),
          closure_code = TRUE
        ) |>
          pivot_wider(names_from = s, values_from = closure_code)
        ,
        by = "event_date")

    #closures, super ugly, needs rethinking
    creel$days <- rows_upsert(
      creel$days,
      bind_rows(
        # 2022 Upper Skagit Chinook
        # tibble(section = "1", closure_begin = "2021-05-31", closure_end = "2021-05-31")

        # 2021 Skagit winter steelhead closure dates
        # tibble(section = "1,2", closure_begin = "2021-02-03", closure_end = "2021-02-05"),
        # tibble(section = "1,2", closure_begin = "2021-02-10", closure_end = "2021-02-12"),
        # tibble(section = "1,2", closure_begin = "2021-02-17", closure_end = "2021-02-19"),
        # tibble(section = "1,2", closure_begin = "2021-02-24", closure_end = "2021-02-26"),
        # tibble(section = "1,2", closure_begin = "2021-03-03", closure_end = "2021-03-05"),
        # tibble(section = "1,2", closure_begin = "2021-03-10", closure_end = "2021-03-12"),
        # tibble(section = "1,2", closure_begin = "2021-03-17", closure_end = "2021-03-19"),
        # tibble(section = "1,2", closure_begin = "2021-03-24", closure_end = "2021-03-26"),
        # tibble(section = "1,2", closure_begin = "2021-03-31", closure_end = "2021-04-02"),
        # tibble(section = "1,2", closure_begin = "2021-04-07", closure_end = "2021-04-09")
        # tibble(section = "1", closure_begin = "2016-04-30", closure_end = "2016-04-30") # placeholder closure date; need to supply at least one

        # kalama
        # tibble(section = "1,2,3", closure_begin = "2016-04-30", closure_end = "2016-04-30")
        # placeholder closure date; need to supply at least onedate here because we use open / closed dates to determine times_strata estimation periods (field n_days further down in code)

        # Cascade
        tibble(section = "1", closure_begin = "2021-09-18", closure_end = "2021-09-18"), # river out due to flows
        tibble(section = "1", closure_begin = "2021-09-19", closure_end = "2021-09-20"), # treaty fishery closure
        tibble(section = "1", closure_begin = "2021-09-26", closure_end = "2021-09-27"), # treaty fishery closure
        tibble(section = "1", closure_begin = "2021-10-03", closure_end = "2021-10-04"), # treaty fishery closure
        tibble(section = "1", closure_begin = "2021-11-13", closure_end = "2021-11-14"), # river out due to flows
        tibble(section = "1", closure_begin = "2021-11-17", closure_end = "2021-11-18") # river out due to flows

        #other Skagit?
        # tibble(section = "2,3", closure_begin = "2021-08-19", closure_end = "2021-08-31"),
        # tibble(section = "2", closure_begin = "2021-09-01", closure_end = "2021-09-01"), # treaty fishery closure
        # tibble(section = "2", closure_begin = "2021-09-07", closure_end = "2021-09-09"), # treaty fishery closure
        # tibble(section = "2", closure_begin = "2021-09-14", closure_end = "2021-09-16"), # treaty fishery closure
        # tibble(section = "1,2,3", closure_begin = "2021-09-18", closure_end = "2021-09-18"), # river out due to flows
        # tibble(section = "2", closure_begin = "2021-10-05", closure_end = "2021-10-06"), # treaty fishery closure
        # tibble(section = "2", closure_begin = "2021-10-12", closure_end = "2021-10-13"), # treaty fishery closure
        # tibble(section = "2", closure_begin = "2021-10-19", closure_end = "2021-10-20"), # treaty fishery closure
        # tibble(section = "1,2,3", closure_begin = "2021-11-13", closure_end = "2021-11-14"), # river out due to flows
        # tibble(section = "1,2,3", closure_begin = "2021-11-17", closure_end = "2021-11-18") # river out due to flows

        # tibble(section = "3,4,5", closure_begin = "2021-08-19", closure_end = "2021-08-31"),
        # tibble(section = "3", closure_begin = "2021-09-01", closure_end = "2021-09-01"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-09-07", closure_end = "2021-09-09"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-09-14", closure_end = "2021-09-16"), # treaty fishery closure
        # tibble(section = "1,2,3,4,5", closure_begin = "2021-09-18", closure_end = "2021-09-18"), # river out due to flows
        # tibble(section = "3", closure_begin = "2021-10-05", closure_end = "2021-10-06"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-10-12", closure_end = "2021-10-13"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-10-19", closure_end = "2021-10-20"), # treaty fishery closure
        # tibble(section = "1,2,3,4,5", closure_begin = "2021-11-13", closure_end = "2021-11-14"), # river out due to flows
        # tibble(section = "1,2,3,4,5", closure_begin = "2021-11-17", closure_end = "2021-11-18") # river out due to flows
      ) |>
        rowwise() |>
        mutate(closure_date = paste(seq.Date(as.Date(closure_begin), as.Date(closure_end), by = "day"), collapse = ",")) |>
        separate_rows(closure_date, sep = ",") |>
        select(event_date = closure_date, section) |>
        mutate(
          event_date = as.Date(event_date),
          closure_code = FALSE # TB - The 1e-06 is needed to keep the model from crashing ?log-normal parameters cant be 0
        ) |>
        separate_rows(section, sep = ",") |>
        pivot_wider(names_from = section, names_prefix = "open_section_", values_from = closure_code) |>
        mutate(across(starts_with("open_section_"), ~replace_na(., TRUE)))
      ,
      by ="event_date"
    )

  } else {
    creel$effort <- NULL
    creel$interview <- NULL
    creel$catch <- NULL
  }
}) |> 
  bindEvent(input$fetch)
  
```


Data
============================================

```{r eval=FALSE}
# renderPrint(input$proj_name)
# renderPrint(input$water_body)
# renderPrint({paste(input$dates[1], "to", input$dates[2])})
```

Event DDays
--------------------------------------------

### Event

```{r}
render_gt({ head(creel$event) })
```

### days

```{r}
#renderPrint({str(days)})
render_gt({ head(creel$days) })
```


Effort
--------------------------------------------

### Effort

```{r}
render_gt({ head(creel$effort) })
```

Interview
--------------------------------------------

### Interview

```{r}
render_gt({ head(creel$interview) })
```

Catch
--------------------------------------------

### Catch

```{r}
render_gt({ head(creel$catch) })
```


Effort/Interview
============================================

```{r prep_effort_census_index, include = FALSE}
#Aggregate census (tie in) effort counts, associating to closest-in-time index count.
#take the initial effort_census, with all count_sequence == 1,
#add/overwrite the count_sequence val with that from closest temporal match from inline/anonymous paired counts object

#could remove the left_join of days? appears to only be used here for day_index, which used only for stan?
#or leave with idea that an endpoint of this could be objects ready for stan?

pe_effort_census <- reactive({
  dplyr::left_join(
    creel$effort |> 
      dplyr::filter(tie_in_indicator == 1) |>
      dplyr::select(event_date, water_body, water_body_desc, location, section, tie_in_indicator, count_type, count_quantity)
    ,
    #reassign count_seq from closest index
    dplyr::left_join(
      creel$effort |> dplyr::filter(tie_in_indicator == 1) |> dplyr::distinct(event_date, section, location, tie_in_indicator, effort_start_time, count_sequence),
      creel$effort |> dplyr::filter(tie_in_indicator == 0) |> dplyr::distinct(event_date, section, location, tie_in_indicator, effort_start_time, count_sequence),
      by = c("event_date", "section"),
      suffix = c("_cen", "_ind")
      ) |>
      dplyr::group_by(event_date, section, location_cen) |>
      dplyr::slice_min(abs(effort_start_time_cen - effort_start_time_ind), n = 1) |>
      dplyr::ungroup() |>
      dplyr::distinct(event_date, section, location = location_cen, count_sequence = count_sequence_ind)
    ,
    by = c("event_date", "section", "location")
  ) |>
    dplyr::left_join(creel$days, by = "event_date") |>
    dplyr::mutate(
      angler_type = dplyr::case_when(
        stringr::word(count_type, 1) %in% c("Bank","bank","Shore") ~ "bank",
        stringr::word(count_type, 1) %in% c("Boat","boat") ~ "boat" #Note "Boats" plural intentionally excluded
      )
    ) |>
    dplyr::filter(!is.na(angler_type)) |>
    dplyr::group_by(event_date, day_index, section, count_sequence, angler_type) |>
    dplyr::summarize(
      count_quantity = sum(count_quantity),
      tie_in_indicator = 1,
      .groups = "drop") |>
    dplyr::arrange(event_date, section, count_sequence) |>
    tidyr::drop_na(count_sequence) #-> pe_effort_census
})

#combines several intermediates from CreelPointEstimate_Dev
#dropping several steps not needed (at all or to reach daily_means)
#not yet using input$index_count_types
#mutate here creates a later join-by column
pe_effort_index_daily_mean <- reactive({
  dplyr::filter(creel$effort, tie_in_indicator == 0) |> 
  dplyr::filter(
    is.na(no_count_reason),
    !is.na(count_type),
    count_type %in% input$index_count_types
    ) |>
  dplyr::group_by(section, event_date, count_sequence, count_type) |>
  dplyr::summarise(count_quantity = sum(count_quantity), .groups = "drop") |>
  dplyr::arrange(event_date, section, count_sequence) |> 
  dplyr::group_by(section, event_date, count_type) |>
  dplyr::summarise(count_quantity = mean(count_quantity), .groups = "drop") |>
  dplyr::mutate(
    angler_type = dplyr::case_when(
      count_type == "Boat Anglers" ~ "boat",
      count_type == "Bank Anglers" ~ "bank",
      count_type == "Trailers Only" ~ "boat",
      count_type == "Vehicle Only" ~ "total"
    )
  ) #-> pe_effort_index_daily_mean
})



# ### THIS FROM SETUP CHUNK IN _DEV NOT YET DEALT WITH
# # fix angler type in census expansion table for use with vehicle / trailer counts so it joins to TI_expan table
# if(str_detect(index_count_types, c("Vehicle Only", "Trailers Only"))) {
# 
# lut$census_expansion <- lut$census_expansion |>
#   mutate(
#     angler_type = if_else(angler_type == "bank", "total", "boat")
#   )
# }

#interview data have angler_count, vehicle_count, trailer_count, angler_type and boat_used
#Disallow NAs in angler_type, fill missing angler_type from boat_used
#!!Does this actually need row-wise time_strata? and why not just call model_period?
#!!Maintain angler_hours_total filter?
#!!lots of extra cols still at this point...
pe_interview <- reactive({
  left_join(creel$interview, creel$days, by = "event_date") |>
  mutate(
    across(c(vehicle_count, trailer_count), ~replace_na(., 0)),
    trip_status = replace_na(trip_status, "Unknown"),
    
    angler_type = tolower(angler_type),
    angler_type = if_else(is.na(angler_type), boat_used, angler_type),
    angler_type = case_when( 
      angler_type == "boat" ~ "boat", #pass through
      angler_type == "bank" ~ "bank", #pass through
      angler_type == "Unk" ~ "bank",  #Kalama, others?
      angler_type == "No" ~ "bank",   #value from boat_used
      angler_type == "Yes" ~ "boat"   #value from boat_used
      ),
    angler_type_ind = as.integer(factor(angler_type)),
    
    fishing_end_time = if_else(
      trip_status == "Incomplete" | is.na(fishing_end_time),
      interview_time,
      fishing_end_time),
    angler_hours = round(as.numeric(fishing_end_time - fishing_start_time) / 3600, 5),
    angler_hours_total = angler_count * angler_hours,
    time_strata = input$model_period
  ) |>
  filter(angler_hours_total >= 0.5) # -> pe_interview
})
```


```{r eval = FALSE}
if(str_detect(index_count_types, c("Bank Anglers", "Boat Anglers"))) {
  
  daily_effort_estimates <- left_join(
    pe_effort_index_daily_mean, 
    select(creel$days, event_date, DayL),
    by = "event_date") |> 
    mutate(mean_daily_effort = DayL * count_quantity) |>
    arrange(event_date, section)
  
} else {
  if(str_detect(index_count_types, c("Vehicle Only", "Trailers Only"))){ 
    
    angler_data_from_interviews <- bind_rows(
      pe_interview |>
      group_by(section, event_date) |> 
      summarize(
        daily_sum_angler = sum(angler_count),
        daily_sum_index_count_from_interview = sum(vehicle_count),
        angler_hours_total = sum(angler_hours_total),
        anglers_per_index_count_from_interview = daily_sum_angler / daily_sum_index_count_from_interview,
        angler_type = "total",
        .groups = "drop")
      ,
      filter(pe_interview, angler_type == "boat") |>
      group_by(section, event_date) |>
      summarize(
        daily_sum_angler = sum(angler_count),
        daily_sum_index_count_from_interview = sum(vehicle_count),
        angler_hours_total = sum(angler_hours_total),
        anglers_per_index_count_from_interview = daily_sum_angler / daily_sum_index_count_from_interview,
        angler_type = "boat",
        .groups = "drop")
      ) 
    
    daily_effort_estimates <- angler_data_from_interviews  |>
      left_join(pe_effort_index_daily_mean, by = c("event_date", "section", "angler_type")) |>
      left_join(select(creel$days, event_date, DayL), by = "event_date") |> 
      mutate(mean_daily_effort = DayL * anglers_per_index_count_from_interview * count_quantity) |>
      arrange(event_date, section) |> 
      filter(!is.na(mean_index_count)) #circle back on this 
    
  }
}



```


### Index counts

```{r}
#renderPrint({str(creel$effort)})

# renderPlot({
#   if(!is.null(creel$effort)) {
#     creel$effort |>
#       group_by(tie_in_indicator, section, event_date) |>
#       summarise(count_quantity = sum(count_quantity), .groups = "drop") |>
#       ggplot(aes(event_date, count_quantity, fill = section)) +
#       geom_col() +
#       facet_wrap(~tie_in_indicator, scales = "free")
#   }
# })

#renderPrint({str(pe_effort_census())})

renderPlot({
  if(!is.null(creel$effort)) {
    pe_effort_index() |>
      ggplot(aes(event_date, count_quantity, fill = factor(count_sequence))) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + count_type, scales = "free")
  }
})

```

### Index daily mean

```{r}
renderPlot({
  if(!is.null(creel$effort)) {
    pe_effort_index_daily_mean() |>
      ggplot(aes(event_date, count_quantity, fill = count_type)) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + count_type, scales = "free")
  }
})

```

Interview
--------------------------------------------

### Interview

```{r}
renderPlot({
  if(!is.null(creel$interview)) {
    pe_interview() |>
      ggplot(aes(event_date, angler_hours_total, fill = angler_type)) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + angler_type, scales = "free")
  }
})

```

### Interview

```{r}
renderPlot({
  if(!is.null(creel$interview)) {
    pe_interview() |>
      ggplot(aes(angler_count, angler_hours_total, fill = angler_type)) +
      geom_point(position = position_dodge()) +
      facet_wrap(~section + angler_type, scales = "free")
  }
})

```

Catch
============================================


About
============================================

Anything to cite/link to?

WDFW gathers fishing information from anglers around the state:
(https://wdfw.wa.gov/fishing/reports/creel)[https://wdfw.wa.gov/fishing/reports/creel]
