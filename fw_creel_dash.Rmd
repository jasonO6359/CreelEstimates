---
title: "FW Creel Point Estimate"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    source_code: embed
    theme:
      version: 4
      bootswatch: default
      bg: "#D0D0D0"
      fg: "#000000"
      navbar-bg: "#1189D9"
      primary: "#1189D9"
runtime: shiny
---

```{r setup, include=FALSE}
#bslib::bs_themer()

library("flexdashboard")
library("tidyverse")
library("shiny")
library("patchwork")
library("gt")

#base endpoints
dwg_base <- list(
  event = "https://data.wa.gov/resource/ui95-axtn.csv",
  effort = "https://data.wa.gov/resource/h9a6-g38s.csv",
  interview = "https://data.wa.gov/resource/rpax-ahqm.csv",
  catch = "https://data.wa.gov/resource/6y4e-8ftk.csv",
  gear = "https://data.wa.gov/resource/d2ks-afhz.csv" #currently unused?
)

#water_body options by proj_name options
#ideally this would be defined directly from a query against strings in the db
proj_levels <- list(
  `R5 Steelhead` = list("Kalama River"),
  `District 13` = list("Skykomish River", "Tokul Creek"),
  `District 14` = list("Cascade River", "Sauk River", "Skagit River")
)

#lookup objects created in build_envi chunk below: 
# -dates of holidays
# -river lon/lat (for day length)
# -sections (for aggregating count/interview locations)
# -tie-in expansions
# -closure files
load("fw_creel_dash_envi.RData")

lu_input <- reactiveValues() #focal river_lonlat, sections, census_exp and closures
creel <- reactiveValues() #data queried from DWG as list of tibbles
pe <- reactiveValues() #intermediate objects wrangled from creel list elements
ests <- reactiveValues() #final objects calc'd from pe & creel

```

```{r build_envi, eval=FALSE}
# # likely will need to build out route to load sections/closures etc on the fly?
# # uncomment to rebuild...
# 
# lu <- list()
# 
# lu$dates_holidays_2015_2030 <- read_lines("input_files/dates_holidays_2015_2030.txt") |>
#   as.Date(format="%Y-%m-%d")
# 
# #single tibble
# lu$river_lonlat <- readr::read_csv("input_files/river_locations_master.csv")
# 
# #list of tibbles
# lu$sections <- list.files("input_files", pattern = "sections_", full.names = T) |>
#   set_names() |> map(readr::read_csv)
# names(lu$sections) <- tools::file_path_sans_ext(basename(names(lu$sections))) |> str_remove("sections_")
# 
# #list of tibbles
# lu$census_expansions <- list.files("input_files", pattern = "ti_expansions_", full.names = T) |>
#   set_names() |> map(readr::read_csv)
# names(lu$census_expansions) <- tools::file_path_sans_ext(basename(names(lu$census_expansions))) |> str_remove("ti_expansions_")
# 
# # # #!! snippet to mod to build closure.csvs for other datasets...
# # # #!! change vals in event_date, s and write_csv
# # # #!! file is date-complete over the focal range
# # # #!! with cols per section, elements coded open==T, closed==F
# # expand_grid(
# #   event_date = seq.Date(as.Date("2021-09-16"), as.Date("2021-11-30"), by = "day"),
# #   s = paste0("open_section_", c(1)),
# #   is_open = TRUE
# #   ) |>
# #   pivot_wider(names_from = s, values_from = is_open) |>
# #   write_csv("input_files/closures_district_river_season_species.csv")
# 
# #list of tibbles
# lu$closures_by_section <- list.files("input_files", pattern = "closures_", full.names = T) |>
#   set_names() |> map(readr::read_csv)
# names(lu$closures_by_section) <- tools::file_path_sans_ext(basename(names(lu$closures_by_section))) |> str_remove("closures_")
# 
# #save.image("fw_creel_dash_envi.RData")

```


Sidebar {.sidebar data-width=350}
============================================

### Controls

```{r input_selectors}
selectInput(inputId = 'proj_name', label = 'Project Name', choices = names(proj_levels)
            , selected = "District 13"
            )

selectizeInput(inputId = 'water_body', label = 'Water Body', choices = proj_levels, multiple = TRUE
               , selected = "Skykomish River"
               )

dateRangeInput(inputId = 'dates', label = "Date range"
               , start = "2021-05-29", end = "2021-07-18" 
               )

selectInput(inputId = 'closures', label = 'Closures', choices = names(lu$closures_by_section), multiple = FALSE
            , selected = "d13_skykomish_summer_chin"
            )
selectInput(inputId = 'sections', label = 'Sections', choices = names(lu$sections), multiple = FALSE
            , selected = "d13_skykomish_summer_chin"
            )
selectInput(inputId = 'census_exp', label = 'Census Expansion LU', choices = names(lu$census_expansions), multiple = FALSE
            , selected = "d13_skykomish_summer_chin"
            )


radioButtons(inputId = 'model_period', label = "Model period", choices = c("Week", "Month")
             , selected = "Week"
             )

radioButtons(inputId = 'index_count_types', label = "Index count types", 
             choices = c("Bank/Boat Anglers", "Vehicle/Trailers Only")
             ,selected = c("Vehicle/Trailers Only")
             )

radioButtons(inputId = 'census_expansion', label = "Census expansion method", 
             choices = c("Direct", "Indirect")
             ,selected = c("Direct")
             )

checkboxGroupInput(inputId = 'days_wkend', label = "Days in 'weekends'",
                   choiceNames =  c("Mon", "Tues", "Wed", "Thur", "Fri", "Sat", "Sun"),
                   choiceValues = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"),
                   selected = c("Saturday", "Sunday"))

numericInput(inputId = 'int_ang_hrs_tot_min', label = "Minimum interview total angler hours", 
             value = 0.5, min = 0, max = 2)

# #can add option to manually upload ...
# fileInput(inputId = 'sections', label = 'Sections LU', accept = ".csv")

```

### Fetch

```{r dwg_fetch}
#fires the requests on button push
actionButton("fetch", label = "Fetch raw data")


# # ##to uncomment for console dev
# lu_input <- list()
# creel <- list()
# input <- list()
# input$proj_name <- "District 13"
# # input$proj_name <- "District 14"
# input$water_body <- c("Skykomish River")
# input$dates <- c(as.Date("2021-05-29", "%Y-%m-%d"), as.Date("2021-07-18", "%Y-%m-%d"))
# # input$water_body <- "Cascade River"
# # input$dates <- c(as.Date("2021-09-16", "%Y-%m-%d"), as.Date("2021-11-30", "%Y-%m-%d"))
# # input$water_body <- c("Skagit River", "Sauk River")
# # input$dates <- c(as.Date("2021-09-01", "%Y-%m-%d"), as.Date("2021-11-01", "%Y-%m-%d"))
# input$model_period <- "Week"
# input$index_count_types <- "Vehicle/Trailers Only" #c("Vehicle Only","Trailers Only")
# input$census_expansion <- "Direct"
# input$days_wkend <- c("Saturday", "Sunday")
# input$int_ang_hrs_tot_min <- 0.5
# #
# input$sections <- "d13_skykomish_summer_chin"
# input$census_exp <- "d13_skykomish_summer_chin"
# input$closures <- "d13_skykomish_summer_chin"
# # input$sections <- "d14_cascade_fall_salmon"
# # input$census_exp <- "Cascade_Fall_Salmon_2021"
# # input$sections <- "r5_kalama_steelhead"
# #input$census_exp <- "r5_kalama_example"
# # input$sections <- "d14_skagit_fall_salmon_PE"
# # input$census_exp <- "Skagit_Fall_Salmon_2021"



#!!this is "event reactive", so should not trigger on fiddling with inputs
#!!but only when "fetch" button is clicked (see last few lines of chunk)
reactive({

  #!!Lon/lat only used in day-length calc?
  #!!anywhere/anywhy that distinct() would be a problem?
  #!!i.e., anyone realistically using this to run ests on widely spaced rivers?
  lu_input$river_lonlat <- dplyr::filter(
    lu$river_lonlat, River %in% input$water_body) |> 
      dplyr::distinct(River, .keep_all = T)
  
  #!!note the current fetch drops/excludes effort and interview rows
  #!!if no section assigned from section LU
  lu_input$sections <- dplyr::select(
      lu$sections[[input$sections]], 
      water_body_desc, location = location_code, section)

  lu_input$census_exp <- lu$census_expansions[[input$census_exp]] |> 
    mutate(cen_exp_meth = input$census_expansion)
  
  lu_input$closures <- lu$closures_by_section[[input$closures]]

  
  creel$event <- paste0(
    dwg_base$event,
    "?$where=project_name in('", input$proj_name, "')",
    " AND water_body in('", paste0(input$water_body, collapse = "','"), "')",
    " AND event_date between '", input$dates[1],
    "T00:00:00' and '", input$dates[2],
    "T00:00:00'&$limit=100000"
    ) |>
    utils::URLencode() |>
    readr::read_csv(show_col_types = F) |>
    dplyr::select(creel_event_id, water_body, event_date, tie_in_indicator)
  
  if(nrow(creel$event) > 0) {
    
    creel$effort <- paste0(
      dwg_base$effort,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::filter(!is.na(count_type)) |> 
      dplyr::select(-created_datetime, -modified_datetime) |> 
      dplyr::left_join(lu_input$sections, by = c("location")) |> 
      dplyr::filter(!is.na(section))

    creel$interview <- paste0(
      dwg_base$interview,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::rename(location = interview_location) |> 
      dplyr::select(
        -created_datetime, -modified_datetime,
        -state_residence, -zip_code) |> 
      dplyr::left_join(lu_input$sections, by = c("location")) |> 
      dplyr::filter(!is.na(section))
    
    creel$catch <- paste0(
      dwg_base$catch,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::select(interview_id, catch_id, species, run, life_stage, fin_mark, fate, fish_count) |> 
      dplyr::mutate(
        life_stage = replace_na(life_stage, "Adult"), # placeholder pending data corrections in fish apps 
        catch_group = paste(species, life_stage, fin_mark, fate, sep = "_") # fish catch groups to estimate catch of 
      )
    
    #this whole chunk depends on button push, so "lazy" against fiddling
    creel$days <- tibble::tibble(
      event_date = seq.Date(input$dates[1], input$dates[2], by = "day"),
      Day = weekdays(event_date),
      DayType = if_else(
        Day %in% input$days_wkend | Day %in% lu$dates_holidays_2015_2030,
        "Weekend", "Weekday"),
      DayType_num = if_else(str_detect(DayType, "end"),1,0),
      DayL = suncalc::getSunlightTimes(
        date = event_date,
        tz = "America/Los_Angeles",
         lat = lu_input$river_lonlat$Lat,
         lon = lu_input$river_lonlat$Long,
        keep=c("sunrise", "sunset")
        ) |>
        mutate(DayL = as.numeric((sunset + 3600) - (sunrise - 3600))) |>
        pluck("DayL"),
      Week = as.numeric(format(event_date, "%V")),
      Month = as.numeric(format(event_date, "%m")),
      ModelPeriod = input$model_period,
      time_strata = if_else(ModelPeriod == "Month", Month, Week)
      ) |>
      tibble::rowid_to_column(var = "day_index") |>
      dplyr::left_join(lu_input$closures, by = "event_date")
    
    # excluding specified closures, total number of days by section, weekday/end, and time strata for which to generate estimates
    creel$days_total <- creel$days |>
      pivot_longer(
        cols = starts_with("open_section"), 
        names_to = "section", 
        values_to = "is_open") |>
      filter(is_open == TRUE) |> 
      mutate(section = as.numeric(gsub("^.*_", "", section))) |>
      count(time_strata, DayType, section, name = "N_days")
    
  } else {
    creel$effort <- NULL
    creel$interview <- NULL
    creel$catch <- NULL
  }
}) |> 
  bindEvent(input$fetch)
  
```

### Estimate

```{r calc_pe_ests}
actionButton("estimate", label = "Calculate estimates")

#pe <- list()
#ests <- list()

reactive({
  #### pe$effort_census --------------
  #Aggregate census (tie in) effort counts, associating to closest-in-time index count.
  #take the initial effort_census, with all count_sequence == 1,
  #add/overwrite the count_sequence val with that from closest temporal match from inline/anonymous paired counts object
  pe$effort_census <- dplyr::left_join(
    #begin with focal census data
    creel$effort |> 
      dplyr::filter(tie_in_indicator == 1) |>
      dplyr::select(event_date, location, section, tie_in_indicator, count_type, count_quantity)
    ,
    #reassign count_seq from closest index
    dplyr::left_join(
      creel$effort |> dplyr::filter(tie_in_indicator == 1) |> 
        dplyr::distinct(event_date, section, location, tie_in_indicator, effort_start_time, count_sequence),
      creel$effort |> dplyr::filter(tie_in_indicator == 0) |> 
        dplyr::distinct(event_date, section, tie_in_indicator, effort_start_time, count_sequence),
      by = c("event_date", "section"),
      suffix = c("_cen", "_ind")
      ) |>
      dplyr::group_by(event_date, section, location) |>
      dplyr::slice_min(abs(effort_start_time_cen - effort_start_time_ind), n = 1) |>
      dplyr::ungroup() |>
      dplyr::distinct(event_date, section, location, count_sequence = count_sequence_ind)
    ,
    by = c("event_date", "section", "location")
    ) |>
    dplyr::mutate(
      angler_type = dplyr::case_when(
        stringr::word(count_type, 1) %in% c("Bank","bank","Shore") ~ "bank",
        stringr::word(count_type, 1) %in% c("Boat","boat") ~ "boat" #Note "Boats" plural intentionally excluded
      )
    ) |>
    tidyr::drop_na(angler_type) |> 
    dplyr::group_by(event_date, section, tie_in_indicator, count_sequence, angler_type) |>
    dplyr::summarize(count_census = sum(count_quantity), .groups = "drop") |>
    tidyr::drop_na(count_sequence) |> 
    dplyr::arrange(event_date, section, count_sequence)
  
  #### pe$effort_index --------------
  # filters and aggregates over locations within count_seq & section
  # mutate angler_type here creates a later join-by column
  pe$effort_index <- dplyr::filter(
    creel$effort, 
    tie_in_indicator == 0,
    is.na(no_count_reason),
    !is.na(count_type)
    ) |>
    dplyr::group_by(event_date, section, count_sequence, count_type) |>
    dplyr::summarise(count_index = sum(count_quantity), .groups = "drop") |>
    dplyr::mutate(
      angler_type = dplyr::case_when(
        count_type == "Boat Anglers" ~ "boat",
        count_type == "Bank Anglers" ~ "bank",
        count_type == "Trailers Only" ~ "boat",
        count_type == "Vehicle Only" ~ "total"
      )
    ) |> 
    dplyr::arrange(event_date, section, count_sequence)
  
  #### pe$interview --------------
  # #interview data have angler_count, vehicle_count, trailer_count, angler_type and boat_used
  # #disallow NAs in angler_type, fill missing angler_type from boat_used
  pe$interview <- dplyr::left_join(
    creel$interview, 
    creel$days |> select(event_date, time_strata, DayType), 
    by = "event_date"
    ) |>
    dplyr::mutate(
      dplyr::across(c(vehicle_count, trailer_count), ~replace_na(., 0)),
      trip_status = replace_na(trip_status, "Unknown"),
      
      angler_type = tolower(angler_type),
      angler_type = dplyr::if_else(is.na(angler_type), boat_used, angler_type),
      angler_type = dplyr::case_when( 
        angler_type == "boat" ~ "boat", #pass through
        angler_type == "bank" ~ "bank", #pass through
        angler_type == "Unk" ~ "bank",  #Kalama, others?
        angler_type == "No" ~ "bank",   #value from boat_used
        angler_type == "Yes" ~ "boat"   #value from boat_used
      ),
      angler_type_ind = as.integer(factor(angler_type)),

      fishing_end_time = dplyr::if_else(
        trip_status == "Incomplete" | is.na(fishing_end_time),
        interview_time,
        fishing_end_time),
      angler_hours = round(as.numeric(fishing_end_time - fishing_start_time) / 3600, 5),
      angler_hours_total = angler_count * angler_hours
    ) |>
    dplyr::filter(angler_hours_total >= input$int_ang_hrs_tot_min) |> 
    #drop a few unused cols for ease of dev
    dplyr::select(-creel_event_id, -water_body, -project_name, -interview_number,
           -crc_area, -fishing_location, -ends_with("_time"),
           -previously_interviewed, -comment_txt, -water_body_desc
    ) |> 
    dplyr::arrange(event_date, time_strata, section, angler_type, location)
  
  #### pe$interview_and_catch --------------
  # join catch data to interview after inferring complete cases (counts or 0s for all catch_groups encountered)
  # note that interview_ids in creel$interview/pe_interview may have no catch and not be in creel$catch
  # so are consequently coded NA for catch_group; final mutate makes explicit
  # similarly, rows in creel$catch for "short" interviews may be lost in join 
  pe$interview_and_catch <- left_join(
    pe$interview |> drop_na(angler_hours) |> 
      select(event_date, time_strata, DayType, section, interview_id, angler_type, ends_with("_count"), angler_hours, angler_hours_total) 
    ,
    creel$catch |> 
      group_by(interview_id, catch_group) |> 
      summarise(fish_count = sum(fish_count, na.rm = T), .groups = "drop") |> 
      complete(interview_id, catch_group, fill = list(fish_count = 0))
    ,
    by = "interview_id"
    ) |>
    mutate(
      catch_group = replace_na(catch_group, "no encounter data"),
      fish_count = replace_na(fish_count, 0)
    )
  
  #### pe$angler_hours_daily_mean --------------
  # depending on the types of index counts, reach the calc: ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * TI_expan_final
  # when index counts are already bank & boat, matching census counts,
  #   then angler_hour daily means are just effort index counts of anglers expanded by day length,
  #   which are multiplied against tie-in expanded census counts of anglers by type (per section)
  # but when index counts are trailers & vehicles,
  #   then angler_hour daily means require first using interviews to estimate anglers_per_vhcl_trlr by angler_type total & boat 
  #   so anglers_per_vhcl_trlr can be multiplied against the trailer & vehicle counts in effort_index, releveled to boat/total
  #   and then TI-expanded counts similarly require splitting, releveling and rebinding census to boat/total to allow join with effort_index
  #   and THEN generating a final object with total, boat and derived-bank, including dealing with case of only-bank (e.g., Cascade)

  if(str_detect(input$index_count_types, "Bank|Boat")) {
    #initial angler_hours_daily_mean: join day length against mean counts over count_seqs per section-day-angler_type
    pe$angler_hours_daily_mean <- left_join(
      pe$effort_index |> 
        dplyr::group_by(event_date, section, angler_type) |>
        dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop"),
      creel$days |> select(event_date, DayL),
      by = "event_date") |>
      mutate(angler_hours_daily_mean = count_index_mean * DayL) |>
      arrange(event_date, section)
    
    #census_TI_expan: left join effort index counts to census counts and expand by TI
    #count_census begins summed by event_date, section, tie_in_indicator, count_sequence, with angler_type in [bank, boat]
    #excluding date-section-anglers with missing (or negative) counts as invalid to support inferring point estimates
    pe$census_TI_expan <- left_join(
      pe$effort_census,
      pe$effort_index,
      by = c("event_date", "section", "count_sequence","angler_type")
      ) |>
      filter(
        !is.na(count_census), !is.na(count_index),
        count_census >= 0, count_index >= 0
        ) |> 
      group_by(section, angler_type) |>
      summarise(
        TI_expan_weighted = sum(count_census) / sum(count_index),
        TI_expan_weighted = if_else(TI_expan_weighted == 0, 1, TI_expan_weighted) |> replace_na(1),
        .groups = "drop") |>
      left_join(
        lu_input$census_exp |>
          select(cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
        by = c("angler_type", "section")) |>
      mutate(
        cen_exp_meth = replace_na(cen_exp_meth, input$census_expansion),
        p_TI = replace_na(p_TI, 1),
        TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
        TI_expan_final = if_else(
          cen_exp_meth == "Direct",
          TI_expan_weighted / p_TI,
          TI_expan_indirect)
      )
    #now overwrite object, adding TI-expansions
    pe$angler_hours_daily_mean <- left_join(
      pe$angler_hours_daily_mean,
      pe$census_TI_expan,
      by = c("section", "angler_type")
      ) |>
      mutate(ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * replace_na(TI_expan_final, 1)) 

  } else if(str_detect(input$index_count_types, "Vehicle|Trailer")) {
    #in this case, boat and bank counts must be indirectly calc'd
    #first the interviews are used to estimate anglers per vehicle, stratified by boat vs total (from boat|bank angler_type rows in interview)
    pe$interview_ang_per_vehic <- bind_rows(
      pe$interview |>
        group_by(event_date, section) |>
        summarize(angler_type = "total", anglers_per_vhcl_trlr = sum(angler_count) / sum(vehicle_count), .groups = "drop")
      ,
      pe$interview |>
        filter(angler_type == "boat") |>
        group_by(event_date, section) |>
        summarize(angler_type = "boat", anglers_per_vhcl_trlr = sum(angler_count) / sum(trailer_count), .groups = "drop")
    ) |> 
      arrange(event_date, section)
    
    #note this left_join drops rows of index counts where a given date-section-angler_type is missing from interview data
    pe$angler_hours_daily_mean <- left_join(
      pe$interview_ang_per_vehic, #coerced above to total/boat
      pe$effort_index |> #already in total/boat
        dplyr::group_by(event_date, section, angler_type) |>
        dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop")
      ,
      by = c("event_date", "section", "angler_type")) |>
      left_join(creel$days |> select(event_date, DayL), by = "event_date") |>
      mutate(angler_hours_daily_mean = anglers_per_vhcl_trlr * count_index_mean * DayL) |>
      arrange(event_date, section)
    
    #now coerce back to angler_type bank/boat (unexpanded)
    pe$angler_hours_daily_mean <- pe$angler_hours_daily_mean |> 
      select(-DayL, -anglers_per_vhcl_trlr, -count_index_mean) |> 
      pivot_wider(
        names_from = angler_type, 
        values_from = c(angler_hours_daily_mean), 
        ) |>
      mutate(bank = total - boat, total = NULL) |> 
      pivot_longer(cols = c(boat, bank), names_to = "angler_type", values_to = "angler_hours_daily_mean") |> 
      #NAs and negatives here reflect inadequate or problematic data barring meaningful inference...
      filter(!is.na(angler_hours_daily_mean), angler_hours_daily_mean >= 0)

    #begin census expansion values object by joining census and index in terms of total & boat
    pe$census_TI_expan <- left_join(
      #census already grouped & summed by event_date, section, tie_in_indicator, count_sequence, and angler_type [bank, boat]
      #but as for interview above, first split and collapse to reassign angler_type as total & boat
      bind_rows(
        pe$effort_census |>
          group_by(event_date, section, count_sequence) |>
          summarize(angler_type = "total", count_census = sum(count_census),  .groups = "drop")
        ,
        pe$effort_census |>
          filter(angler_type == "boat") |>
          group_by(event_date, section, count_sequence) |>
          summarize(angler_type = "boat", count_census = sum(count_census), .groups = "drop")
      ),
      #index via interviews with angler_type already total & boat
      #this is very similar to initial pe$angler_hours_daily_mean, but not summarized to daily mean
      #note this will typically be an expanding left_join 
      #since interview_ang_per_vheic is per day-section but effort_index is per count_seq (per day-section)
      left_join(
        pe$interview_ang_per_vehic,
        pe$effort_index,
        by = c("event_date", "section", "angler_type")
      ) |>
        mutate(count_index = anglers_per_vhcl_trlr * count_index) |>
        select(event_date, section, count_sequence, angler_type, count_index)
      ,
      by = c("event_date", "section", "count_sequence", "angler_type")
    )  
    #now overwrite, coercing angler_type back to bank/boat as above for pe$angler_hours_daily_mean
    #again dropping NAs and negatives as invalid for inferring estimates
    pe$census_TI_expan <- pe$census_TI_expan |> 
      pivot_longer(cols = c(count_census, count_index), names_to = "count_type", values_to = "count") |> 
      pivot_wider(names_from = angler_type, values_from = count) |>
      mutate(bank = total - boat, total = NULL) |> #filter(is.na(boat) | is.na(bank) | bank < 0)
      pivot_longer(cols = c(boat, bank), names_to = "angler_type", values_to = "count") |>
      pivot_wider(names_from = count_type, values_from = count) |> 
      filter(
        !is.na(count_census), !is.na(count_index),
        count_census >= 0, count_index >= 0
      ) |> 
      group_by(section, angler_type) |> 
      summarise(
        TI_expan_weighted = sum(count_census) / sum(count_index),
        TI_expan_weighted = if_else(TI_expan_weighted == 0, 1, TI_expan_weighted) |> replace_na(1),
        .groups = "drop") |> 
      #and now bring in the external expansion values if any
      left_join(
        lu_input$census_exp |>
          select(cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
        by = c("angler_type", "section")) |>
      mutate(
        cen_exp_meth = replace_na(cen_exp_meth, input$census_expansion),
        p_TI = replace_na(p_TI, 1),
        TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
        TI_expan_final = if_else(
          cen_exp_meth == "Direct",
          TI_expan_weighted / p_TI,
          TI_expan_indirect)
      )
    
    #now multiply mean daily effort in angler_hours by tie-in ratio bias term 
    #aiming for event_date, section, angler_type [total, boat, bank (as total-boat)]
    pe$angler_hours_daily_mean <- left_join(
      pe$angler_hours_daily_mean, 
      pe$census_TI_expan |> select(section, angler_type, TI_expan_final),
      by = c("section", "angler_type")
    ) |>
      mutate(ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * TI_expan_final)
    
}
  
  #### pe$dailyCPUE ------------------------

  #aggregate interviews per day per strata of [week/month-weekend/day-section-bank/boat-catch_group]
  #   here including only "mean of ratios" (mean over interviews)
  #   dropping "ratio of the means" (actually sums): sum(fish_count) / sum(angler_hours_total)
  #then multiply by TI-expanded effort estimate
  #dropping any date-section-angler_type-catch_groups for which interview-based CPUE is available
  #but census-corrected effort estimates are not (various reasons why a day-section-angler_type hours could be NA)
  pe$daily_CPUE <- pe$interview_and_catch |>
    mutate(cpue_interview = fish_count / angler_hours_total) |>
    group_by(time_strata, event_date, DayType, section, angler_type, catch_group) |>
    summarise(cpue_mor_daily = mean(cpue_interview), .groups = "drop") |> 
    left_join(
      pe$angler_hours_daily_mean, 
      by = c("event_date", "section", "angler_type")
    ) |>
    drop_na(ang_hrs_daily_mean_TI_expan) |> 
    mutate(catch_estimate = round(cpue_mor_daily * ang_hrs_daily_mean_TI_expan, 3)) |>
    arrange(event_date, section, angler_type, catch_group)
      
  # #degrees of freedom by section and angler type to apply to time strata estimates
  # pe$df <- pe$angler_hours_daily_mean |> 
  #   distinct(section, angler_type, time_strata, n_days) |>
  #   group_by(section, angler_type) |>
  #   summarize(df = (min(n_days - 1) + sum(n_days))/2, .groups = "drop")
#!! the above version more closely follows EB orig
#!! but "n_days" in the distinct() is reflecting DayType as a "hidden strata"
#!! should the count of days sampled account for DayType within a week/month-section-angler_type?
#!! the final df differs due to the different min(n_days_samp-1)
  pe$df <- left_join(
    pe$angler_hours_daily_mean,
    creel$days |> select(event_date, time_strata, DayType),
    by = "event_date"
    ) |> 
    count(time_strata, DayType, section, angler_type, name = "n_days_samp") |> 
    #count(time_strata, section, angler_type, name = "n_days_samp") |> 
    group_by(section, angler_type) |>
    mutate(df = (min(n_days_samp - 1) + sum(n_days_samp))/2) |> 
    ungroup()
# #!! to recover section-angler_type level only...
#   pe$df |> distinct(section, angler_type, df)

#!!pending above...note still incorrect actual "df = " calc...will update if needed  
  # #used in final set of objects, could move into pe or make inline?
  # ests$degrees_freedom_total <- pe$angler_hours_daily_mean |>
  #   distinct(section, angler_type, n_days = n_days_total) |>
  #   group_by(section, angler_type) |>
  #   summarize(
  #     min_n_days = min(n_days),
  #     sum_n_days = sum(n_days),
  #     degrees_freedom = min_n_days + sum_n_days / 2,
  #     .groups = "drop"
  #   )


  #### DA testing section -----------------
  
  ests$effort <- left_join(
    #dates expanded to n-sections * n-angler_types * n-days, previously held as "creel$days_section_angler_type" but only used once
    creel$days |>
      select(time_strata, event_date, DayType, starts_with("open_section")) |> 
      mutate(
        section = list(unique(lu_input$sections$section)),
        angler_type = list(c("bank", "boat")) 
      ) |> 
      unnest(cols = section) |> 
      unnest(cols = angler_type)
    ,
    #estimates of angler_hours possible to calculate for sampled dates-sections-angler_type 
    pe$angler_hours_daily_mean |> select(event_date, section, angler_type, ang_hrs_daily_mean_TI_expan)
    ,
    by = c("event_date", "section", "angler_type")
  ) 
  
  #adding PER-DAY the week/month-daytype-section-angler_type strata mean
  #this is the finest stratification above individual days 
  #but note that sample size is too small to offer meaningful var with a DayType per week stratification
  # -the var() and sd() functions return NA when passed a length-1 vector (single obs)
  # -variance has limited meaning even when n=3, e.g. if sampling Fri & Sat & Sun
  ests$effort_ts_s_at_dt_mean_filled <- ests$effort |> 
    group_by(time_strata, section, angler_type, DayType) |>
    mutate(
      ang_hrs_mean = mean(ang_hrs_daily_mean_TI_expan, na.rm = T),
      ang_hrs = if_else(is.na(ang_hrs_daily_mean_TI_expan), ang_hrs_mean, ang_hrs_daily_mean_TI_expan)
      ) |> 
    ungroup()

# #!! this enables various aggregations of the point estimate
# #!! some of which may be inappropriate
# #!! and which neglect the dispersion/uncertainty (assuming not including a var() call above and then summarizing by mean/sum on ang_hrs_var)
#   ests$effort_ts_s_at_dt_mean_filled |> summarise(across(ang_hrs, sum), .groups = "drop")
#   ests$effort_ts_s_at_dt_mean_filled |> group_by(DayType) |> summarise(across(ang_hrs, sum), .groups = "drop")
#   ests$effort_ts_s_at_dt_mean_filled |> group_by(angler_type) |> summarise(across(ang_hrs, sum), .groups = "drop")
#   ests$effort_ts_s_at_dt_mean_filled |> group_by(DayType, angler_type) |> summarise(across(ang_hrs, sum), .groups = "drop")
#   ests$effort_ts_s_at_dt_mean_filled |> group_by(time_strata) |> summarise(across(ang_hrs, sum), .groups = "drop")
#   ests$effort_ts_s_at_dt_mean_filled |> group_by(time_strata, DayType) |> summarise(across(ang_hrs, sum), .groups = "drop")
#   ests$effort_ts_s_at_dt_mean_filled |> group_by(time_strata, angler_type) |> summarise(across(ang_hrs, sum), .groups = "drop")
#   ests$effort_ts_s_at_dt_mean_filled |> group_by(time_strata, DayType, section, angler_type) |> summarise(across(ang_hrs, sum), .groups = "drop")

  ests$effort_ts_s_at <- ests$effort |> 
    group_by(time_strata, section, angler_type) |>
    summarize(
      n_obs = sum(!is.na(ang_hrs_daily_mean_TI_expan)), #n_days = n(),
      across(
        .cols = c(ang_hrs_daily_mean_TI_expan),
        .fns = list(
          mean = ~mean(.x, na.rm = T),
          var = ~var(.x, na.rm = T)
          ), #sd = ~sd(.x, na.rm = T), med = ~median(.x, na.rm=T),
        .names = "ang_hrs_{.fn}"
      ), .groups = "drop") |> 
    right_join(
      creel$days_total |> 
        group_by(time_strata, section) |> 
        summarise(N_days = sum(N_days), .groups = "drop"),
      by = c("time_strata", "section")) |> 
#!!not sure this is correct - could/should recalc df for within-week/month?
    left_join(pe$df |> distinct(section, angler_type, df), by = c("section", "angler_type")) |> 
#!!this carries forward the orig variance eqns but not sure if
#!!1) eqns are correctly implemented or 
#!!2) eqns are meaningful relative to the ang_hrs_var already present from base var() 
#!! i.e., the 3rd term "adjustment coef" in the first case 
#!! acts to reduce the first 2 terms' computed "variance", and is asymptotic to 0 for complete sampling
#!! such that case logic prevents 0 total_effort_var at n_obs==N_days 
    mutate(
      total_effort = N_days * ang_hrs_mean,
      total_effort_var = if_else(
        n_obs < N_days,
        (N_days^2) * (ang_hrs_var / n_obs) * (1-(n_obs/N_days)),
        (N_days^2) * (ang_hrs_var / n_obs)
      ),
      lwr95CI = total_effort - qt(1-(0.05/2),df)*(total_effort_var^0.5),
      upr95CI = total_effort + qt(1-(0.05/2),df)*(total_effort_var^0.5)
    ) 

#these DO NOT match...
#the former takes means within DayTypes per week strata
#whereas the latter takes means across DayTypes per week strata... 
ests$effort_ts_s_at_dt_mean_filled |> summarise(across(ang_hrs, sum), .groups = "drop")
ests$effort_ts_s_at |> summarise(across(total_effort, sum), .groups = "drop")

left_join(
  ests$effort_ts_s_at |> print(n=nrow(ests$effort_ts_s_at))
  ,  
  ests$effort_ts_s_at_dt_mean_filled |> group_by(time_strata, section, angler_type) |> summarise(across(ang_hrs, sum), .groups = "drop")
  ,
  by = c("time_strata","section","angler_type")
) |> 
  mutate(d = total_effort - ang_hrs) |> 
  select(time_strata, angler_type, total_effort, ang_hrs) |> 
  pivot_longer(c(total_effort, ang_hrs), names_to = "var", values_to = "val") |> 
  ggplot(aes(factor(time_strata), val, fill = var)) + geom_col(position = "dodge") + facet_wrap(~angler_type)

#!!illustrating a further case...
  ests$effort_s_at <- ests$effort |> 
    group_by(section, angler_type) |>
    summarize(
      n_obs = sum(!is.na(ang_hrs_daily_mean_TI_expan)), #n_days = n(),
      across(
        .cols = c(ang_hrs_daily_mean_TI_expan),
        .fns = list(
          mean = ~mean(.x, na.rm = T),
          var = ~var(.x, na.rm = T)
          ), #sd = ~sd(.x, na.rm = T), med = ~median(.x, na.rm=T),
        .names = "ang_hrs_{.fn}"
      ), .groups = "drop") |> 
    right_join(
      creel$days_total |> 
        group_by(section) |> 
        summarise(N_days = sum(N_days), .groups = "drop"),
      by = c("section")) |> 
    left_join(pe$df |> distinct(section, angler_type, df), by = c("section", "angler_type")) |> 
    mutate(
      total_effort = N_days * ang_hrs_mean,
      total_effort_var = if_else(
        n_obs < N_days,
        (N_days^2) * (ang_hrs_var / n_obs) * (1-(n_obs/N_days)),
        (N_days^2) * (ang_hrs_var / n_obs)
      ),
      lwr95CI = total_effort - qt(1-(0.05/2),df)*(total_effort_var^0.5),
      upr95CI = total_effort + qt(1-(0.05/2),df)*(total_effort_var^0.5)
    ) 
#yet another distinct (higher) total estimate...
ests$effort_s_at |> summarise(across(total_effort, sum), .groups = "drop")
#peak obs inflate means that are then applied to all days...?
ests$effort_ts_s_at_dt_mean_filled |> group_by(section, angler_type) |>  summarise(across(ang_hrs, sum), .groups = "drop")
ests$effort_ts_s_at |> group_by(section, angler_type) |> summarise(across(total_effort, sum), .groups = "drop")
ests$effort_s_at



  pe$daily_CPUE |>
    group_by(time_strata, DayType, section, angler_type, catch_group) |>
    summarize(
      across(
        c(catch_estimate),
        .fns = list(med = median, mean = mean, var = var, sd = sd)
      ),
      .groups = "drop")
  
  
#   #### effort summaries  --------------
# 
# #!! DA - I THINK THIS IS NOW BROKEN BY UPSTREAM CHANGES TO INCOMING OBJECTS 
# #!! IN ADDITION, UNCLEAR WHAT IS REALLY NEEDED/WANTED
# 
#   #!!how was distinct() meant to play with still-grouped summarize output?
#   # calculate effort by day type and angler type strata
#   ests$time_strata_effort_by_daytype <- pe$daily_CPUE |>
#     group_by(section, angler_type, time_strata, DayType, n_days, N_days) |>
#     summarize(
#       n = n(),
#       sum_daily_effort_sampled_days = sum(ang_hrs_daily_mean_TI_expan),
#       angler_hours_daily_mean = mean(ang_hrs_daily_mean_TI_expan),
#       variance_daily_effort = var(ang_hrs_daily_mean_TI_expan),
#       total_effort = angler_hours_daily_mean * N_days,
#       variance_total_daily_effort = if_else(
#         n_days < N_days,
#         (N_days^2) * (variance_daily_effort / n_days) * (1-(n_days/N_days)),
#         (N_days^2) * (variance_daily_effort / n_days)
#       ),
# #!!THIS MAY BE WRONG but need to explicitly specify .groups if otherwise
#       .groups = "keep"
#     ) |>
#     distinct()
# 
#   #!!Not sure about left_join on still-grouped summarize output? i.e., with just time_strata dropped?
#   #!!the col named "SE" is standard deviation not standard error
#   #!!not sure which is desired? if sd, could also use sd()?
#   #!!moved filter() up; confirm relative to left_join of degfreedom?
#   # Sum effort estimates across day types, retain grouping on angler type
#   ests$time_strata_effort_total <- ests$time_strata_effort_by_daytype |>
#     filter(angler_type %in% c("bank","boat")) |>
#     group_by(section, angler_type, time_strata) |>
#     summarise(
#       total_effort = sum(total_effort),
#       variance = sum(variance_total_daily_effort),
# #!!THIS MAY BE WRONG but need to explicitly specify .groups if otherwise
#       .groups = "keep"
#     ) |>
#     left_join(pe$degrees_freedom, by = c("section", "angler_type")) |>
#     mutate(
#       variance = replace_na(variance,0),
#       SE = sqrt(variance),
#       CV = SE / total_effort,
#       lwr95CI = total_effort - qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
#       upr95CI = total_effort + qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
#       across(where(is.numeric), round, 2)
#     ) |>
#     distinct(time_strata, angler_type, .keep_all = TRUE)
# 
#   #!!this gets overwritten below...?
#   #!!may be able to drop ungroup if dealt with earlier?
#   ests$total_effort <- ungroup(ests$time_strata_effort_total) |>
#     summarize(total_effort = sum(total_effort, na.rm = T))
# 
#   #### catch summaries  --------------
# 
#   #!!as above, concern/questions about (double) distinct()
#   #!!and this exits the pipe still grouped...
#   # calculate catch by day type and angler type strata
#   ests$time_strata_catch_by_daytype <- pe$daily_CPUE |>
#     filter(!is.na(catch_estimate)) |>
#     group_by(section, angler_type, catch_group, time_strata, DayType, n_days, N_days) |>
#     summarize(
#       total_catch_unexpanded = sum(catch_estimate),
#       mean_daily_catch = total_catch_unexpanded / n_days,
#       total_catch_expanded_2 = total_catch_unexpanded * N_days,
#       total_catch_expanded = mean_daily_catch * N_days,
#       variance_catch_estimate = var(catch_estimate),
#       n_days = mean(n_days),
#       N_days = mean(N_days),
# #!!THIS MAY BE WRONG but need to explicitly specify .groups if otherwise
# #!!What is going on with the double distinct()??
#       .groups = "keep"
#       ) |>
#     distinct() |>
#     mutate(
#       variance_catch_estimate = replace_na(variance_catch_estimate, 0),
#       variance_total_catch_expanded = if_else(
#         n_days < N_days,
#         (N_days^2) * (variance_catch_estimate / n_days) * (1-(n_days/N_days)),
#         (N_days^2) * (variance_catch_estimate / n_days))
#     ) |>
#     distinct()
# 
#   # cannot calculate variance for estimates when n = 1 for daytype strata within a week
#   # Sum catch estimates across day types, retain grouping on angler type
#   ests$time_strata_catch_total <- ests$time_strata_catch_by_daytype |>
#     filter(angler_type %in% c("bank", "boat")) |>
#     group_by(section, time_strata, catch_group, angler_type) |>
#     summarise(
#       total_catch = sum(total_catch_expanded),
#       variance = sum(variance_total_catch_expanded),
# #!!THIS MAY BE WRONG but need to explicitly specify .groups if otherwise
#       .groups = "keep"
#     ) |>
#     left_join(pe$degrees_freedom, by = c("section", "angler_type")) |>
#     mutate(
#       variance = replace_na(variance, 0),
#       SE = sqrt(variance),
#       CV = SE / total_catch,
#       lwr95CI = total_catch - qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
#       upr95CI = total_catch + qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
#       across(where(is.numeric), round, 2)
#     ) |>
#     distinct() |>
#     arrange(section, catch_group, time_strata)
# 
#   #!!as above for ests$total_effort, currently getting overwritten below
#   ests$total_catch <- ests$time_strata_catch_total |>
#     group_by(section, catch_group) |>
#     summarize(total_catch = sum(total_catch), .groups = "drop")
# 
#   #### totals -------
# 
#   #!!from unnamed chunk L1540
#   #!!DA looks like this may only be for weekly? at least the first mutate seems wrong for monthly strata?
#   # EB circle back to this for calculating CPUE / HPUE and associated uncertainty over time period of interest
#   ests$cpue_time_strata <- dplyr::left_join(
#     ests$time_strata_catch_total  |>
#       dplyr::select(
#         section, time_strata, angler_type, catch_group,
#         total_catch, variance, SE, CV, lwr95CI, upr95CI
#       ) |>
#       mutate(daily_catch_estimate = total_catch / 7)
#     ,
#     ests$time_strata_effort_total |>
#       dplyr::select(
#         section, time_strata, angler_type,
#         total_effort, variance, SE, CV, lwr95CI, upr95CI),
#     by = c("section","angler_type","time_strata"),
#     suffix = c("_catch", "_effort")
#     ) |>
#     mutate(
#       across(where(is.numeric), round, 2),
#       cpue_time_strata = replace_na(total_catch / total_effort, 0),
#       cpue_lwr95_time_strata = replace_na(lwr95CI_catch / lwr95CI_effort, 0),
#       cpue_upr95_time_strata = replace_na(upr95CI_catch / upr95CI_effort, 0)
#     ) |>
# #!! really??
#     distinct()
# 
#   #!!DA on L1689 assigned to estimates list then (possibly) overwrites the previously created non-list version
#   # Adding together time strata specific effort estimates and associated variance and calculating SE, CV, and 95% CI's
#   ests$total_effort <- ests$time_strata_effort_total |>
#     dplyr::select(-c(min_n_days, sum_n_days, degrees_freedom)) |>
#     dplyr::left_join(ests$degrees_freedom_total, by = c("section", "angler_type")) |>
#     dplyr::group_by(section, angler_type) |>
#     dplyr::summarise(
#       total_effort = sum(total_effort),
#       variance = sum(variance),
#       SE = sqrt(variance),
#       CV = SE / total_effort,
#       lwr95CI = total_effort - qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
#       upr95CI = total_effort + qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
# #!!This "drop" may be incorrect depending on the intent of the following distinct()
# #!!but if so we should be explicit about the group intent with "keep" or "drop_last"
#       .groups = "drop"
#     ) |>
#     dplyr::distinct() |>
#     dplyr::mutate(across(where(is.numeric), round, 2)) |>
#     dplyr::arrange(section)
# 
#   # Adding together time_strata catch estimates and associated variance and calculating SE, CV, and 95% CI's
#   ests$total_catch <- ests$time_strata_catch_total |>
#     dplyr::select(-c(min_n_days, sum_n_days, degrees_freedom)) |>
#     dplyr::left_join(ests$degrees_freedom_total, by = c("section", "angler_type")) |>
#     dplyr::filter(angler_type %in% c("bank", "boat")) |>
#     dplyr::mutate(variance = replace_na(variance, 0)) |>
#     dplyr::group_by(catch_group, section, angler_type) |>
#     dplyr::summarise(
#       total_catch = sum(total_catch),
#       variance = sum(variance),
#       SE = sqrt(variance),
#       CV = SE / total_catch,
#       lwr95CI = total_catch - qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
#       upr95CI = total_catch + qt(1-(0.05/2),degrees_freedom)*(variance^0.5),
# #!!As immediately above, this "drop" may be incorrect depending on the intent of the following distinct()
# #!!but if so we should be explicit about the group intent with "keep" or "drop_last"
#       .groups = "drop"
#     ) |>
#     dplyr::distinct() |>
#     dplyr::mutate(across(where(is.numeric), round, 2)) |>
#     dplyr::arrange(section, catch_group)
# 
  
}) |> 
  bindEvent(input$estimate)
```


Data from DWG
============================================

Event and Days
--------------------------------------------

### Event

```{r gt_creel_event}
render_gt({ 
  if(!is.null(creel$event)) {
    creel$event |> count(water_body, tie_in_indicator) 
    }
  })
```

### Days

```{r gt_creel_days}
render_gt({ 
  if(!is.null(creel$days_total)) {
  creel$days_total |> pivot_wider(names_from = DayType, values_from = N_days)
  }
})
```


Effort
--------------------------------------------

### Effort

```{r gt_creel_effort}
render_gt({ 
  if(!is.null(creel$event)) {
    creel$effort |> count(water_body, section, tie_in_indicator, location)
  }
})
```

Interview
--------------------------------------------

### Interview

```{r gt_creel_interview}
render_gt({ head(creel$interview) })
```

Catch
--------------------------------------------

### Catch

```{r gt_creel_catch}
render_gt({ head(creel$catch) })
```


Effort
============================================

Census
--------------------------------------------

### Census counts

```{r}
#render_gt({ pe$effort_census })

renderPlot({
  if(!is.null(pe$effort_census)) { #creel$effort
    pe$effort_census |>
      ggplot(aes(event_date, count_census, fill = factor(count_sequence))) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + angler_type, scales = "free", labeller = label_wrap_gen(multi_line = F))
  }
})

```

Index
--------------------------------------------

### Index counts

```{r}
renderPlot({
  if(!is.null(pe$effort_index)) { #creel$effort
    pe$effort_index |>
      ggplot(aes(event_date, count_index, fill = factor(count_sequence))) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + count_type + angler_type, scales = "free", labeller = label_wrap_gen(multi_line = F))
  }
})

```


Interview
============================================

Interview
--------------------------------------------

### Interview

```{r}
renderPlot({
  if(!is.null(pe$interview)) { #creel$interview
    pe$interview |>
      mutate(event_date = format(event_date, "%m-%d")) |> 
      ggplot(aes(event_date, angler_hours_total, fill = angler_type)) +
      geom_boxplot(position = position_dodge(), outlier.shape = NA) +
      geom_jitter(width = 0.5) +
      scale_x_discrete(guide = guide_axis(angle = 90)) +
      facet_wrap(~section + angler_type, scales = "free", labeller = label_wrap_gen(multi_line = F), ncol = 1) 
  }
})

```

Catch
--------------------------------------------

### Catch

```{r}
renderPlot({
  if(!is.null(pe$interview_and_catch)) { #creel$interview
    pe$interview_and_catch |>
      group_by(event_date, time_strata, section, angler_type, catch_group) |> 
      summarise(fish_count = sum(fish_count), .groups = "drop") |> 
      # separate(catch_group, into = c("species", "life_stage", "mark", "fate"), sep = "_", remove = T, fill = "right") |> 
      # pivot_wider(names_from = c(life_stage, mark, fate), values_from = fish_count)
      ggplot(aes(event_date, catch_group, size = fish_count, color = fish_count)) +
      geom_point() +
      scale_size_area() + scale_color_binned() +
      scale_x_date("") + scale_y_discrete("") +
      facet_wrap(~section + angler_type, scales = "fixed", labeller = label_wrap_gen(multi_line = F))
  }
})

```

Estimates
============================================

### Effort estimates 

```{r}
renderPlot({
  if(!is.null(ests$effort)){
    (
      ggplot(pe$angler_hours_daily_mean,
             aes(event_date, ang_hrs_daily_mean_TI_expan, fill = angler_type)) +
        geom_col(position = "stack") +
        scale_x_date("", date_breaks = "1 week", guide = guide_axis(n.dodge = 2)) +
        scale_y_continuous("Hours") +
        labs(
          title = "Daily estimated angler hours, sampled days",
          subtitle = "Census-adjusted and interview-informed index counts")
    ) + (
      ggplot(ests$effort,
             aes(event_date, ang_hrs, fill = angler_type)) +
        geom_col(position = "stack") +
        scale_x_date("", date_breaks = "1 week", guide = guide_axis(n.dodge = 2)) +
        scale_y_continuous("Hours") +
        labs(
          title = "Daily estimated angler hours, strata-means to complete days",
          subtitle = "Census-adjusted and interview-informed index counts")
    ) + (
      ggplot(ests$effort |> group_by(angler_type) |> mutate(ang_hrs_cml = cumsum(ang_hrs)) |> ungroup(),
             aes(event_date, ang_hrs_cml, color = angler_type)) +
        geom_line() +
        scale_x_date("", date_breaks = "1 week", guide = guide_axis(n.dodge = 2)) +
        scale_y_continuous("Hours") +
        labs(
          title = "Cumulative angler hours, strata-means to complete days",
          subtitle = "Census-adjusted and interview-informed index counts")
    ) + plot_layout(ncol = 1)
    
  }
})


# renderValueBox({
#   if(!is.null(ests$total_effort)){
#     valueBox(ests$total_effort |> filter(angler_type == "bank") |> pluck("total_effort") |> round())
#   }
# })

# render_gt({
#   if(!is.null(ests$total_effort)){
#     ests$total_effort
#   }
# })

```

### total catch

```{r}
# render_gt({
#   if(!is.null(ests$total_catch)){
#     ests$total_catch
#   }
# })

```

About
============================================

Anything to cite/link to?

WDFW gathers fishing information from anglers around the state: <a href="https://wdfw.wa.gov/fishing/reports/creel"> https://wdfw.wa.gov/fishing/reports/creel</a>
