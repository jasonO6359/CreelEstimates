---
title: "FW Creel Point Estimate"
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    source_code: embed
    theme:
      version: 4
      bootswatch: default
      bg: "#D0D0D0"
      fg: "#000000"
      navbar-bg: "#1189D9"
      primary: "#1189D9"
runtime: shiny
---

```{r setup, include=FALSE}
#bslib::bs_themer()

library("flexdashboard")
library("tidyverse")
library("shiny")
library("patchwork")
library("gt")

#base endpoints
dwg_base <- list(
  event = "https://data.wa.gov/resource/ui95-axtn.csv",
  effort = "https://data.wa.gov/resource/h9a6-g38s.csv",
  interview = "https://data.wa.gov/resource/rpax-ahqm.csv",
  catch = "https://data.wa.gov/resource/6y4e-8ftk.csv",
  gear = "https://data.wa.gov/resource/d2ks-afhz.csv" #currently unused?
)

#water_body options by proj_name options
proj_levels <- list(
  `R5 Steelhead` = list("Kalama River"),
  `District 13` = list("Skykomish River", "Tokul Creek"),
  `District 14` = list("Cascade River", "Sauk River", "Skagit River")
)

#lookup objects created below
load("fw_creel_dash_envi.RData")

creel <- reactiveValues() #will hold resulting data objects ##event = NULL, effort = NULL, interview = NULL, catch = NULL

```

```{r build_envi, eval=FALSE}
# # uncomment to rebuild...
# 
# dates_holidays_2015_2030 <- read_lines("input_files/dates_holidays_2015_2030.txt") |>
#   as.Date(format="%Y-%m-%d")
# 
# # river_loc_all <- list.files("input_files", pattern = "River.Location", full.names = T) |>
# #   set_names() |>
# #   map(readr::read_csv)
# river_loc_all <- readr::read_csv("input_files/river_locations_master.csv")
# 
# #excludes "master"; read_csv("input_files/lut_water_body_location_master_2022_01_28.csv") |> distinct(water_body_desc)
# sections_all <- list.files("input_files", pattern = "lut_water_body_location_", full.names = T)[-8] |>
#   set_names() |>
#   map(readr::read_csv)
# 
# census_expansion_all <- list.files("input_files", pattern = "Proportional", full.names = T) |>
#   set_names() |>
#   map(readr::read_csv)
# 
# #names(river_loc_all) <- tools::file_path_sans_ext(basename(names(river_loc_all)))
# names(sections_all) <- tools::file_path_sans_ext(basename(names(sections_all))) #|> str_remove("lut_water_body_location_")
# names(census_expansion_all) <- tools::file_path_sans_ext(basename(names(census_expansion_all))) #|> str_remove("lut_Proportional_Expansions_for_Tie_In_")
# 
# #save.image("fw_creel_dash_envi.RData")

```


Controls {.sidebar data-width=350}
============================================

###

```{r input_selectors}
selectInput(inputId = 'proj_name', label = 'Project Name', choices = names(proj_levels)
            , selected = "District 14"
            )

selectizeInput(inputId = 'water_body', label = 'Water Body', choices = proj_levels, multiple = TRUE
               , selected = "Cascade River"
               )

dateRangeInput(inputId = 'dates', label = "Date range"
               , start = "2021-09-16", end = "2021-10-16" 
               )


selectInput(inputId = 'sections', label = 'Sections', choices = names(sections_all), multiple = FALSE
            , selected = "lut_water_body_location_d14_cascade_fall_salmon"
            )
# selectInput(inputId = 'river_loc', label = 'River Lat/Lon', choices = names(river_loc_all), multiple = FALSE
#             , selected = "lut_River.Locations_2019-01-07"
#             )
selectInput(inputId = 'census_exp', label = 'Census Expansion LU', choices = names(census_expansion_all), multiple = FALSE
            , selected = "lut_Proportional_Expansions_for_Tie_In_Sections_Cascade_Fall_Salmon_2021"
            )


radioButtons(inputId = 'model_period', label = "Model period", choices = c("Week", "Month")
             , selected = "Week"
             )

radioButtons(inputId = 'index_count_types', label = "Index count types", 
             choices = c("Bank/Boat Anglers", "Vehicle/Trailers Only")
             ,selected = c("Vehicle/Trailers Only")
             )

radioButtons(inputId = 'census_expansion', label = "Census expansion method", 
             choices = c("Direct", "Indirect")
             ,selected = c("Direct")
             )

# #can add option to manually upload ...
# fileInput(inputId = 'sections', label = 'Sections LU', accept = ".csv")

```

###

```{r dwg_fetch}
actionButton("fetch", label = "Fetch raw data")

#fire the requests on button push
#!! note this excludes effort and interview rows
#!! with no section assigned from section LU

# creel <- list()
# input <- list()
# input$proj_name <- "District 14"
# input$water_body <- "Cascade River"
# input$dates <- c(as.Date("2021-09-16", "%Y-%m-%d"), as.Date("2021-11-30", "%Y-%m-%d"))
# input$model_period <- "Week"
# input$index_count_types <- "Vehicle/Trailers Only" #c("Vehicle Only","Trailers Only")
# input$census_expansion <- "Direct"
# 
# input$sections <- "lut_water_body_location_d14_cascade_fall_salmon"
# #input$river_loc <- "lut_River.Locations_2019-01-07"
# input$census_exp <- "lut_Proportional_Expansions_for_Tie_In_Sections_Cascade_Fall_Salmon_2021"
# sections <- dplyr::select(sections_all[[input$sections]], water_body_desc, location = location_code, section)
# #river_loc <- river_loc_all[[input$river_loc]]
# river_loc <- dplyr::filter(river_loc_all, River %in% input$water_body)
# census_exp <- if(str_detect(input$index_count_types, "Vehicle|Trailer")) {
#     census_expansion_all[[input$census_exp]] |>
#       mutate(
#         angler_type = if_else(angler_type == "bank", "total", "boat"),
#         cen_exp_meth = input$census_expansion)
#   } else {
#     census_expansion_all[[input$census_exp]] |>
#       mutate(cen_exp_meth = input$census_expansion)
#     }


  
sections <- reactive({
  dplyr::select(sections_all[[input$sections]], water_body_desc, location = location_code, section)
})

#!!NOT YET GENERIC TO MULTIPLE WATER_BODY(s) AND ROWS IN MASTER 
#!!ONLY USED IN DAY-LENGTH CALCULATION? WORK AROUND IS JUST SLICE(1)
river_loc <- reactive({
  #river_loc_all[[input$river_loc]]
  dplyr::filter(river_loc_all, River %in% input$water_body)
})

census_exp <- reactive({
  ## fix angler type in census expansion table for use with vehicle / trailer counts so it joins to TI_expan table
  if(str_detect(input$index_count_types, "Vehicle|Trailer")) {
    census_expansion_all[[input$census_exp]] |> 
      mutate(
        angler_type = if_else(angler_type == "bank", "total", "boat"),
        cen_exp_meth = input$census_expansion
        )
  } else {
    census_expansion_all[[input$census_exp]] |> 
      mutate(cen_exp_meth = input$census_expansion)
    }
})

#this is "event reactive", so should not trigger on fiddling with inputs
#but only when "fetch" button is clicked (see last few lines of chunk)
reactive({
  creel$event <- paste0(
    dwg_base$event,
    "?$where=project_name in('", input$proj_name, "')",
    " AND water_body in('", paste0(input$water_body, collapse = "','"), "')",
    " AND event_date between '", input$dates[1],
    "T00:00:00' and '", input$dates[2],
    "T00:00:00'&$limit=100000"
    ) |>
    utils::URLencode() |>
    readr::read_csv(show_col_types = F) |>
    dplyr::select(creel_event_id, water_body, event_date, tie_in_indicator)
  
  if(nrow(creel$event) > 0) {
    
    creel$effort <- paste0(
      dwg_base$effort,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::filter(!is.na(count_type)) |> 
      dplyr::select(-created_datetime, -modified_datetime) |> 
      dplyr::left_join(sections, by = c("location")) |> 
#      dplyr::left_join(sections(), by = c("location")) |> 
      dplyr::filter(!is.na(section))

    creel$interview <- paste0(
      dwg_base$interview,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::rename(location = interview_location) |> 
      dplyr::select(
        -created_datetime, -modified_datetime,
        -state_residence, -zip_code) |> 
      dplyr::left_join(sections, by = c("location")) |> 
#      dplyr::left_join(sections(), by = c("location")) |> 
      dplyr::filter(!is.na(section))
    
    creel$catch <- paste0(
      dwg_base$catch,
      "?$where=creel_event_id in('",
      paste(creel$event$creel_event_id, collapse = "','"),
      "')&$limit=100000"
      ) |> 
      utils::URLencode() |>
      readr::read_csv(show_col_types = F) |>
      dplyr::select(interview_id, catch_id, species, run, life_stage, fin_mark, fate, fish_count) |> 
      dplyr::mutate(
        life_stage = replace_na(life_stage, "Adult"), # placeholder pending data corrections in fish apps 
        catch_group = paste(species, life_stage, fin_mark, fate, sep = "_") # fish catch groups to estimate catch of 
      )
    
    ##seems somewhat inefficient to (potentially) rebuild, but takes a reactive dependence on input$dates and river_loc...
    #and this whole chunk depends on button push, so "lazy" against fiddling
    creel$days <- tibble::tibble(
      event_date = seq.Date(input$dates[1], input$dates[2], by = "day"),
      Day = weekdays(event_date),
      DayType = if_else(
        Day == "Saturday" | Day == "Sunday" | Day %in% dates_holidays_2015_2030,
        "Weekend", "Weekday"),
      DayType_num = if_else(str_detect(DayType, "end"),1,0),
      DayL = suncalc::getSunlightTimes(
        date = event_date,
        tz = "America/Los_Angeles",
         lat = river_loc$Lat,
         lon = river_loc$Long,
#        lat = river_loc()$Lat,
#        lon = river_loc()$Long,
        keep=c("dawn", "dusk")
      ) |>
        mutate(DayL = as.numeric(dusk - dawn)) |>
        pluck("DayL"),
      Week = as.numeric(format(event_date, "%V")),
      Month = as.numeric(format(event_date, "%m")),
      ModelPeriod = input$model_period
    ) |>
      tibble::rowid_to_column(var = "day_index") |>
      #make open section cols (only those actually used, not all in LU)
      left_join(
        expand_grid(
          event_date = seq.Date(input$dates[1], input$dates[2], by = "day"),
          s = paste0("open_section_", sort(unique(creel$effort$section))),
          closure_code = TRUE
        ) |>
          pivot_wider(names_from = s, values_from = closure_code)
        ,
        by = "event_date")

    #closures, super ugly, needs rethinking
    creel$days <- rows_upsert(
      creel$days,
      bind_rows(
        # 2022 Upper Skagit Chinook
        # tibble(section = "1", closure_begin = "2021-05-31", closure_end = "2021-05-31")

        # 2021 Skagit winter steelhead closure dates
        # tibble(section = "1,2", closure_begin = "2021-02-03", closure_end = "2021-02-05"),
        # tibble(section = "1,2", closure_begin = "2021-02-10", closure_end = "2021-02-12"),
        # tibble(section = "1,2", closure_begin = "2021-02-17", closure_end = "2021-02-19"),
        # tibble(section = "1,2", closure_begin = "2021-02-24", closure_end = "2021-02-26"),
        # tibble(section = "1,2", closure_begin = "2021-03-03", closure_end = "2021-03-05"),
        # tibble(section = "1,2", closure_begin = "2021-03-10", closure_end = "2021-03-12"),
        # tibble(section = "1,2", closure_begin = "2021-03-17", closure_end = "2021-03-19"),
        # tibble(section = "1,2", closure_begin = "2021-03-24", closure_end = "2021-03-26"),
        # tibble(section = "1,2", closure_begin = "2021-03-31", closure_end = "2021-04-02"),
        # tibble(section = "1,2", closure_begin = "2021-04-07", closure_end = "2021-04-09")
        # tibble(section = "1", closure_begin = "2016-04-30", closure_end = "2016-04-30") # placeholder closure date; need to supply at least one

        # kalama
        # tibble(section = "1,2,3", closure_begin = "2016-04-30", closure_end = "2016-04-30")
        # placeholder closure date; need to supply at least onedate here because we use open / closed dates to determine times_strata estimation periods (field n_days further down in code)

        # Cascade
        tibble(section = "1", closure_begin = "2021-09-18", closure_end = "2021-09-18"), # river out due to flows
        tibble(section = "1", closure_begin = "2021-09-19", closure_end = "2021-09-20"), # treaty fishery closure
        tibble(section = "1", closure_begin = "2021-09-26", closure_end = "2021-09-27"), # treaty fishery closure
        tibble(section = "1", closure_begin = "2021-10-03", closure_end = "2021-10-04"), # treaty fishery closure
        tibble(section = "1", closure_begin = "2021-11-13", closure_end = "2021-11-14"), # river out due to flows
        tibble(section = "1", closure_begin = "2021-11-17", closure_end = "2021-11-18") # river out due to flows

        #other Skagit?
        # tibble(section = "2,3", closure_begin = "2021-08-19", closure_end = "2021-08-31"),
        # tibble(section = "2", closure_begin = "2021-09-01", closure_end = "2021-09-01"), # treaty fishery closure
        # tibble(section = "2", closure_begin = "2021-09-07", closure_end = "2021-09-09"), # treaty fishery closure
        # tibble(section = "2", closure_begin = "2021-09-14", closure_end = "2021-09-16"), # treaty fishery closure
        # tibble(section = "1,2,3", closure_begin = "2021-09-18", closure_end = "2021-09-18"), # river out due to flows
        # tibble(section = "2", closure_begin = "2021-10-05", closure_end = "2021-10-06"), # treaty fishery closure
        # tibble(section = "2", closure_begin = "2021-10-12", closure_end = "2021-10-13"), # treaty fishery closure
        # tibble(section = "2", closure_begin = "2021-10-19", closure_end = "2021-10-20"), # treaty fishery closure
        # tibble(section = "1,2,3", closure_begin = "2021-11-13", closure_end = "2021-11-14"), # river out due to flows
        # tibble(section = "1,2,3", closure_begin = "2021-11-17", closure_end = "2021-11-18") # river out due to flows

        # tibble(section = "3,4,5", closure_begin = "2021-08-19", closure_end = "2021-08-31"),
        # tibble(section = "3", closure_begin = "2021-09-01", closure_end = "2021-09-01"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-09-07", closure_end = "2021-09-09"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-09-14", closure_end = "2021-09-16"), # treaty fishery closure
        # tibble(section = "1,2,3,4,5", closure_begin = "2021-09-18", closure_end = "2021-09-18"), # river out due to flows
        # tibble(section = "3", closure_begin = "2021-10-05", closure_end = "2021-10-06"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-10-12", closure_end = "2021-10-13"), # treaty fishery closure
        # tibble(section = "3", closure_begin = "2021-10-19", closure_end = "2021-10-20"), # treaty fishery closure
        # tibble(section = "1,2,3,4,5", closure_begin = "2021-11-13", closure_end = "2021-11-14"), # river out due to flows
        # tibble(section = "1,2,3,4,5", closure_begin = "2021-11-17", closure_end = "2021-11-18") # river out due to flows
      ) |>
        rowwise() |>
        mutate(closure_date = paste(seq.Date(as.Date(closure_begin), as.Date(closure_end), by = "day"), collapse = ",")) |>
        separate_rows(closure_date, sep = ",") |>
        select(event_date = closure_date, section) |>
        mutate(
          event_date = as.Date(event_date),
          closure_code = FALSE # TB - The 1e-06 is needed to keep the model from crashing ?log-normal parameters cant be 0
        ) |>
        separate_rows(section, sep = ",") |>
        pivot_wider(names_from = section, names_prefix = "open_section_", values_from = closure_code) |>
        mutate(across(starts_with("open_section_"), ~replace_na(., TRUE)))
      ,
      by ="event_date"
    )

  } else {
    creel$effort <- NULL
    creel$interview <- NULL
    creel$catch <- NULL
  }
}) |> 
  bindEvent(input$fetch)
  
```


Data
============================================

```{r eval=FALSE}
# renderPrint(input$proj_name)
# renderPrint(input$water_body)
# renderPrint({paste(input$dates[1], "to", input$dates[2])})
```

Event and Days
--------------------------------------------

### Event

```{r}
render_gt({ head(creel$event) })
```

### Days

```{r}
#renderPrint({str(days)})
render_gt({ head(creel$days) })
```


Effort
--------------------------------------------

### Effort

```{r}
render_gt({ head(creel$effort) })
```

Interview
--------------------------------------------

### Interview

```{r}
render_gt({ head(creel$interview) })
```

Catch
--------------------------------------------

### Catch

```{r}
render_gt({ head(creel$catch) })
```


Effort/Interview
============================================

```{r prep_effort_interview, include = FALSE}
#Aggregate census (tie in) effort counts, associating to closest-in-time index count.
#take the initial effort_census, with all count_sequence == 1,
#add/overwrite the count_sequence val with that from closest temporal match from inline/anonymous paired counts object

#could remove the left_join of days? appears to only be used here for day_index, which used only for stan?
#or leave with idea that an endpoint of this could be objects ready for stan?

pe_effort_census <- reactive({
  dplyr::left_join(
    creel$effort |> 
      dplyr::filter(tie_in_indicator == 1) |>
      dplyr::select(event_date, water_body, water_body_desc, location, section, tie_in_indicator, count_type, count_quantity)
    ,
    #reassign count_seq from closest index
    dplyr::left_join(
      creel$effort |> dplyr::filter(tie_in_indicator == 1) |> dplyr::distinct(event_date, section, location, tie_in_indicator, effort_start_time, count_sequence),
      creel$effort |> dplyr::filter(tie_in_indicator == 0) |> dplyr::distinct(event_date, section, location, tie_in_indicator, effort_start_time, count_sequence),
      by = c("event_date", "section"),
      suffix = c("_cen", "_ind")
      ) |>
      dplyr::group_by(event_date, section, location_cen) |>
      dplyr::slice_min(abs(effort_start_time_cen - effort_start_time_ind), n = 1) |>
      dplyr::ungroup() |>
      dplyr::distinct(event_date, section, location = location_cen, count_sequence = count_sequence_ind)
    ,
    by = c("event_date", "section", "location")
  ) |>
    dplyr::left_join(creel$days, by = "event_date") |>
    dplyr::mutate(
      angler_type = dplyr::case_when(
        stringr::word(count_type, 1) %in% c("Bank","bank","Shore") ~ "bank",
        stringr::word(count_type, 1) %in% c("Boat","boat") ~ "boat" #Note "Boats" plural intentionally excluded
      )
    ) |>
    dplyr::filter(!is.na(angler_type)) |>
    dplyr::group_by(event_date, day_index, section, tie_in_indicator, count_sequence, angler_type) |>
    dplyr::summarize(count_census = sum(count_quantity), .groups = "drop") |>
    dplyr::arrange(event_date, section, count_sequence) |>
    tidyr::drop_na(count_sequence) #-> pe_effort_census
})

#combines several intermediates from CreelPointEstimate_Dev
#mutate angler_type here creates a later join-by column
pe_effort_index <- reactive({
  dplyr::filter(
    creel$effort, 
    tie_in_indicator == 0,
    is.na(no_count_reason),
    !is.na(count_type)
    #,count_type %in% input$index_count_types
    ) |>
  dplyr::group_by(event_date, section, count_sequence, count_type) |>
  dplyr::summarise(count_index = sum(count_quantity), .groups = "drop") |>
  dplyr::mutate(
    angler_type = dplyr::case_when(
      count_type == "Boat Anglers" ~ "boat",
      count_type == "Bank Anglers" ~ "bank",
      count_type == "Trailers Only" ~ "boat",
      count_type == "Vehicle Only" ~ "total"
    )
  ) |> 
  dplyr::arrange(event_date, section, count_sequence) #-> pe_effort_index
})

pe_effort_index_daily_mean <- reactive({
  pe_effort_index() |> 
  #pe_effort_index |> 
  dplyr::group_by(event_date, section, angler_type) |>
  dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop") #-> pe_effort_index_daily_mean
})


#interview data have angler_count, vehicle_count, trailer_count, angler_type and boat_used
#Disallow NAs in angler_type, fill missing angler_type from boat_used
#!!Does this actually need row-wise time_strata?
#!!Maintain angler_hours_total filter?
#!!lots of extra cols still at this point...
pe_interview <- reactive({
  left_join(creel$interview, creel$days, by = "event_date") |>
  mutate(
    across(c(vehicle_count, trailer_count), ~replace_na(., 0)),
    trip_status = replace_na(trip_status, "Unknown"),
    
    angler_type = tolower(angler_type),
    angler_type = if_else(is.na(angler_type), boat_used, angler_type),
    angler_type = case_when( 
      angler_type == "boat" ~ "boat", #pass through
      angler_type == "bank" ~ "bank", #pass through
      angler_type == "Unk" ~ "bank",  #Kalama, others?
      angler_type == "No" ~ "bank",   #value from boat_used
      angler_type == "Yes" ~ "boat"   #value from boat_used
      ),
    angler_type_ind = as.integer(factor(angler_type)),
    
    fishing_end_time = if_else(
      trip_status == "Incomplete" | is.na(fishing_end_time),
      interview_time,
      fishing_end_time),
    angler_hours = round(as.numeric(fishing_end_time - fishing_start_time) / 3600, 5),
    angler_hours_total = angler_count * angler_hours,
    time_strata = if_else(ModelPeriod == "Month", Month, Week)
  ) |>
  filter(angler_hours_total >= 0.5) #-> pe_interview
})
```

*NOT YET SHINY*

```{r effort_interview_final, eval = FALSE}

days_join <- creel$days |>
  mutate(time_strata = if_else(ModelPeriod == "Month", Month, Week)) |> 
  select(event_date, DayType, time_strata, starts_with("open_section")) |> 
  mutate(
    section = list(unique(sections$section)),
    angler_type = list(c("bank", "boat")) #is total ever actually needed?
  ) |> 
  unnest(cols = c(section, angler_type))

# #"days_join" also separate_rows option?
# creel$days |>
#   mutate(time_strata = if_else(ModelPeriod == "Month", Month, Week)) |> 
#   select(event_date, DayType, time_strata, starts_with("open_section")) |> 
#   mutate(
#     section = paste0(unique(sections$section), collapse = ","),
#     angler_type = paste0(c("bank", "boat"), collapse = ",") #is total ever actually needed?
#   ) |> 
#   separate_rows(c(section, angler_type), sep = ",")


if(str_detect(input$index_count_types, "Bank|Boat")) {
  
  daily_effort_estimates <- left_join(
    pe_effort_index_daily_mean, 
    creel$days |> select(event_date, DayL),
    by = "event_date") |> 
    mutate(mean_daily_effort = count_index_mean * DayL) |>
    arrange(event_date, section)
  
  # left join index effort counts to census counts 
  census_counts_all <- left_join(
    pe_effort_census, #grouped & summed by event_date, day_index, section, tie_in_indicator, count_sequence, angler_type [bank, boat]
    pe_effort_index, #grouped & summed by event_date, section, count_sequence, count_type [Bank Ang, Boat Ang, Vehic, Trailr] and derived angler_type [bank, boat, total])
    by = c("event_date", "section", "count_sequence","angler_type")
  ) |>
    mutate(
      count_index = replace_na(count_index, 0),
      TI_expan = count_census / count_index,
      TI_expan = if_else(is.infinite(TI_expan) | is.nan(TI_expan), NA_real_, TI_expan)
    ) |> 
    group_by(section, angler_type) |> 
    summarise(
      TI_expan_mean = mean(TI_expan, na.rm=TRUE),
      TI_expan_weighted = sum(count_census) / sum(count_index),
      across(
        c(TI_expan_mean, TI_expan_weighted),
        ~if_else(. == 0, 1, .) |> replace_na(1)
      ),
      .groups = "drop"
    ) |> 
    left_join(
      select(census_exp, cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
      by = c("angler_type", "section")
    ) |>
    mutate(
      #dealing with e.g. Cascade edge case of nothing to join for an angler_type/section
      #should really be addressed in the Prop_Expansion table...
      cen_exp_meth = replace_na(cen_exp_meth, input$census_expansion),
      p_TI = replace_na(p_TI, 1),
      TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
      TI_expan_final = if_else(
        cen_exp_meth == "Direct" | is.na(cen_exp_meth),
        TI_expan_weighted / p_TI,
        TI_expan_indirect)
    )
  
  # join census (tie in) counts to index counts 
  # calculate mean daily effort multipled by bias term (tie in ratio) from census counts
  effort_interviews_final <- left_join(
    daily_effort_estimates,
    census_counts_all, 
    by = c("section", "angler_type")
  ) |>
    mutate(
      TI_expan_final = replace_na(TI_expan_final, 1),
      mean_daily_TI_expan = mean_daily_effort * TI_expan_final
    )  |>
    select(section, event_date, angler_type, mean_daily_TI_expan) |> 
    right_join(days_join, by = c("section", "event_date", "angler_type")) |>
    mutate(
      creeled = if_else(!is.na(mean_daily_TI_expan) & open_section_1 == TRUE, "Y", "N")
    ) |> 
    arrange(event_date)
  
} else {
  if(str_detect(input$index_count_types, "Vehicle|Trailer")) { 

    #anglers_per_vehicle from day-section totals amount to arith mean of multiple interviews?
    #presumably this blows up if sum(vehicle_count)==0
    angler_data_from_interviews <- bind_rows(
      pe_interview |>
        group_by(event_date, section) |> 
        summarize(
          angler_hours_total = sum(angler_hours_total),
          anglers_per_vehicle = sum(angler_count) / sum(vehicle_count),
          #anglers_per_index_count_from_interview = daily_sum_angler / daily_sum_index_count_from_interview,
          angler_type = "total",
          .groups = "drop")
      ,
      pe_interview |> 
        filter(angler_type == "boat") |>
        group_by(event_date, section) |> 
        summarize(
          angler_hours_total = sum(angler_hours_total),
          anglers_per_vehicle = sum(angler_count) / sum(vehicle_count),
          angler_type = "boat",
          .groups = "drop")
    ) 
    
    daily_effort_estimates <- angler_data_from_interviews  |>
      left_join(pe_effort_index_daily_mean, by = c("event_date", "section", "angler_type")) |>
      left_join(select(creel$days, event_date, DayL), by = "event_date") |> 
      mutate(mean_daily_effort = anglers_per_vehicle * count_index_mean * DayL) |>
      arrange(event_date, section) 
    # |> filter(!is.na(mean_index_count)) #EB: circle back on this

    #join interview-expanded index counts to census
    census_counts_all <- left_join(
      #census already grouped & summed by event_date, day_index, section, tie_in_indicator, count_sequence, angler_type [bank, boat]
      #but here split, collapse and then reassign angler_type to total & boat
      bind_rows(
        pe_effort_census |> 
          group_by(event_date, section, count_sequence) |> 
          summarize(count_census = sum(count_census), angler_type = "total", .groups = "drop")
        ,
        pe_effort_census |> 
          filter(angler_type == "boat") |>
          group_by(event_date, section, count_sequence) |> 
          summarize(count_census = sum(count_census), angler_type = "boat", .groups = "drop")
      )
      ,
      #index via interviews with angler_type [total, boat]
      #using ang/vehicle from interview to expand index counts of vehicles
      #!!most likely an expanding join since interview is already per day-section here
      #!!but effort_index is per count_seq (per day-section)
      #!!so is it correct for this to be left_ rather than full/inner?
      left_join(
        angler_data_from_interviews,
        pe_effort_index, #|> select(-count_type), 
        by = c("event_date", "section", "angler_type")
        ) |> 
        mutate(count_index = anglers_per_vehicle * count_index) |> 
        select(event_date, section, count_sequence, angler_type, count_index)
      ,
      by = c("event_date", "section", "count_sequence", "angler_type")
      ) |>
      mutate(
        count_index = replace_na(count_index, 0),
        TI_expan = count_census / count_index,
        TI_expan = if_else(is.infinite(TI_expan) | is.nan(TI_expan), NA_real_, TI_expan)
      ) |> 
      group_by(section, angler_type) |> 
      summarise(
        TI_expan_mean = mean(TI_expan, na.rm=TRUE),
        TI_expan_weighted = sum(count_census) / sum(count_index),
        across(
          c(TI_expan_mean, TI_expan_weighted),
          ~if_else(. == 0, 1, .) |> replace_na(1)
          ),
        .groups = "drop"
      ) |> 
      left_join(
        census_exp |> select(cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
        by = c("angler_type", "section")
        ) |>
      mutate(
        #dealing with e.g. Cascade edge case of nothing to join for an angler_type/section
        #should really be addressed in the Prop_Expansion table...
        cen_exp_meth = replace_na(cen_exp_meth, input$census_expansion),
        p_TI = replace_na(p_TI, 1),
        TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
        TI_expan_final = if_else(
          cen_exp_meth == "Direct" | is.na(cen_exp_meth),
          TI_expan_weighted / p_TI,
          TI_expan_indirect)
      )
    
    # join census (tie in) counts to index counts 
    
    # calculate mean daily effort multipled by bias term (tie in ratio) from census counts
    #!!aiming for event_date, angler_type [total, boat, bank (as total-boat)]
    #!!Fails for Cascade - no "boat" in daily_effort_estimates (since no boat angler_type in pe_interview)
    #!!so left_join of census_counts_all provides no "boat" rows
    #!!so pivot wider produces no "boat" col, so mutate cannot find
    #!!however "total - boat" seems potentially troublesome even when both present
    #!!negatives, zeros, near-zero, etc
    #!!is "total" really needed/used? 
    #!!   not present for a non-trailer/vehicle index case
    #!!   and just creates additional level that could be dropped against days_join obj?
    effort_interviews_totalandboat <- left_join(
      daily_effort_estimates |> select(event_date, section, angler_type, mean_daily_effort),
      census_counts_all |> select(section, angler_type, TI_expan_final),
      by = c("section", "angler_type")
    ) |> 
      mutate(mean_daily_TI_expan = mean_daily_effort * TI_expan_final) 
    
    if(any(pe_interview$angler_type=="boat")) {
      effort_interviews_final <- bind_rows(
        #total and boat
        effort_interviews_totalandboat |> 
          select(event_date, section, angler_type, mean_daily_TI_expan),
        #derived bank
        effort_interviews_totalandboat |> 
          select(event_date, section, angler_type, mean_daily_TI_expan) |> 
          pivot_wider(names_from = angler_type, values_from = mean_daily_TI_expan, values_fill = 0) |>
          mutate(
            angler_type = "bank", 
            mean_daily_TI_expan = total - boat,
            total = NULL, boat = NULL)
      ) |> 
        right_join(days_join, by = c("section", "event_date", "angler_type")) |> 
        mutate(creeled = if_else(!is.na(mean_daily_TI_expan), "Y", "N")) |> 
        arrange(event_date)
    } else { #only angler_type == "total", coerce "boat" to 0 and "bank" to total
      effort_interviews_final <- bind_rows(
        effort_interviews_totalandboat |> 
          select(event_date, section, angler_type, mean_daily_TI_expan),
        effort_interviews_totalandboat |> 
          select(event_date, section) |> 
          mutate(angler_type = "boat", mean_daily_TI_expan = 0),
        effort_interviews_totalandboat |> 
          select(event_date, section, mean_daily_TI_expan) |> 
          mutate(angler_type = "bank")
      ) |> 
        right_join(days_join, by = c("section", "event_date", "angler_type")) |> 
        mutate(creeled = if_else(!is.na(mean_daily_TI_expan), "Y", "N")) |> 
        arrange(event_date)
    }
    
  }
}

```

```{r effort_interview_final_with_days_total_sampled, eval = FALSE}
# excluding specified closures, total number of days by section, weekday/end, and time strata for which to generate estimates
creel$days_total <- creel$days |>
  pivot_longer(
    cols = starts_with("open_section"), 
    names_to = "section", 
    values_to = "closure_value") |>
  filter(closure_value == TRUE) |> 
  mutate(
    section = as.numeric(gsub("^.*_", "", section)),
    time_strata = if_else(ModelPeriod == "Month", Month, Week)
    ) |>
  count(section, DayType, time_strata, name = "N_days")

# number of days sampled within monitoring period
creel$days_sampled <- effort_interviews_final |>
  filter(!is.na(mean_daily_TI_expan) & creeled == "Y") |> 
  count(section, DayType, time_strata, angler_type, name = "n_days")


# add these objects to the table with index count data
effort_interviews_final <- effort_interviews_final |> 
  filter(!is.na(mean_daily_TI_expan)) |> 
  left_join(creel$days_total,
    by = c("section", "DayType", "time_strata")) |> 
  left_join(creel$days_sampled,
    by = c("section", "DayType", "time_strata", "angler_type")) |>
  left_join(
    creel$days_total |> 
      group_by(section, DayType) |> 
      summarise(N_days_total = sum(N_days), .groups = "drop"),
    by = c("section", "DayType")) |> 
  left_join(
    creel$days_sampled |> 
      group_by(section, DayType, angler_type) |> 
      summarise(n_days_total = sum(n_days), .groups = "drop"),
    by = c("section", "DayType", "angler_type")) 

```

```{r daily CPUE from interviews, include = FALSE}

# Calculating CPUE for the different angler_types

#!!Move this up with other reactive pe_* object creation?
# join catch data to interview after inferring complete cases (counts or 0s for all catch_groups encountered)
interview_and_catch <- left_join(
  #should already be distinct on interview_id
  #!!currently filtered to angler_hours >= 0.5
  #!!so some rows in creel$catch for "short" interviews may be lost in join 
  #!!note also that interview_ids in creel$interview/pe_interview may have no catch and not be in creel$catch
  #!!so are consequently coded NA for catch_group
    pe_interview |> drop_na(angler_hours) 
    ,
    creel$catch |> 
      group_by(interview_id, catch_group) |> 
      summarise(fish_count = sum(fish_count, na.rm = T), .groups = "drop") |>
      pivot_wider(
        names_from = catch_group,
        values_from = fish_count,
        values_fill = 0) |> 
      pivot_longer(
        cols = -interview_id, 
        names_to = "catch_group", 
        values_to = "fish_count"
      )
    , 
    by = "interview_id"
  )

# setdiff(creel$catch$interview_id, pe_interview$interview_id)  #lost in the join, due to "short" angler_hours
# setdiff(creel$interview$interview_id, creel$catch$interview_id) #no catch, so no catch_group(s) to assign
# interview_and_catch |> filter(is.na(catch_group))


#mean angler hours by section, time_strata, angler_type 
# use in case there is non-zero catch, but no angler hours to use to calculate CPUE (should be a rare situation)
angler_hours_summary <- interview_and_catch |>
  group_by(section, time_strata, DayType, angler_type, catch_group) |>
  summarise(mean_strata_angler_hours = mean(angler_hours_total), .groups = "drop") |>
  complete(
    section, time_strata, DayType, angler_type, catch_group,
    fill = list(mean_strata_angler_hours = 0))

# CPUE for bank and boat effort 
interview_daily_totals <- left_join(
    interview_and_catch,
    angler_hours_summary,
    by = c("section", "time_strata", "DayType", "angler_type", "catch_group")
    ) |> 
   mutate(
    cpue_interview = if_else(
      angler_hours_total > 0,
        fish_count / angler_hours_total, 
        fish_count / mean_strata_angler_hours)
  ) |>
  group_by(event_date, day_index, section, time_strata, DayType, angler_type, catch_group) |>
  summarise(
    n_groups = n(),
    catch_dailysum = sum(fish_count),
    angler_hours_total_dailysum = sum(angler_hours_total),
    cpue_rom = catch_dailysum / angler_hours_total_dailysum, # ratio of the means CPUE estimator
    cpue_mor = mean(cpue_interview),  # mean of ratios CPUE estimator
    .groups = "drop"
  )


#  add implicit missing values of CPUE to dataset using tidyr complete() function
interview_daily_totals_complete <- interview_daily_totals |>
  ungroup() |>
  select(section, event_date, angler_type, catch_group,
         total_angler_hours = angler_hours_total_dailysum,
         catch_dailysum, cpue_rom, cpue_mor) |>
  mutate(angler_type = replace_na(angler_type, "bank")) |> #kalama steelhead fix
  # filter(catch_group == "Chinook_Adult_UM_Released") |> # placeholder spot to filter catch groups
  # complete(section, event_date, angler_type, fill = list(catch_dailysum = 0)) |>
  complete(section, event_date, angler_type, catch_group, fill = list(catch_dailysum = 0)) |>
  filter(!(is.na(angler_type))) |>
  # mutate(catch_group = "Chinook_Adult_UNK_Released") |>
  # distinct() |>
  left_join(d_days, by = c("event_date")) |> 
  mutate(time_strata = if_else(ModelPeriod == "Month", Month, Week))


# calculate mean CPUE values by strata to use on days with known effort but a lack of interviews 
cpue_summary <- interview_daily_totals |>
  group_by(section, time_strata, DayType, angler_type, catch_group) |>
  summarise(
    mean_strata_cpue_mor = mean(cpue_mor), # Fisheries Techniques (Jones and Pollock 2012) suggest MOR for roving survey design
    mean_strata_cpue_rom = mean(cpue_rom)
  ) |>
  ungroup() |>
  complete(section, time_strata, DayType, angler_type, catch_group,
           fill = list(mean_strata_cpue_mor = 0, mean_strata_cpue_rom = 0))

# calculate mean daily effort by strata to use on days with interviews but a lack of quantified effort
# effort_summary <- effort_interviews_final |> 
#   filter(!is.na(DayType)) |>
#   group_by(section, time_strata, DayType, angler_type) |>
#   summarise(
#     mean_strata_effort = mean(mean_daily_TI_expan)
#   ) |>
#   ungroup() |>
#   complete(section, time_strata, angler_type,
#            fill = list(mean_strata_effort = 0))


effort_summary <- effort_interviews_final |> 
  filter(!is.na(mean_daily_TI_expan)) |>
  group_by(section, time_strata, angler_type) |>
  summarise(
    mean_strata_effort = mean(mean_daily_TI_expan)
  ) |>
  ungroup() |>
  complete(section, time_strata, angler_type,
           fill = list(mean_strata_effort = 0))


effort_join <- effort_interviews_final |> 
  filter(!is.na(DayType)) |> 
  select(section, time_strata, event_date, angler_type, mean_daily_TI_expan, n_days, N_days, n_days_total, N_days_total) |> 
left_join(effort_summary) |> 
  mutate(
    mean_daily_TI_expan = if_else(mean_daily_TI_expan == 0, mean_strata_effort, mean_daily_TI_expan)
  )


# join mean_strata_cpue values to table with daily cpue values so we can use the mean strata cpue values on days with known effort but no corresponding interview
# extract the columns we need from the interview and catch daily total table to calculate daily CPUE
daily_CPUE <- interview_daily_totals_complete |> 
  left_join(cpue_summary, by = c("section", "angler_type", "time_strata", "DayType", "catch_group"))|> 
  select(section, time_strata, event_date, DayType, angler_type, catch_group, catch_dailysum, total_angler_hours, cpue_rom, cpue_mor, mean_strata_cpue_rom, mean_strata_cpue_mor)

```



### Index counts

```{r}
#renderPrint({str(creel$effort)})

# renderPlot({
#   if(!is.null(creel$effort)) {
#     creel$effort |>
#       group_by(tie_in_indicator, section, event_date) |>
#       summarise(count_quantity = sum(count_quantity), .groups = "drop") |>
#       ggplot(aes(event_date, count_quantity, fill = section)) +
#       geom_col() +
#       facet_wrap(~tie_in_indicator, scales = "free")
#   }
# })

#renderPrint({str(pe_effort_census())})

renderPlot({
  if(!is.null(creel$effort)) {
    pe_effort_index() |>
      ggplot(aes(event_date, count_quantity, fill = factor(count_sequence))) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + count_type, scales = "free")
  }
})

```

### Index daily mean

```{r}
renderPlot({
  if(!is.null(creel$effort)) {
    pe_effort_index_daily_mean() |>
      ggplot(aes(event_date, count_quantity, fill = count_type)) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + count_type, scales = "free")
  }
})

```

Interview
--------------------------------------------

### Interview

```{r}
renderPlot({
  if(!is.null(creel$interview)) {
    pe_interview() |>
      ggplot(aes(event_date, angler_hours_total, fill = angler_type)) +
      geom_col(position = position_dodge()) +
      facet_wrap(~section + angler_type, scales = "free")
  }
})

```

### Interview

```{r}
renderPlot({
  if(!is.null(creel$interview)) {
    pe_interview() |>
      ggplot(aes(angler_count, angler_hours_total, fill = angler_type)) +
      geom_point(position = position_dodge()) +
      facet_wrap(~section + angler_type, scales = "free")
  }
})

```

Catch
============================================


About
============================================

Anything to cite/link to?

WDFW gathers fishing information from anglers around the state:
(https://wdfw.wa.gov/fishing/reports/creel)[https://wdfw.wa.gov/fishing/reports/creel]
