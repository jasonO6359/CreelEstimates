---
title: "Freshwater Creel Estimates"
date: "`r Sys.Date()`"
params:
  project_name: "CRM-Roving Creel Project"
  fishery_name: "Drano Lake salmon and steelhead 2023"
  est_date_start: "2023-08-01"
  est_date_end: "2023-10-31"
  est_catch_groups: !r data.frame(rbind(
    c(species = 'Chinook', life_stage = 'Adult', fin_mark = 'AD', fate = 'Kept'),
    c(species = 'Chinook', life_stage = 'Adult', fin_mark = 'AD', fate = 'Released'),
    c(species = 'Steelhead', life_stage = 'Adult', fin_mark = 'AD', fate = 'Released'),
    c(species = 'Steelhead', life_stage = 'Adult', fin_mark = 'UM', fate = 'Released')
    ))
  study_design: "Drano"  
  person_count_type: "angler"
  period_pe: "week"
  period_bss: "day"
  days_wkend: !r c('Saturday', 'Sunday')
  index_count_types: "Bank Angler/Boat counts"
  census_expansion: "Direct"
  day_length_expansion: "night closure"
  min_fishing_time: 0.5
  output_location_filepath: "local"
output:
  html_document:
    fig_caption: yes
    theme: default
    toc: yes
    toc_depth: 3
    toc_float: yes
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
#running the 'setup' chunk loads the read-only `params` list
knitr::opts_chunk$set(warning = FALSE, message = FALSE, fig.width = 10, fig.height = 8)
library("here") #defines root at working dir of .Rproj
```

```{r first_time_run, eval=FALSE, include=FALSE}
# # set up file paths
# ## top level for scripts and outputs
# if (!dir.exists(here("fishery_analyses"))) {
#   dir.create(here("fishery_analyses")); "fishery_analyses folder created"
# }
# ## project level
# if (!dir.exists(here("fishery_analyses", params$project_name))) {
#   dir.create(here("fishery_analyses", params$project_name))
#   paste(here("fishery_analyses", params$project_name), "folder created")
# }
# ## fishery-specific
# if (!dir.exists(here("fishery_analyses", params$project_name, params$fishery_name))) {
#   dir.create(here("fishery_analyses", params$project_name, params$fishery_name))
#   paste(here("fishery_analyses", params$project_name, params$fishery_name), "folder created")
# }
# 
# # evaluate if analysis .Rmd already exists, if not then generate new file 
# if (file.exists(here("fishery_analyses", params$project_name, params$fishery_name, 
#        paste0("fw_creel_", params$fishery_name, ".Rmd")))) {
#   
#   print("Analysis .Rmd file already exists")
#   
# } else {
# #save the master template with new params arguments for the fishery
# rstudioapi::documentSave(rstudioapi::getActiveDocumentContext()$id)
# #make an appropriately renamed copy
# file.copy(
#   here("template_scripts/fw_creel.Rmd"),
#   here("fishery_analyses", params$project_name, params$fishery_name, 
#        paste0("fw_creel_", params$fishery_name, ".Rmd"))
# )
# #open the new copy
# rstudioapi::documentOpen(
#   here("fishery_analyses", params$project_name, params$fishery_name, 
#        paste0("fw_creel_", params$fishery_name, ".Rmd"))
# )
# }

```

```{r packages_and_functions}
library("suncalc")
library("tidyverse")
library("patchwork")
library("gt")
theme_set(theme_light())

library("rstan")
rstan_options(auto_write = TRUE)

purrr::walk(list.files(here("R_functions"), full.names = T), source)
```

# `r paste(params$fishery_name)`

```{r}
gt(tibble(param = names(params), value = as.character(params)))
```

# Set day length times if using manual option 

```{r day_length_inputs, echo = FALSE}

day_length_inputs <- list()

if(params$day_length_expansion == "manual"){
# Step #1: Select general strategy for [earliest] start and [latest] end time
    day_length_inputs$start_time<-c("sunrise") # enter either "sunrise" or "manual" 
    day_length_inputs$end_time<-c("sunset")    # enter either "sunset"  or "manual" 
  # Step #2A: If necessary, specify an offset (in hours) to the start and end times
    # (e.g., if legal fishing occurs 1 hr. prior to sunrise & sunset, enter 1 below for both); enter 0 if no offset needed
    day_length_inputs$start_adj<-c(1) # Specify an offset for the start time (in hours);    
    day_length_inputs$end_adj<-c(1)   # Specify an offset for the end time (in hours);  
  # Step #2B: If "manual" entered for "ui_start_time" or "ui_end_time", enter the earliest start and/or latest end time for a creel survey event
    day_length_inputs$start_manual<-c("06:00:00") # Specify manual start time (format "HH:MM:SS", e.g., 6 AM = "06:00:00")
    day_length_inputs$end_manual<-  c() # Specify manual end time (format "HH:MM:SS")  
}
```

# Fetch raw data

```{r dwg_fetch, echo=FALSE}
dwg <- fetch_dwg(params$fishery_name)

dwg$days <- prep_days(
  date_begin = params$est_date_start, 
  date_end = params$est_date_end, 
  weekends = params$days_wkend,
  holidays = read_lines(paste(here(), "input_files/dates_holidays_2015_2030.txt", sep = "/")),
  lat = mean(dwg$ll$centroid_lat), #can/should consider smarter options
  long = mean(dwg$ll$centroid_lon),#can/should consider smarter options 
  period_pe = params$period_pe,
  sections = unique(dwg$effort$section_num),
  closures = dwg$closures,
  day_length = params$day_length_expansion,
  day_length_inputs = day_length_inputs
  )
```

# Review fetched data

## Fishery sections

```{r table_sections}
dwg$effort |> 
  filter(location_type == "Section") |> 
  distinct(water_body, section_num, location) |> 
  arrange(section_num) |>
  select(`Water Body` = water_body, `Section Number` = section_num, `Location description` = location) |> 
  gt()
```

## Days

```{r gt_creel_days}
dwg$days |> 
  mutate(across(starts_with("open_"), ~if_else(., "open","closed"))) |> 
  rename_with(.cols = starts_with("open_"), .fn = ~str_remove_all(., "open_")) |> 
  gt::gt() |> 
  gt::data_color(
    columns = contains("section_"),
    colors = scales::col_factor(
      palette = c("#C3C7C3", "#78B574"),
      domain = c("closed","open")) 
  )

```

## Period-Dates reference
```{r gt_period_dates_reference}

# reference for period (time_strata)

dwg$days |> 
    group_by(period) |> 
    summarise(
      min_event_date = min(event_date),
      max_event_date = max(event_date)) |> 
  gt::gt(caption = "Reference table containing the first and last date within each time stratum period in the monitoring period.")

```

## Effort

```{r gt_creel_effort}
dwg$effort |>
  filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))) |> 
  distinct(section_num, location, event_date, tie_in_indicator, count_sequence) |> 
  count(section_num, location, tie_in_indicator) |> 
  mutate(tie_in_indicator = case_when(
    tie_in_indicator == 1 ~ "census",
    tie_in_indicator == 0 ~ "index"
  )) |>
  arrange(section_num, tie_in_indicator, location) |> 
  gt(groupname_col = "section_num", rowname_col = "location") |> 
  tab_style(
    style = list(cell_fill("grey70"), cell_text(weight = "bold")),
    locations = cells_body(rows = tie_in_indicator == "census")
  )
```

## Interview

```{r gt_creel_interview}
# dwg$interview |>  
#   filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))) |> 
#   count(section_num, fishing_location) |> 
#   arrange(section_num) |> 
#   gt(groupname_col = "section_num", caption = "Number of interviews by analysis section")

dwg$interview |>  
  filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))) |> 
  count(section_num, event_date) |> 
  pivot_wider(names_from = section_num, values_from = n) |> 
  arrange(event_date) |> 
  gt(rowname_col = "event_date") |> 
  sub_missing() |> 
  data_color(
    columns = where(is.numeric),
    colors = scales::col_quantile(
      palette = c("white", "orange"), 
      reverse = T, na.color = "grey",
      domain = NULL #c(0, )
    )
  )
```

## Catch

```{r gt_creel_catch}
dwg$catch |>
  left_join(dwg$interview, by = "interview_id") |> 
  filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))) |> 
  group_by(catch_group) |> 
  summarise(fish_count = sum(fish_count), .groups = "drop") |> 
  gt(caption = "Total reported encounters in interviews to date for catch groups defined as individual combinations of species, life state, fin mark, and fate")
```

# Shared data aggregation

```{r prep_dwg_summ_shared_summary_objects, echo=FALSE, results = 'hide'}

# Create blank list that will be used to attach the following three datasets
  dwg_summ <- list() #intermediate objects wrangled from creel list elements

##KB: I don't understand the downstream implications of the following two comments regarding NAs in the vehicle_count/trailer_count fields 
   #prep_interview() no longer excludes observations with NA vehicle_count/trailer_count
    #requires handling during summarization for fisheries/records where these were not collected

# Interview data summarization

#KB - I commented out the existing interview function and replaced with three new functions that essentially do the same things but in smaller chunks and uses a few new arguments that add flexibility to the analysis/data wrangling based on study design 
    # dwg_summ$interview <-
    #   prep_dwg_interview(
    #     dwg_interview = dwg$interview |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))),
    #     dwg_catch = dwg$catch,
    #     person_count_type = params$person_count_type,
    #     min_fishing_time = params$min_fishing_time,
    #     est_catch_groups = params$est_catch_groups
    #   )

#KB NOTE: it doesn't appear as though interview data are filtered out if a "person_count" (i.e., total_group_count or angler_count) are NA; but maybe we should so we don't end up with NAs in CPUE data and object counts (i.e trailers/vehicles/boats per person/group); right now, interview data are filtered for NAs in the "prep_inputs_bss" function for the object "interview_cg_intA"

  # Summarize fishing time 
    interview_fishing_time <- 
      prep_dwg_interview_fishing_time(
        dwg_interview = dwg$interview |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))),
        #person_count_type = params$person_count_type,
        min_fishing_time = params$min_fishing_time,
        study_design = params$study_design
      )
   
  # Summarize angler types
    interview_plus_angler_types <- 
      prep_dwg_interview_angler_types(
        interview_fishing_time = interview_fishing_time,
        study_design = params$study_design,
        boat_type_collapse = "No",
        #fish_location_determines_type = "No",
        angler_type_kayak_pontoon = "boat"
      )
    
    #KB: preview angler_final
    interview_plus_angler_types |> select(interview_id, angler_type, boat_used, boat_type, fish_from_boat, angler_final) |> group_by(boat_used, fish_from_boat, boat_type) |> count(angler_final)
    #KB NOTE: check with Beth as to why there is a boat_type entered as Large Boat (Trailered) -- should not be -- but is fine for now
    
    
  # Summarize catch (for catch groups of interest)
  interview_plus_catch <- 
    prep_dwg_interview_catch(
      interview_plus_angler_types = interview_plus_angler_types,
      study_design = params$study_design,
      dwg_catch = dwg$catch,
      est_catch_groups = params$est_catch_groups
    )
  
  # Attach the final formatted interview data set to "dwg_summ"
    dwg_summ$interview <-interview_plus_catch
    
# Effort index data summarization
#KB - I commented out the existing effort census function and replaced with...  
    # dwg_summ$effort_index <-
    #   prep_dwg_effort_index(
    #     eff = dwg$effort |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end)))
    #   )
    
#KB NOTE: the final "effort_index_summ" contains/retains the field/column "count_type" for the "standard" study design but is removed for the "Drano" study design; this difference comes about when using the group_by function to create the final object "index_angler_final"; specifically, the count_type field can be retained for the standard study design simply because there is a unique combo of count_type to angler_final (trailers --> boats, vehicles --> total); however it doesn't work for Drano there can be more count_types than angler_final (and we want to creat an output that summarizes based on the unique angler_final groups); for now, I've kept "count_type" field for in the "standard" study design output (as it can help with some clarity viewing the outputs) BUT does cause some downstream issues (e.g., the function "plot_inputs_pe_index_effort_counts" does not work for Drano lake data because it uses the count_type field to plot AND more importantly the "prep_inputs_bss_dev" function using "count_type" field form the effort index data set to filter data with vehicle and trailer counts, which isn't applicable to Drano.  I've created a work around but worth revisiting if there's a way to remove the count_type field here and still have all downstream functions and outputs work as desired)  
    
    #Aggregates index effort counts over locations within count_seq & section; count_types are converted to angler_final based on arguments
      effort_index_summ <- 
        prep_dwg_effort_index_dev(
          eff = dwg$effort |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))),
          study_design = params$study_design,
          boat_type_collapse = "No",
          #fish_location_determines_type = "No", #not applicable
          angler_type_kayak_pontoon = "boat"
        )
    #QAQC - are there any census effort count groups that "failed"
      # NOTE: fails get filtered out from "effort_index_summ$index_angler_final so make sure this is correct
      effort_index_summ$index_angler_groups |> distinct(angler_final)   
      
    # Attach the final formatted effort census data set to "dwg_summ"
      dwg_summ$effort_index <- effort_index_summ$index_angler_final     

# Effort census data summarization
    
#KB - I commented out the existing effort census function and replaced with a modified (dev) function that essentially does the same thing but i.) uses a few new arguments that add flexibility to the analysis/data wrangling based on study design and ii.) now returns two outputs - one data frame is use to highlight/flag "fails" in assigning count_types to an angler_final grouping and the other is the equivalent to before which is the final formatted effort census dataset 
    # dwg_summ$effort_census <-
    #   prep_dwg_effort_census(
    #     eff = dwg$effort |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end)))
    #   )
    
  # Aggregates census (tie in) effort counts, associating to closest-in-time index count; count_types are converted to angler_final based on arguments
    
#KB NOTE: the code runs BUT it seems like the chunk fails with the Drano data set (returns this error: no applicable method for 'count' applied to an object of class "NULL"); need to update so entire chunk will run successfully    
    effort_census_summ <- 
      prep_dwg_effort_census_dev(
        eff = dwg$effort |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))),
        study_design = params$study_design,
        boat_type_collapse = "No",
        fish_location_determines_type = "No",
        angler_type_kayak_pontoon = "boat"
      )

  #QAQC - are there any census effort count groups that "failed"
  # NOTE: fails get filtered out from "effort_census_summ$census_angler_final so make sure this is correct
    effort_census_summ$census_angler_groups |> count(angler_final) 
    effort_census_summ$census_angler_groups |> filter(angler_final == "fail") 
  
  # Attach the final formatted effort census data set to "dwg_summ"
    dwg_summ$effort_census <- effort_census_summ$census_angler_final

```

## Index effort count (KB - this tiny code chunk seems out of place)


```{r plot_index_effort_counts, fig.cap= "Index effort counts for each count sequence on surveyed days within the monitoring period."}
# plot of index effort counts faceted by section and count_type per count sequence and day 

#KB NOTES: this function is currently broken (for Drano study design) because I updated "dwg_summ$effort_index" to include "angler_final" instead of leaving it as "count_type" 

plot_inputs_pe_index_effort_counts(effort_index = dwg_summ$effort_index)
```

# PE estimation

```{r prep_inputs_pe, results = 'hide'}

#       -  probably want to drop the if/else if portions that use that "index_count_types" and move this inside functions using the study_design framework used above
#       -  need to work through the following functions:
#          -- prep_inputs_pe_int_ang_per_vhcl_trlr  (question - can this be generalized again using the study_design framework; e.g., vhcl/trls info not collected for Drano but want boats/ang)
#          -- prep_inputs_pe_paired_census_index_counts (will need to update based on changes to "prep_dwg_effort_index_dev" function above; standard study design more complicated than Drano)
#          -- prep_inputs_pe_ang_hrs_vhcl_trlr/prep_inputs_pe_ang_hrs_bank_boat (again, use study_design framework to generalize for standard, Drano, Baker, LCR steelhead)
#          -- prep_inputs_pe_daily_cpue_catch_est (not sure anything needs update here)
#          -- prep_inputs_pe_df (no idea; see note about this function being seemingly "wrong"??)
#          -- prep_inputs_bss (this function is in a section further down; first, check to see if my edits to "prep_dwg_effort_index_dev" function will cause issues with angler_final vs. count_type; see L10-20, L60, L68, L76, L84,  "prep_inputs_bss" function)


inputs_pe <- list()

#derive a table of potentially section-anglerType-specific values to modify census expansions

#KB NOTES: figure out where this table gets used in the analysis (is it even used?); the current construct is limited to two "angler_final" groupings (bank, boat); maybe this can be folded into the study_design framework (and removed from database/fishery tables)
# KB NOTES: inside this function, "census_indir" gets hard coded to 1 (everytime); without revisiting why I even built this in, I'm guessing this is not the functionality we want to have with this expansion factor
#KB NOTES: at a minimum, could the "census_expansion" YAML parameter be removed and added to/used in the function based on the "study_design" YAML parameter
inputs_pe$census_expan <- 
  prep_inputs_pe_census_expan(
    eff = dwg$effort, 
    census_expansion = params$census_expansion
  )

# Calculate total days the fishery was open per strata (strata = period, day_type, and section_num)

#KB NOTES: this function appears to be working fine as is - counts the number of "open" fishing days by period/week, daytype (weekday, weekend), and section_num
inputs_pe$days_total <- 
  prep_inputs_pe_days_total(
    days = dwg$days
  )

################################################# ###
#KB edits: start

  #could skip retaining as list element and just pass as inline call in arg to next function #KB - this was a comment from perhaps Dan from years ago but could probably be deleted
  (inputs_pe$interview_ang_per_object <- 
    prep_inputs_pe_int_ang_per_object(
      dwg_summarized = dwg_summ, 
      study_design = params$study_design
    ))

# KB NOTES: similar to note in previous section, should revisit the utility of having the "census_indir", "cen_exp_meth", and "TI_expan_weighted" columns that end up in this table (e.g., under current analysis construct, would these field ever be used; will they be used for LCR steelhead?)

# KB NOTES: may want to build in a "time difference threshold" by which census and index counts must be within (e.g., 2 hours or less??); an example of why not having this threshold may lead to an erroneous paired count happened on April 29th, 2023, during the 2023 Skagit winter steelhead survey (census/TI count occurred at ~11:15 AM; there were three index counts in section 2 but ONLY one in section 1, where the one index count in section 1 happened at 8:15 PM; not sure why this happened but the tie-in count and index for section 1 occurred 9 hours apart and this paired event wasn't truly paired and should be dropped for section 1)

  # returns season-long total of counts for paired census and index counts
  (inputs_pe$paired_census_index_counts <- 
    prep_inputs_pe_paired_census_index_counts_dev(
      days = dwg$days,
      dwg_summarized = dwg_summ,
      interview_ang_per_object = inputs_pe$interview_ang_per_object,
      census_expan = inputs_pe$census_expan,
      study_design = params$study_design
    ))

  # returns census-corrected daily mean angler hours 
  (inputs_pe$ang_hrs_daily_mean <- #KB NOTE: consider renaming to "ang_hrs_daily_mean_TI_expan" (which would match column header & final object name returned from function)
    prep_inputs_pe_ang_hrs_dev(
      days = dwg$days, 
      dwg_summarized = dwg_summ,
      #interview_ang_per_vehic = inputs_pe$interview_ang_per_vhcl_trlr,
      interview_ang_per_object = inputs_pe$interview_ang_per_object,
      paired_census_index_counts = inputs_pe$paired_census_index_counts,
      #census_expan = inputs_pe$census_expan,
      study_design = params$study_design
    ))

#KB edits: end
################################################# ###

#KB edit: commented out the following 75 lines of original script that was replaced by the updated three previous functions above

# # depending on the types of index counts, reach the calc: ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * TI_expan_final
# # when index counts are already bank & boat, matching census counts,
# #   then angler_hour daily means are just effort index counts of anglers expanded by day length,
# #   which are multiplied against tie-in expanded census counts of anglers by type (per section_num)
# # but when index counts are trailers & vehicles,
# #   then angler_hour daily means require first using interviews to estimate anglers_per_vhcl_trlr by angler_final total & boat 
# #   so anglers_per_vhcl_trlr can be multiplied against the trailer & vehicle counts in effort_index, releveled to boat/total
# #   and then TI-expanded counts similarly require splitting, re-leveling and rebinding census to boat/total to allow join with effort_index
# #   and THEN generating a final object with total, boat and derived-bank, including dealing with case of only-bank (e.g., Cascade)
# if(params$index_count_types == "Bank Angler/Boat Angler") {
#   
#   inputs_pe$ang_hrs_daily_mean <- 
#     prep_inputs_pe_ang_hrs_bank_boat(
#       days = dwg$days, 
#       dwg_summarized = dwg_summ,
#       census_expan = inputs_pe$census_expan
#     )
#   
# } else if(str_detect(params$index_count_types, "Vehicle|Trailer")) {
#   
#   #could skip retaining as list element and just pass as inline call in arg to next function
#   inputs_pe$interview_ang_per_vhcl_trlr <- 
#     prep_inputs_pe_int_ang_per_vhcl_trlr(
#       dwg_summarized = dwg_summ
#     )
#   
#   # returns season-long total of counts for paired census and index counts
#   inputs_pe$paired_census_index_counts <- 
#     prep_inputs_pe_paired_census_index_counts(
#       days = dwg$days,
#       dwg_summarized = dwg_summ,
#       interview_ang_per_vehic = inputs_pe$interview_ang_per_vhcl_trlr,
#       census_expan = inputs_pe$census_expan
#     )
#   
#   # returns census-corrected daily mean angler hours 
#   inputs_pe$ang_hrs_daily_mean <- 
#     prep_inputs_pe_ang_hrs_vhcl_trlr(
#       days = dwg$days, 
#       dwg_summarized = dwg_summ,
#       interview_ang_per_vehic = inputs_pe$interview_ang_per_vhcl_trlr,
#       paired_census_index_counts = inputs_pe$paired_census_index_counts,
#       census_expan = inputs_pe$census_expan
#     )
# 
# ### Drano specific update (added extra else if to deal with new index_count_types option) ###
# }  else if(params$index_count_types == "Bank Angler/Boat counts") {
# 
#   #could skip retaining as list element and just pass as inline call in arg to next function
#   #inputs_pe$interview_ang_per_vhcl_trlr <- prep_inputs_pe_int_ang_per_vhcl_trlr(dwg_summarized = dwg_summ)
#   inputs_pe$interview_ang_per_group_type <- 
#     prep_inputs_pe_int_ang_per_group_type(
#       dwg_summarized = dwg_summ
#       )
# 
#   # # returns season-long total of counts for paired census and index counts
#   # inputs_pe$paired_census_index_counts <- 
#   #   prep_inputs_pe_paired_census_index_counts_drano(
#   #     days = dwg$days,
#   #     dwg_summarized = dwg_summ,
#   #     interview_ang_per_vehic = inputs_pe$interview_ang_per_vhcl_trlr,
#   #     census_expan = inputs_pe$census_expan
#   #   )
#   
#   # returns census-corrected daily mean angler hours 
#   inputs_pe$ang_hrs_daily_mean <- 
#     prep_inputs_pe_ang_hrs_bank_boat_drano(
#       days = dwg$days, 
#       dwg_summarized = dwg_summ,
#       interview_ang_per_vehic = inputs_pe$interview_ang_per_boat,
#       # paired_census_index_counts = inputs_pe$paired_census_index_counts,
#       # census_expan = inputs_pe$census_expan
#     )
#   
# }    

  #aggregate interviews per day per strata of [week/month-weekend/day-section_num-bank/boat-est_cg]
  #then multiply by TI-expanded effort estimate
  #dropping any date-section_num-angler_final-catch_groups for which only interview-based CPUE is available
  #but census-corrected effort estimates are not (various reasons why a day-section_num-angler_final hours could be NA)
  inputs_pe$daily_cpue_catch_est <- 
    prep_inputs_pe_daily_cpue_catch_est(
      days = dwg$days,
      dwg_summarized = dwg_summ,
      angler_hours_daily_mean = inputs_pe$ang_hrs_daily_mean
  )
  
# KB NOTE: in the above function, the "catch_estimate" for a particular "angler_final" grouping and section pair will be zero if no interviews are obtained on a given survey date. While this detail may not be a huge deal if zero interviews for a given "angler_final" by section/date is a result of little to no estimated angler effort.  HOWEVER, this could also be an artifact of creel survey effort (e.g., low creel effort resulting in some angler_final grouping simply not being interviewed even though they were present on a given date/section); an alternative approach would be to impute some sort of average "cpue_rom_daily" OR drop this date/section/angler_final grouping prior to the function "est_pe_catch" so that catch is estimated for this day AND not assumed to be zero (simply because no interview were obtained) 

# summary - creel surveys dates by section where estimated total effort for a particular "angler_final" grouping was >0  group but no interviews were obtained
inputs_pe$daily_cpue_catch_est |> filter(is.na(est_cg), angler_hours_daily_mean>0)


#THIS SEEMS WRONG/MISSING STRATA:  dplyr::group_by(section_num, angler_final)
inputs_pe$df <- 
  prep_inputs_pe_df_dev(
    days = dwg$days,
    angler_hours_daily_mean = inputs_pe$ang_hrs_daily_mean
)

```

## Paired census and index angler effort count surveys

```{r view_paired_census_index_counts, fig.cap= "Scatterplot displaying the effort bias-term ratio (TI_expan_final) for each section and angler type (angler_final), representing the total count from census surveys divided by the total count from index surveys. A 1:1 relationship is shown by the dashed line." }

#KB NOTE: this function doesn't work for Drano Lake dataset because "census" counts weren't completed; could update dataframe (e.g., copy index counts and create new column called "count_census" so that they functions at least runs though output would be meaningless)

# table view of census / index surveys and resulting bias term ratio 
inputs_pe$paired_census_index_counts |> 
  select(section_num, angler_final, count_census, count_index, TI_expan_final) |> 
  gt(caption = "The season-long sum of paired census and index angler effort counts and corresponding bias-term ratio (TI_expan_final), indicating the magnitude and direction (postive or negative) of bias in index counts relative to census counts") |> 
  fmt_number(count_index, decimals = 0) |> 
  fmt_number(TI_expan_final, decimals = 2)

# scatterplot of total census counts vs. total index counts by angler type and section 
plot_inputs_pe_census_vs_index(census_TI_expan = inputs_pe$paired_census_index_counts)

```


```{r estimates_pe}
estimates_pe <- list() 

estimates_pe$effort <- est_pe_effort(
  days = dwg$days,
  pe_inputs_list = inputs_pe
)

estimates_pe$catch <- est_pe_catch(
  days = dwg$days,
  pe_inputs_list = inputs_pe
)
 

# Next steps - 3.) update "inputs_pe$census_expan" object -- currenlty not using the indirect census expansion values from database due to naming issue in database (i.e., direct_census_bank should be indirect_census_boat) and ability/use of pivot_wider function to handle column header prefixes.

```

## Summary PE

### Effort estimates
```{r PE_effort_summary}

# effort by section_num
 estimates_pe$effort |>
        group_by(section_num, angler_final) |> 
        summarise(
          E_sum = round(sum(est, na.rm=T),0),
          .groups = "drop"
        ) |> 
  pivot_wider(names_from = section_num, values_from = E_sum) |>
  gt(caption = paste("Estimated effort (angler hours) by fishing section from", params$est_date_start, "to", params$est_date_end))

```

```{r plot_pe_effort_estimates, fig.cap= "Estimated effort (angler-hours) grouped by time strata, section and angler type (angler_final)."}
# barplot of effort estimates by time stratum, section, and angler type
  plot_est_pe_effort(
    estimates_pe_effort = estimates_pe$effort,
    period_pe = params$period_pe
  )

```
### Catch rate (CPUE) estimates

```{r pe_cpue_period_plots, results = 'hide'}

pe_cpue_period_plots <- 
  unique(inputs_pe$daily_cpue_catch_est$est_cg) |> 
  set_names() |> 
  map(
    ~plot_inputs_pe_cpue_period(
      days = dwg$days,
      dwg_summarized = dwg_summ,
      daily_cpue_catch_est = inputs_pe$daily_cpue_catch_est,
      est_catch_group = .x,
      period_pe = params$period_pe)
  )
      
pe_cpue_period_plots

```

Estimated catch per unit effort (fish/hour) grouped by catch group, period, section, angler type, and day-type. 

### Catch estimates

```{r PE_catch_summary}

estimates_pe$catch |> 
  group_by(est_cg, section_num) |>
  summarise(
    C_sum = sum(est),
    .groups = "drop"
  ) |> 
  pivot_longer(
    cols = -c(est_cg, section_num),
    names_to = "estimate",
    values_to = "PE"
  ) |> 
  select(est_cg, section_num, estimate, PE, everything()) |> 
  gt(groupname_col = "est_cg", caption = "Total estimates of catch during the monitoring period for each fish catch group.") |>
  fmt_number(-c(estimate, est_cg, section_num), decimals = 1) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "PE")
  ) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "PE")
  )
```


```{r plot_pe_catch_estimates, results = 'hide'}
# barplot of catch estimates by catch group, time stratum, section, and angler type

pe_catch_est_plots <- unique(estimates_pe$catch$est_cg) |> 
  set_names() |> 
  map(
    ~plot_est_pe_catch(
      estimates_pe_catch = estimates_pe$catch,
      est_catch_group = .x,
      period_pe = params$period_pe)
  )
      
pe_catch_est_plots
```

Estimated catch grouped by catch group, period, section, angler type,and day type. 

# BSS estimation

```{r prep_inputs_bss, eval=FALSE}
#either a single element list for a single catch_group
#or a list of bss-input-lists, one for each catch_group
inputs_bss <- 
  unique(na.omit(dwg_summ$interview$est_cg)) |> 
  set_names() |> 
  map(
    # ~prep_inputs_bss(
      ~prep_inputs_bss_dev(
        est_catch_group = .x,
        period = params$period_bss,
        days = dwg$days,
        dwg_summarized = dwg_summ,
        tie_in_mat = inputs_pe$census_expan, # KB addition/edit
        study_design = params$study_design, # KB addition/edit
        #KB edit: commented out following 9 lines, replaced with argument/input of "inputs_pe$census_expan" (above), and moved the summary of "tie_in_mat" (which before was set to be equal to "p_TI") inside the "prep_inputs_bss" function
        # #likely warrants revision? targeting n-gears-rows by n-sections-cols matrix of values
        # tie_in_mat = dwg$effort |> 
        #   filter(tie_in_indicator == 1) |> 
        #   distinct(section_num, p_census_bank, p_census_boat) |> 
        #   pivot_longer(starts_with("p_census"), names_to = "ang", values_to = "val") |> 
        #   arrange(section_num) |> 
        #   pivot_wider(names_from = section_num, values_from = val) |> 
        #   select(-ang) |> 
        #   as.matrix(),
      priors = c(
        value_cauchyDF_sigma_eps_C = 0.5,
        value_cauchyDF_sigma_eps_E = 0.5,
        value_cauchyDF_sigma_r_E = 0.5,  
        value_cauchyDF_sigma_r_C = 0.5,  
        value_cauchyDF_sigma_mu_C = 0.5, 
        value_cauchyDF_sigma_mu_E = 0.5, 
        value_normal_sigma_omega_C_0 = 1,
        value_normal_sigma_omega_E_0 = 3,
        value_lognormal_sigma_b = 1,
        value_normal_sigma_B1 = 5,  
        value_normal_mu_mu_C = log(0.02),
        value_normal_sigma_mu_C = 1.5,  
        value_normal_mu_mu_E = log(5),
        value_normal_sigma_mu_E = 2,  
        value_betashape_phi_E_scaled = 1, 
        value_betashape_phi_C_scaled = 1 
      )
    )
  )

```

```{r estimates_bss, eval=FALSE}
#should work for either single or multiple catch_group 
estimates_bss <- list()

for(ecg in names(inputs_bss)) {
  gc(verbose = T)
  
  ecg_fit <- fit_bss(
    bss_inputs_list = inputs_bss[[ecg]],
    n_iter = 2000
  )
  
  ecg_keep <- list()
  
  ecg_keep$overview <- get_bss_overview(bss_fit = ecg_fit, ecg = ecg)
  
  ecg_keep$cpue_daily <- get_bss_cpue_daily(bss_fit = ecg_fit, ecg = ecg)
  
  ecg_keep$catch_daily <- get_bss_catch_daily(bss_fit = ecg_fit, ecg = ecg)
  
  ecg_keep$effort_daily <- get_bss_effort_daily(bss_fit = ecg_fit, ecg = ecg)
  
  ecg_keep$draws <- extract(ecg_fit)
  
  # #can write wrapper on tidybayes::spread_draws or write our own
  # #to repackage full posterior of key estimated quantities
  # #such as daily catch or something else?
  # ecg_keep$catch_daily_draws <- ecg_fit |> tidybayes::spread_draws(C[s][d,g]) #long, each index still a col 
  # ecg_keep$catch_daily_draws <- ecg_fit |> tidybayes::spread_draws(C[s][d,g] | g) #a bit wider, bank/boat pivoted wide 

  estimates_bss[[ecg]] <- ecg_keep
    
  rm(ecg_fit, ecg_keep); gc()
}

```

## summary BSS

```{r BSS_summary, eval= FALSE}

# effort by section_num

map_df(estimates_bss, ~.x$overview) |> 
  gt(groupname_col = "est_cg") |>
  fmt_number(-c(estimate, est_cg), decimals = 1) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "50%")
  ) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "50%")
  )

```

## plot probability density function of effort and catch 

```{r, eval=FALSE}

season_results <- map_df(estimates_bss, ~.x$draws$C_sum) |> 
  mutate(iter = row_number()) |> 
  pivot_longer(cols = -(iter), names_to = "est_cg", values_to = "C_sum")

map_df(estimates_bss, ~.x$draws$C_sum) |> 
  mutate(iter = row_number()) |> 
  pivot_longer(cols = -(iter), names_to = "est_cg", values_to = "C_sum") |> 
  ggplot(aes(x=C_sum,fill=C_sum)) +
  facet_wrap(~ est_cg, ncol=1,scales = 'free') +
  theme_bw() +
  geom_density() +
  ylab(NULL) +
  geom_vline(
    season_results |> 
      group_by(est_cg) |> 
      summarise(C_sum = quantile(C_sum, c(0.025, 0.5, 0.975)), q = c(0.025, 0.5, 0.975)), mapping=aes(xintercept=C_sum,group=est_cg),linetype="dashed") +
theme(legend.title = element_blank())
    
```



## plot daily catch BSS

```{r, eval=FALSE}

map_df(estimates_bss, ~.x$catch_daily) |> 
    ggplot(aes(x = event_date, y = `50%`, fill = angler_final, color = angler_final)) +
    geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), alpha = 0.2, color = "transparent") +
    geom_line(lwd = 1) +
    ylab("Median (50%) catch") +
    xlab("Date") +
    labs(color = "Angler type", fill = "Angler type") +
    scale_x_date() +
    theme_bw() +
    facet_wrap(~section_num + est_cg)

```


## plot daily effort BSS

```{r,  eval=FALSE}

estimates_bss[[1]]$effort_daily |> 
    ggplot(aes(x = event_date, y = `50%`, fill = angler_final, color = angler_final)) +
    geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), alpha = 0.2, color = "transparent") +
    geom_line(lwd = 1) +
    ylab("Median (50%) effort (angler hours)") +
    xlab("Date") +
    labs(color = "Angler type", fill = "Angler type") +
    scale_x_date() +
    theme_bw() +
    facet_wrap(~section_num, nrow = estimates_bss[[1]]$effort_daily$section_num |> n_distinct())


```


## plot daily CPUE BSS

```{r, eval=FALSE}

map_df(estimates_bss, ~.x$cpue_daily) |> 
    ggplot(aes(x = event_date, y = `50%`, fill = angler_final, color = angler_final)) +
    geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), alpha = 0.2, color = "transparent") +
    geom_line(lwd = 1) +
    ylab("Median (50%) catch per unit effort (fish/hour") +
    xlab("Date") +
    labs(color = "Angler type", fill = "Angler type") +
    scale_x_date() +
    theme_bw() +
    facet_wrap(~section_num + est_cg)

```




# PE/BSS combined summary

```{r combo_overview, eval=FALSE}
#per-est_cg summary of total effort hours and catch/encounters, showing results of both PE and BSS estimation methods

map_df(estimates_bss, ~.x$overview) |> 
  left_join(
    bind_cols(
      estimates_pe$catch |> 
        group_by(est_cg) |>
        summarise(
          C_sum = sum(est),
          .groups = "drop"
        ),
      estimates_pe$effort |> 
        summarise(
          E_sum = sum(est, na.rm=T),
          .groups = "drop"
        )
    ) |> 
      pivot_longer(
        cols = -est_cg,
        names_to = "estimate",
        values_to = "PE"
      )
    ,
    by = c("estimate", "est_cg")
  ) |> 
  select(est_cg, estimate, PE, everything()) |> 
  gt(groupname_col = "est_cg") |>
  fmt_number(-c(estimate, est_cg), decimals = 1) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "PE")
  ) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "PE")
  ) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "50%")
  ) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "50%")
  )

```


# Save results

```{r write_out_results, eval = FALSE}
# bss_overview <- estimates_bss$summary_by_catchgroup
#write out a workbook with results from model runs 


## how to write out html to outputs file path??

# data fetched from dwg and summarized data used for PE and BSS (dwg_summ)
if(nchar(params$output_location_filepath) > 1) {
  writexl::write_xlsx(
  c(set_names(dwg, paste0("dwg_", names(dwg))), set_names(dwg_summ, paste0("dwg_summ", names(dwg_summ)))),
  path = file.path(here("fishery_analyses", params$project_name, params$fishery_name), paste0("fetch_dwg_", params$fishery_name, ".xlsx"))
  )
}

# PE output
if(nchar(params$output_location_filepath) > 1) {
  writexl::write_xlsx(
  c(estimates_pe[rev(names(estimates_pe))]),
  path = file.path(here("fishery_analyses", params$project_name, params$fishery_name), paste0("pe_output_", params$fishery_name, ".xlsx"))
  )
}

# overview of BSS output
# if(nchar(params$output_location_filepath) > 1) {
#   writexl::write_xlsx(bss_overview,
#   path = file.path(where("fishery_analyses", params$project_name, params$fishery_name), paste0("bss_overview_", params$fishery_name, ".xlsx"))
#   )
# }
```
