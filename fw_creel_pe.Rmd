---
title: "FW Creel Point Estimate"
date: "`r Sys.Date()`"
params:
  analysis_name: "District 13_Skykomish River_summer_chin_2022"
  days_wkend: !r c('Saturday', 'Sunday')
  model_period: "Week"
  index_count_types: "Vehicle/Trailers Only"
  census_expansion: "Direct"
  int_ang_hrs_tot_min: 0.25
  dir_output: "T:/DFW-Team FP D14 FW Creel - General/"
output:
  html_document:
    fig_caption: yes
    theme: default
    toc: yes
    toc_depth: 3
    toc_float: yes
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, fig.width = 10, fig.height = 8)

library("tidyverse")
library("patchwork")
library("gt")
theme_set(theme_light())

#base endpoints
dwg_base <- list(
  event = "https://data.wa.gov/resource/ui95-axtn.csv",
  effort = "https://data.wa.gov/resource/h9a6-g38s.csv",
  interview = "https://data.wa.gov/resource/rpax-ahqm.csv",
  catch = "https://data.wa.gov/resource/6y4e-8ftk.csv",
  gear = "https://data.wa.gov/resource/d2ks-afhz.csv" #currently unused?
)


input_analysis <- as_tibble(
  str_split_fixed(params$analysis_name, pattern = "_", n = 6),
  .name_repair = ~c("proj_name", "water_body", "season", "species", "year", "misc")
)

lu_input <- list() #focal river_lonlat, sections, census_exp and closures

lu_input$dates_holidays_2015_2030 <- read_lines("input_files/dates_holidays_2015_2030.txt") |>
  as.Date(format="%Y-%m-%d")

#!!Lon/lat only used in day-length calc?
#!!anywhere/anywhy that distinct() would be a problem?
#!!i.e., anyone realistically using this to run ests on widely spaced rivers?
lu_input$river_lonlat <- readr::read_csv("input_files/river_locations_master.csv") |> 
  dplyr::filter(River %in% input_analysis$water_body) |> 
  dplyr::distinct(River, .keep_all = T)

#!!note the current fetch drops/excludes effort and interview rows
#!!if no section assigned from section LU
lu_input$sections <- readr::read_csv(paste0("input_files/", params$analysis_name, "_sections.csv")) |> 
 dplyr::select(water_body_desc, location = location_code, section)

lu_input$census_exp <- readr::read_csv(paste0("input_files/", params$analysis_name, "_tiexp.csv")) |>  
  dplyr::mutate(cen_exp_meth = params$census_expansion)

lu_input$closures <- readr::read_csv(paste0("input_files/", params$analysis_name, "_closures.csv")) |> 
  tidyr::drop_na(event_date)


creel <- list() #data queried from DWG as list of tibbles
pe <- list() #intermediate objects wrangled from creel list elements

```

# `r paste(params$analysis_name)`

```{r}
gt(tibble(param = names(params), value = as.character(params)))
```

# Fetch data

```{r dwg_fetch, echo=FALSE}
creel$event <- paste0(
  dwg_base$event,
  "?$where=project_name in('", input_analysis$proj_name, "')",
  " AND water_body in('", paste0(input_analysis$water_body, collapse = "','"), "')", 
  " AND event_date between '", first(lu_input$closures$event_date),
  "T00:00:00' and '", last(lu_input$closures$event_date),
  "T00:00:00'&$limit=100000"
) |>
  utils::URLencode() |>
  readr::read_csv(show_col_types = F) |>
  dplyr::select(creel_event_id, water_body, event_date, tie_in_indicator)

##directly passing the desired section-locations works (with a double single quote)
#   " AND location in('", 
#   paste(str_replace_all(lu_input$sections$location, "'","''"), collapse = "','"),
##but the section field is still needed and so the join is also still needed... 
creel$effort <- paste0(
  dwg_base$effort,
  "?$where=creel_event_id in('",
  paste(creel$event$creel_event_id, collapse = "','"),
  "')&$limit=100000"
  ) |>
  utils::URLencode() |>
  readr::read_csv(show_col_types = F) |>
  dplyr::filter(!is.na(count_type)) |>
  dplyr::select(-created_datetime, -modified_datetime) |>
  dplyr::inner_join(lu_input$sections, by = c("location"))
  
#view has no field "location" corresponding to lu_input$sections
#must be created from interview_location or fishing_location
#so cannot pass directly to DWG API
creel$interview <- paste0(
  dwg_base$interview,
  "?$where=creel_event_id in('",
  paste(creel$event$creel_event_id, collapse = "','"),
  "')&$limit=100000"
  ) |>
  utils::URLencode() |>
  readr::read_csv(show_col_types = F) |>
  dplyr::select(
    -created_datetime, -modified_datetime,
    -state_residence, -zip_code) |>
  dplyr::mutate(
    location = if_else(is.na(interview_location), as.character(fishing_location), as.character(interview_location))
  ) |>
  dplyr::inner_join(lu_input$sections, by = c("location"))

#this needs to be filtered by the date-section applicable interviews or otherwise contains catch across entire project!
creel$catch <- paste0(
  dwg_base$catch,
  "?$where=creel_event_id in('",
  paste(creel$event$creel_event_id, collapse = "','"),"')",
  " AND interview_id in('", 
  paste(creel$interview$interview_id, collapse = "','"),
  "')&$limit=100000"
  ) |> 
  utils::URLencode() |>
  readr::read_csv(show_col_types = F) |>
  dplyr::select(interview_id, catch_id, species, run, life_stage, fin_mark, fate, fish_count) |> 
  dplyr::mutate(
    catch_group = paste(species, life_stage, fin_mark, fate, sep = "_") # fish catch groups to estimate catch of 
  )

creel$days <- tibble::tibble(
  event_date = lu_input$closures$event_date,
  Day = weekdays(event_date),
  DayType = if_else(
    Day %in% params$days_wkend | Day %in% lu_input$dates_holidays_2015_2030,
    "Weekend", "Weekday"),
  DayType_num = if_else(str_detect(DayType, "end"),1,0),
  DayL = suncalc::getSunlightTimes(
    date = event_date,
    tz = "America/Los_Angeles",
    lat = lu_input$river_lonlat$Lat,
    lon = lu_input$river_lonlat$Long,
    keep=c("sunrise", "sunset")
  ) |>
    mutate(DayL = as.numeric((sunset + 3600) - (sunrise - 3600))) |>
    pluck("DayL"),
  Week = as.numeric(format(event_date, "%V")),
  Month = as.numeric(format(event_date, "%m")),
  ModelPeriod = params$model_period,
  time_strata = if_else(ModelPeriod == "Month", Month, Week)
) |>
  tibble::rowid_to_column(var = "day_index") |>
  dplyr::left_join(lu_input$closures, by = "event_date")

# excluding specified closures, total number of days by section, weekday/end, and time strata for which to generate estimates
creel$days_total <- creel$days |>
  pivot_longer(
    cols = starts_with("open_section"), 
    names_to = "section", 
    values_to = "is_open") |>
  filter(is_open) |> 
  mutate(section = as.numeric(gsub("^.*_", "", section))) |>
  count(time_strata, DayType, section, name = "N_days")

  
```

## Days

```{r gt_creel_days}
creel$days_total |> pivot_wider(names_from = c(section, DayType), values_from = N_days) |> gt(rowname_col = "time_strata", caption = "Potential days of fishing by time strata, section and day type")
```

## Effort

```{r gt_creel_effort}
creel$effort |> 
  distinct(water_body, section, location, event_date, tie_in_indicator, count_sequence) |> 
  count(water_body, section, location, tie_in_indicator) |> 
  unite("water_body_section", water_body, section) |> 
  arrange(water_body_section, desc(tie_in_indicator)) |> 
  gt(groupname_col = "water_body_section", caption = "Index (tie_in: 0) and Census (tie_in: 1) sampling to date")
```

## Interview

```{r gt_creel_interview}
creel$interview |> count(water_body, section, location) |> gt(caption = "Number of interviews by analysis section")
```

## Catch

```{r gt_creel_catch}
creel$catch |> group_by(catch_group) |> summarise(fish_count = sum(fish_count), .groups = "drop") |> gt(caption = "Total reported encounters in interviews to date")
```

# Summarized observations

```{r calc_pe_ests, echo=FALSE}
#### pe$effort_census --------------
#Aggregate census (tie in) effort counts, associating to closest-in-time index count.
#take the initial effort_census, with all count_sequence == 1,
#add/overwrite the count_sequence val with that from closest temporal match from inline/anonymous paired counts object
pe$effort_census <- dplyr::left_join(
  #begin with focal census data
  creel$effort |> 
    dplyr::filter(tie_in_indicator == 1) |>
    dplyr::select(section, location, event_date, tie_in_indicator, count_type, count_quantity)
  ,
  #reassign count_seq from closest index
  dplyr::left_join(
    creel$effort |> dplyr::filter(tie_in_indicator == 1) |> 
      dplyr::distinct(section, location, event_date, tie_in_indicator, effort_start_time, count_sequence),
    creel$effort |> dplyr::filter(tie_in_indicator == 0) |> 
      dplyr::distinct(section, event_date, tie_in_indicator, effort_start_time, count_sequence),
    by = c( "section", "event_date"),
    suffix = c("_cen", "_ind")
  ) |>
    dplyr::group_by(section, event_date, location) |>
    dplyr::slice_min(abs(effort_start_time_cen - effort_start_time_ind), n = 1) |>
    dplyr::ungroup() |>
    dplyr::distinct(section, location, event_date, count_sequence = count_sequence_ind)
  ,
  by = c("section", "location", "event_date")
) |>
  dplyr::mutate(
    angler_type = dplyr::case_when(
      stringr::word(count_type, 1) %in% c("Bank","bank","Shore") ~ "bank",
      stringr::word(count_type, 1) %in% c("Boat","boat") ~ "boat" #Note "Boats" plural intentionally excluded
    )
  ) |>
  tidyr::drop_na(angler_type) |> 
  dplyr::group_by(section, event_date, tie_in_indicator, count_sequence, angler_type) |>
  dplyr::summarize(count_census = sum(count_quantity), .groups = "drop") |>
  dplyr::arrange(section, event_date, count_sequence)

#### pe$effort_index --------------
# filters and aggregates over locations within count_seq & section
# mutate angler_type here creates a later join-by column
pe$effort_index <- dplyr::filter(
  creel$effort, 
  tie_in_indicator == 0,
  is.na(no_count_reason),
  !is.na(count_type)
) |>
  dplyr::left_join(creel$days |> select(event_date, DayType), by = "event_date") |> 
  dplyr::group_by(section, DayType, event_date, count_sequence, count_type) |>
  dplyr::summarise(count_index = sum(count_quantity), .groups = "drop") |>
  dplyr::mutate(
    angler_type = dplyr::case_when(
      count_type == "Boat Anglers" ~ "boat",
      count_type == "Bank Anglers" ~ "bank",
      count_type == "Trailers Only" ~ "boat",
      count_type == "Vehicle Only" ~ "total"
    )
  ) |> 
  dplyr::arrange(section, event_date, count_sequence)

#### pe$interview --------------
# #interview data have angler_count, vehicle_count, trailer_count, angler_type and boat_used
# #disallow NAs in angler_type, fill missing angler_type from boat_used
pe$interview <- dplyr::left_join(
  creel$interview, 
  creel$days |> select(event_date, time_strata, DayType), 
  by = "event_date"
) |>
  dplyr::mutate(
    dplyr::across(c(vehicle_count, trailer_count), ~replace_na(., 0)),
    trip_status = replace_na(trip_status, "Unknown"),
    
    angler_type = tolower(angler_type),
    angler_type = dplyr::if_else(is.na(angler_type), boat_used, angler_type),
    angler_type = dplyr::case_when( 
      angler_type == "boat" ~ "boat", #pass through
      angler_type == "bank" ~ "bank", #pass through
      angler_type == "Unk" ~ "bank",  #Kalama, others?
      angler_type == "No" ~ "bank",   #value from boat_used
      angler_type == "Yes" ~ "boat"   #value from boat_used
    ),
    angler_type_ind = as.integer(factor(angler_type)),
    
    fishing_end_time = dplyr::if_else(
      trip_status == "Incomplete" | is.na(fishing_end_time),
      interview_time,
      fishing_end_time),
    angler_hours = round(as.numeric(fishing_end_time - fishing_start_time) / 3600, 5),
    angler_hours_total = angler_count * angler_hours
  ) |>
  dplyr::filter(angler_hours_total >= params$int_ang_hrs_tot_min) |> 
  #drop a few unused cols for ease of dev
  dplyr::select(-creel_event_id, -water_body, -project_name, -interview_number,
                -crc_area, -fishing_location, -ends_with("_time"),
                -previously_interviewed, -comment_txt, -water_body_desc
  ) |> 
  dplyr::arrange(section, time_strata, event_date, angler_type, location)

#### pe$interview_and_catch --------------
# join catch data to interview after inferring complete cases (counts or 0s for all catch_groups encountered)
# note rows in creel$catch for "short" interviews are lost if filtered above 
# interview_ids in creel$interview/pe_interview with no reported encounters are not in creel$catch
# so the pivots ensure that no-encounter interviews get assigned 0 fish_count for each possible catch_group
# and are therefore included in the later CPUE
pe$interview_and_catch <- left_join(
  pe$interview |> 
    select(section, time_strata, DayType, event_date,
           interview_id, angler_type, ends_with("_count"), angler_hours, angler_hours_total)
  ,
  creel$catch |> 
    group_by(interview_id, catch_group) |> 
    summarise(fish_count = sum(fish_count, na.rm = T), .groups = "drop") |> 
    pivot_wider(names_from = catch_group, values_from = fish_count)
  ,
  by = "interview_id"
) |> 
  pivot_longer(cols = -c(section:angler_hours_total), names_to = "catch_group", values_to = "fish_count") |> 
  mutate(fish_count = replace_na(fish_count, 0))


#### pe$angler_hours_daily_mean --------------
# depending on the types of index counts, reach the calc: ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * TI_expan_final
# when index counts are already bank & boat, matching census counts,
#   then angler_hour daily means are just effort index counts of anglers expanded by day length,
#   which are multiplied against tie-in expanded census counts of anglers by type (per section)
# but when index counts are trailers & vehicles,
#   then angler_hour daily means require first using interviews to estimate anglers_per_vhcl_trlr by angler_type total & boat 
#   so anglers_per_vhcl_trlr can be multiplied against the trailer & vehicle counts in effort_index, releveled to boat/total
#   and then TI-expanded counts similarly require splitting, releveling and rebinding census to boat/total to allow join with effort_index
#   and THEN generating a final object with total, boat and derived-bank, including dealing with case of only-bank (e.g., Cascade)

if(str_detect(params$index_count_types, "Bank|Boat")) {
  #initial angler_hours_daily_mean: join day length against mean counts over count_seqs per section-day-angler_type
  pe$angler_hours_daily_mean <- left_join(
    pe$effort_index |> 
      dplyr::group_by(section, event_date, angler_type) |>
      dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop"),
    creel$days |> select(event_date, DayL),
    by = "event_date") |>
    mutate(angler_hours_daily_mean = count_index_mean * DayL) |>
    arrange(section, event_date)
  
  #census_TI_expan: left join effort index counts to census counts and expand by TI
  #count_census begins summed by event_date, section, tie_in_indicator, count_sequence, with angler_type in [bank, boat]
  #excluding date-section-anglers with missing (or negative) counts as invalid to support inferring point estimates
  pe$census_TI_expan <- left_join(
    pe$effort_census,
    pe$effort_index,
    by = c("section", "event_date", "count_sequence", "angler_type")
  ) |>
    filter(
      !is.na(count_census), !is.na(count_index),
      count_census >= 0, count_index >= 0
    ) |> 
    group_by(section, angler_type) |>
    summarise(
      across(c(count_census, count_index), sum),
      TI_expan_weighted = count_census / count_index,
      TI_expan_weighted = if_else(TI_expan_weighted == 0, 1, TI_expan_weighted) |> replace_na(1),
      .groups = "drop") |>
    left_join(
      lu_input$census_exp |>
        select(cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
      by = c("section", "angler_type")) |>
    mutate(
      cen_exp_meth = replace_na(cen_exp_meth, params$census_expansion),
      p_TI = replace_na(p_TI, 1),
      TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
      TI_expan_final = if_else(
        cen_exp_meth == "Direct",
        TI_expan_weighted / p_TI,
        TI_expan_indirect)
    )
  #now overwrite object, adding TI-expansions
  pe$angler_hours_daily_mean <- left_join(
    pe$angler_hours_daily_mean,
    pe$census_TI_expan,
    by = c("section", "angler_type")
  ) |>
    mutate(ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * replace_na(TI_expan_final, 1)) 
  
} else if(str_detect(params$index_count_types, "Vehicle|Trailer")) {
  #in this case, boat and bank counts must be indirectly calc'd
  #first the interviews are used to estimate anglers per vehicle, stratified by boat vs total (from boat|bank angler_type rows in interview)
  #note that further below the section-dayType-angler_type mean is used to infer missing values 
  #both where a given section-date has interviews but lacks an angler_type
  #and where a section-date index count is missing interview data for either/both angler_types
  #the full date range of observations is included in the sample distribution under the assumptions that
  #more observations will tend to stablize the mean and that major temporal trends in carpooling are unlikely over the fishery duration
  #note that this can still fail if no interviews are available within section-dayType-angler_type...
  pe$interview_ang_per_vehic <- bind_rows(
    pe$interview |>
      group_by(section, DayType, event_date) |>
      summarize(angler_type = "total", anglers_per_vhcl_trlr = sum(angler_count) / sum(vehicle_count), .groups = "drop")
    ,
    pe$interview |>
      filter(angler_type == "boat") |>
      group_by(section, DayType, event_date) |>
      summarize(angler_type = "boat", anglers_per_vhcl_trlr = sum(angler_count) / sum(trailer_count), .groups = "drop")
    ) |> 
    arrange(section, event_date)
  
  ##alternative, probably not preferable option to infer missing angler_type on days with interview of the other
  ##opted for more general case to infer from mean whenever needed
  #   tidyr::complete(section, event_date, angler_type) |>
  #   left_join(creel$days |> select(event_date, DayType), by = "event_date") |>
  #   group_by(section, DayType, angler_type) |>
  #   mutate(anglers_per_vhcl_trlr = if_else(
  #     is.na(anglers_per_vhcl_trlr),
  #     mean(anglers_per_vhcl_trlr, na.rm=T),
  #     anglers_per_vhcl_trlr)) |>
  #   ungroup() |>
  #   select(section, DayType, event_date, angler_type, anglers_per_vhcl_trlr) |>
  #   arrange(section, event_date) |> print(n=50)
  
  #initially dropped rows of index counts where a given date-section-angler_type is missing from interview data
  #replace with a version using means if no interviews available to assign angler numbers per vehicle/trailer on a given day
  pe$angler_hours_daily_mean <- full_join(
    pe$interview_ang_per_vehic, #coerced above to total/boat
    pe$effort_index |> #already in total/boat
      dplyr::group_by(section, DayType, event_date, angler_type) |>
      dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop")
    ,
    by = c( "section", "DayType", "event_date", "angler_type")) |>
    group_by(section, DayType, angler_type) |> 
    mutate(
      count_index_mean = replace_na(count_index_mean, 0 ), # noticed NA's in count_index_mean that I think should be 0's, but should double check this thought 
      anglers_per_vhcl_trlr = if_else(
        is.na(anglers_per_vhcl_trlr),
        mean(anglers_per_vhcl_trlr, na.rm=T),
        anglers_per_vhcl_trlr)) |> 
    ungroup() |> 
    left_join(creel$days |> select(event_date, DayL), by = "event_date") |>
    mutate(angler_hours_daily_mean = anglers_per_vhcl_trlr * count_index_mean * DayL) |>
    select(-DayL, -anglers_per_vhcl_trlr, -count_index_mean) |> 
    drop_na(angler_hours_daily_mean) |> 
    arrange(section, event_date)
  
  #now coerce back to angler_type bank/boat (unexpanded)
  if(any(pe$angler_hours_daily_mean$angler_type=="boat")){
    pe$angler_hours_daily_mean <- pe$angler_hours_daily_mean |> 
      pivot_wider(
        names_from = angler_type, 
        values_from = c(angler_hours_daily_mean), 
      ) |>
      mutate(
        boat = tidyr::replace_na(boat, 0),
        bank = total - boat, total = NULL) |> 
      pivot_longer(cols = c(boat, bank), names_to = "angler_type", values_to = "angler_hours_daily_mean") |> 
      #NAs and negatives here reflect inadequate or problematic data barring meaningful inference...
      filter(!is.na(angler_hours_daily_mean), angler_hours_daily_mean >= 0)
  } else {
    pe$angler_hours_daily_mean <- pe$angler_hours_daily_mean |> 
      mutate(angler_type = "bank")
  }
  
  if(all(creel$effort$tie_in_indicator < 1)) {
    pe$census_TI_expan <- expand_grid(
      section = unique(pe$angler_hours_daily_mean$section), 
      angler_type = unique(pe$angler_hours_daily_mean$angler_type),
      TI_expan_final = 1)
  } else {
    #begin census expansion values object by joining census and index in terms of total & boat
    pe$census_TI_expan <- left_join(
      #census already grouped & summed by event_date, section, tie_in_indicator, count_sequence, and angler_type [bank, boat]
      #but as for interview above, first split and collapse to reassign angler_type as total & boat
      bind_rows(
        pe$effort_census |>
          group_by(section, event_date, count_sequence) |>
          summarize(angler_type = "total", count_census = sum(count_census),  .groups = "drop")
        ,
        pe$effort_census |>
          filter(angler_type == "boat") |>
          group_by(section, event_date, count_sequence) |>
          summarize(angler_type = "boat", count_census = sum(count_census), .groups = "drop")
      ),
      #index counts via interviews for angler-per-vehic; angler_type already total & boat
      #this is very similar to above pe$angler_hours_daily_mean
      #but all count_seqs rather than summarized to daily mean
      #as above, applies mean ang-per-vehic within section-daytype-angtype
      #where interview missing an ang-type or no interviews on that date
      #prevents loss of use of census info b/c of a single day missing interviews...
      full_join(
        pe$interview_ang_per_vehic,
        pe$effort_index,
        by = c( "section", "DayType", "event_date", "angler_type")
        ) |>
        group_by(section, DayType, angler_type) |> 
        mutate(
          anglers_per_vhcl_trlr = if_else(
            is.na(anglers_per_vhcl_trlr),
            mean(anglers_per_vhcl_trlr, na.rm=T),
            anglers_per_vhcl_trlr)) |> 
        ungroup() |> 
        mutate(count_index = anglers_per_vhcl_trlr * count_index) |>
        select(section, event_date, count_sequence, angler_type, count_index)
      ,
      by = c("section", "event_date", "count_sequence", "angler_type")
    ) |> 
      tidyr::drop_na(count_index)
    
    #now overwrite, coercing angler_type back to bank/boat as above for pe$angler_hours_daily_mean
    #again dropping NAs and negatives as invalid for inferring estimates
    if(any(pe$census_TI_expan$angler_type=="boat")){
      pe$census_TI_expan <- pe$census_TI_expan |> 
        pivot_longer(cols = c(count_census, count_index), names_to = "count_type", values_to = "count") |> 
        pivot_wider(names_from = angler_type, values_from = count) |>
        mutate(bank = total - boat, total = NULL) |> #filter(is.na(boat) | is.na(bank) | bank < 0)
        pivot_longer(cols = c(boat, bank), names_to = "angler_type", values_to = "count") |>
        pivot_wider(names_from = count_type, values_from = count) |> 
        filter(
          !is.na(count_census), !is.na(count_index),
          count_census >= 0, count_index >= 0
        )      
    } else {
      pe$census_TI_expan <- pe$census_TI_expan |>
        mutate(angler_type = "bank")
    }
    
    pe$census_TI_expan <- pe$census_TI_expan |> 
      group_by(section, angler_type) |> 
      summarise(
        across(c(count_census, count_index), sum),
        TI_expan_weighted = count_census / count_index,
        TI_expan_weighted = if_else(TI_expan_weighted == 0, 1, TI_expan_weighted) |> replace_na(1),
        .groups = "drop") |> 
      #and now bring in the external expansion values if any
      left_join(
        lu_input$census_exp |>
          select(cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
        by = c("section", "angler_type")) |>
      mutate(
        cen_exp_meth = replace_na(cen_exp_meth, params$census_expansion),
        p_TI = replace_na(p_TI, 1),
        TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
        TI_expan_final = if_else(
          cen_exp_meth == "Direct",
          TI_expan_weighted / p_TI,
          TI_expan_indirect)
      )
  }
  
  #now multiply mean daily effort in angler_hours by tie-in ratio bias term 
  #aiming for event_date, section, angler_type [total, boat, bank (as total-boat)]
  pe$angler_hours_daily_mean <- left_join(
    pe$angler_hours_daily_mean, 
    pe$census_TI_expan |> select(section, angler_type, TI_expan_final),
    by = c("section", "angler_type")
  ) |>
    mutate(ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * TI_expan_final)
  
}

#### pe$daily_cpue_catch_est ------------------------

#aggregate interviews per day per strata of [week/month-weekend/day-section-bank/boat-catch_group]
#   here including only "mean of ratios" (mean over interviews)
#   dropping "ratio of the means" (actually sums): sum(fish_count) / sum(angler_hours_total)
#then multiply by TI-expanded effort estimate
#dropping any date-section-angler_type-catch_groups for which only interview-based CPUE is available
#but census-corrected effort estimates are not (various reasons why a day-section-angler_type hours could be NA)
pe$daily_cpue_catch_est <- pe$interview_and_catch |>
  mutate(cpue_interview = fish_count / angler_hours_total) |>
  group_by(section, time_strata, DayType, event_date, angler_type, catch_group) |>
  summarise(cpue_mor_daily = mean(cpue_interview), .groups = "drop") |> 
  left_join(
    pe$angler_hours_daily_mean, 
    by = c("section", "DayType", "event_date", "angler_type")
  ) |>
  tidyr::drop_na(ang_hrs_daily_mean_TI_expan) |> 
  mutate(catch_estimate = round(cpue_mor_daily * ang_hrs_daily_mean_TI_expan, 3)) |>
  arrange(section, event_date, angler_type, catch_group)

# #degrees of freedom by section and angler type to apply to time strata estimates
#!! should the count of days sampled account for DayType within a week/month-section-angler_type?
pe$df <- left_join(
  pe$angler_hours_daily_mean, #already has DayType
  creel$days |> select(event_date, time_strata),
  by = "event_date"
) |> 
  count(section, time_strata, DayType, angler_type, name = "n_days_samp") |> 
  #count(time_strata, section, angler_type, name = "n_days_samp") |> 
  group_by(section, angler_type) |>
  mutate(df = (min(n_days_samp - 1) + sum(n_days_samp))/2) |> 
  ungroup()
# #!! to recover section-angler_type level only...
#   pe$df |> distinct(section, angler_type, df)

#!!pending above...note still incorrect actual "df = " calc...will update if needed  
# #used in final set of objects, could move into pe or make inline?
# ests$degrees_freedom_total <- pe$angler_hours_daily_mean |>
#   distinct(section, angler_type, n_days = n_days_total) |>
#   group_by(section, angler_type) |>
#   summarize(
#     min_n_days = min(n_days),
#     sum_n_days = sum(n_days),
#     degrees_freedom = min_n_days + sum_n_days / 2,
#     .groups = "drop"
#   )


#### pe$est_effort and $est_catch ---------------------

#!!the intersection of section-day-angler_type interview and effort observations may differ...
#!!opting to derive summarized estimates from the object more likely to encompass more observations
#!!but could revert to using hours in cpue object, in order to stay fully consistent with catch info?
#!!     pe$daily_cpue_catch_est |> distinct(section, time_strata, DayType, event_date, angler_type, ang_hrs_daily_mean_TI_expan)

#calculate mean and variance for section-time_strata-dayType-angler_type
#this is the finest stratification above individual days 
#sample size is inherently small for a DayType within week stratification
# -the var() and sd() functions return NA when passed a length-1 vector (single obs)
# -variance has limited meaning even when n=3, e.g. if sampling Fri & Sat & Sun
#BUT sample design itself (and first principles) stratify on DayType
#such that pooling over weekend/weekday is counter to data collection protocol/design
#could pool over weeks (and perhaps angler_type) if a better variance is desired over the fishery duration

pe$est_effort_s_ts_dt_at <- left_join(
  #dates expanded to n-sections * n-angler_types * n-days, previously held as "creel$days_section_angler_type" but only used once
  creel$days |>
    select(time_strata, DayType, event_date, starts_with("open_section")) |>
    pivot_longer(
      cols = starts_with("open_section"), 
      names_to = "section", 
      values_to = "is_open") |>
    filter(is_open) |> # what is this doing?
    mutate(
      section = as.numeric(gsub("^.*_", "", section)), 
      is_open = NULL,
      angler_type = list(unique(pe$angler_hours_daily_mean$angler_type)) 
    ) |> 
    # unnest(cols = section) |> 
    unnest(angler_type)
  ,
  #estimates of angler_hours possible to calculate for sampled dates-sections-angler_type 
  pe$angler_hours_daily_mean |> select(section, DayType, event_date, angler_type, ang_hrs_daily_mean_TI_expan)
  ,
  by = c("section", "DayType", "event_date", "angler_type")
) |>
  group_by(section, time_strata, DayType, angler_type) |>
  summarize(
    n_obs = sum(!is.na(ang_hrs_daily_mean_TI_expan)), #n_days = n(),
    across(
      .cols = c(ang_hrs_daily_mean_TI_expan),
      .fns = list(
        mean = ~mean(.x, na.rm = T),
        var = ~var(.x, na.rm = T)
      ), #sd = ~sd(.x, na.rm = T), med = ~median(.x, na.rm=T),
      .names = "ang_hrs_{.fn}"
    ), .groups = "drop") |> 
  right_join(creel$days_total, by = c("section", "time_strata", "DayType")) |> 
  #!!not sure this is correct - could/should recalc df for within-week/month?
  left_join(pe$df |> distinct(section, angler_type, df), by = c("section", "angler_type")) |> 
  #!!this carries forward the orig variance eqns but not sure if
  #!!1) eqns are correctly implemented or 
  #!!2) eqns are meaningful relative to the ang_hrs_var already present from base var() 
  #!! i.e., the 3rd term "adjustment coef" in the first case 
  #!! acts to reduce the first 2 terms' computed "variance", and is asymptotic to 0 for complete sampling
  #!! such that case logic prevents 0 total_effort_var at n_obs==N_days 
  mutate(
    ang_hrs_var = replace_na(ang_hrs_var, 0),
    est = N_days * ang_hrs_mean,
    var = if_else(
      n_obs < N_days,
      (N_days^2) * (ang_hrs_var / n_obs) * (1-(n_obs/N_days)),
      (N_days^2) * (ang_hrs_var / n_obs)
    ),
    l95 = est - qt(1-(0.05/2),df)*(var^0.5),
    u95 = est + qt(1-(0.05/2),df)*(var^0.5)
  ) 

pe$est_catch_s_ts_dt_at <- left_join(
  #dates expanded to n-sections * n-angler_types * n-days, previously held as "creel$days_section_angler_type" but only used once
  creel$days |>
    select(time_strata, DayType, event_date, starts_with("open_section")) |> 
    pivot_longer(
      cols = starts_with("open_section"), 
      names_to = "section", 
      values_to = "is_open") |>
    filter(is_open) |> 
    mutate(
      section = as.numeric(gsub("^.*_", "", section)), 
      is_open = NULL,
      angler_type = list(unique(pe$angler_hours_daily_mean$angler_type)) 
    ) |> 
    # unnest(cols = section) |> 
    unnest(angler_type)
  ,
  pe$daily_cpue_catch_est |> select(section, time_strata, DayType, event_date, angler_type, catch_group, catch_estimate)
  ,
  by = c("section", "time_strata", "DayType", "event_date", "angler_type")
) |> 
  group_by(section, time_strata, DayType, angler_type, catch_group) |>
  summarize(
    n_obs = sum(!is.na(catch_estimate)), #n_days = n(),
    across(
      .cols = c(catch_estimate),
      .fns = list(
        mean = ~mean(.x, na.rm = T),
        var = ~var(.x, na.rm = T)
      ), #sd = ~sd(.x, na.rm = T), med = ~median(.x, na.rm=T),
      .names = "catch_est_{.fn}"
    ), .groups = "drop") |> 
  right_join(creel$days_total, by = c("section", "time_strata", "DayType")) |> 
  left_join(pe$df |> distinct(section, angler_type, df), by = c("section", "angler_type")) |> 
  mutate(
    catch_est_var = replace_na(catch_est_var, 0),
    est = N_days * catch_est_mean,
    var = if_else(
      n_obs < N_days,
      (N_days^2) * (catch_est_var / n_obs) * (1-(n_obs/N_days)),
      (N_days^2) * (catch_est_var / n_obs)
    ),
    se = sqrt(var),
    l95 = est - qt(1-(0.05/2),df)*(var^0.5),
    u95 = est + qt(1-(0.05/2),df)*(var^0.5)
  ) |> 
  drop_na(catch_group)

#### write out a workbook ----------------------------
#not a great test, but allows passing "" to stop overwrite...
if(nchar(params$dir_output) > 1) {
  writexl::write_xlsx(
  c(pe[rev(names(pe))], set_names(creel, paste0("dwg_", names(creel)))),
  path = file.path(params$dir_output, paste0(params$analysis_name,".xlsx"))
  )
}
```

## Index counts

```{r pe$effort_index_col}
pe$effort_index |>
  mutate(count_sequence = factor(count_sequence)) |> 
  ggplot(aes(event_date, count_index, fill = count_sequence, color = count_sequence)) +
  #geom_point() + geom_text(aes(label = count_index), nudge_y = 1, check_overlap = T) +
  geom_col(position = position_dodge(width = 0.7)) +
  scale_x_date("", date_breaks = "3 days", date_labels =  "%m-%d") + scale_y_continuous("") +
  scale_color_brewer(palette = "Set2", aesthetics = c("color", "fill")) +
  facet_wrap(~section + count_type + angler_type, scales = "free", ncol = 1, labeller = label_wrap_gen(multi_line = F))

```

## Census counts

```{r pe$effort_census}
# pe$effort_census |>
#   mutate(count_sequence = factor(count_sequence)) |> 
#   ggplot(aes(event_date, count_census, fill = count_sequence, color = count_sequence)) +
#   #geom_point() + geom_text(aes(label = count_census), nudge_y = 1, check_overlap = T) +
#   geom_col(position = position_dodge(width = 0.7)) +
#   scale_x_date("", date_breaks = "1 day") + scale_y_continuous("") +
#   scale_color_brewer(palette = "Set2", aesthetics = c("color", "fill")) +
#   facet_wrap(~section + angler_type, scales = "fixed", ncol = 1, labeller = label_wrap_gen(multi_line = F))

pe$census_TI_expan |> 
  ggplot(aes(count_index, count_census, color = angler_type)) +
  geom_abline(slope = 1, intercept = 0, linetype = 2) +
  scale_x_continuous(limits = c(0, NA)) +
  scale_y_continuous(limits = c(0, NA)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(~paste("Section:",section), labeller = label_wrap_gen(multi_line = F))

```

## Total angler hours per interview

```{r pe$interview_dot_smooth}
pe$interview |>
  ggplot(aes(event_date, angler_hours_total, color = angler_type, fill = angler_type)) +
  geom_jitter(width = 0.1, alpha = 0.7) +
  geom_smooth(
    data = pe$interview |> group_by(section, angler_type, event_date) |> 
      summarise(angler_hours_total = median(angler_hours_total), .groups = "drop"),
    se = F
    ) +
  scale_x_date() +
  facet_wrap(~section + angler_type, scales = "free_x", ncol = 2, labeller = label_wrap_gen(multi_line = F)) 

```

## Catch

```{r pe$interview_and_catch}
pe$interview_and_catch |>
  group_by(section, time_strata, DayType, event_date, angler_type, catch_group) |> 
  summarise(fish_count = sum(fish_count), .groups = "drop") |> 
  filter(fish_count > 0) |>
  pivot_wider(names_from = angler_type, values_from = fish_count) |> 
  gt(groupname_col = "catch_group", rowname_col = "event_date") |> 
  fmt_missing(c("bank", "boat"))
  #gt::summary_rows(groups = TRUE, columns = "fish_count", fns = list(sum = ~sum(.)))

  # ggplot(aes(event_date, catch_group, size = fish_count, color = fish_count)) +
  # geom_point() +
  # scale_size_area() + scale_color_binned() +
  # scale_x_date("") + scale_y_discrete("") +
  # facet_wrap(~section + angler_type, scales = "fixed", ncol = 2, labeller = label_wrap_gen(multi_line = F))

```

# Effort estimates

## Grand totals

```{r gt_effort_totals}
#by angler_type, summed over weekday/weekend and week/month
pe$est_effort_s_ts_dt_at |>
  group_by(section, angler_type) |>
  summarise(across(c(est, var), ~round(sum(., na.rm = T))), .groups = "drop") |> 
  pivot_wider(names_from = angler_type, values_from = c(est, var)) |> 
  select(section, contains("bank"), contains("boat")) |> 
  gt(caption = "Total angler hours, sum over temporal strata") |> 
  fmt_number(columns = -section, decimals = 0) |> 
  gt::summary_rows(columns = contains("est"), fns = list(sum = ~round(sum(., na.rm = T),0)), decimals = 0)

```

## Census-adjusted daily mean angler hours

```{r gg_angler_hours_daily_mean}
pe$angler_hours_daily_mean |> 
  ggplot(aes(event_date, ang_hrs_daily_mean_TI_expan, fill = angler_type)) +
  geom_col(position = position_stack()) +
  scale_x_date("", date_breaks = "3 day", guide = guide_axis(n.dodge = 2)) +
  scale_y_continuous("Hours") +
  facet_wrap(~section + DayType, scales = "fixed", labeller = label_wrap_gen(multi_line = F), ncol = 2) +
  labs(
    title = "Daily angler hours, sampled days",
    subtitle = "Day length * (Census-adjusted and interview-informed index counts)")
```

## Angler hours by section-time_strata-DayType-angler_type 

```{r gg_angler_hours_est_ribbons}
pe$est_effort_s_ts_dt_at |> 
  ggplot(aes(time_strata, fill = angler_type, color = angler_type)) +
  geom_ribbon(aes(y = est, ymin = l95, ymax = u95), alpha = 0.4) +
  geom_line(aes(y = est)) +
  scale_y_continuous("Hours") +
  facet_wrap(~section + DayType, scales = "fixed", labeller = label_wrap_gen(multi_line = F), ncol = 2) +
  labs(
    title = "Estimated angler hours by time strata",
    subtitle = "Section-time-strata-DayType-angler-type means * N-days")
```

## Cumulative angler hours by day and angler type

```{r gg_cumulative_ang_hours}
pe$est_effort_s_ts_dt_at |> 
  drop_na(est) |> 
  group_by(DayType, angler_type) |> 
  mutate(effort_cml = cumsum(est)) |> 
  ungroup() |> 
  ggplot(aes(time_strata, effort_cml, color = angler_type)) +
  geom_line() +
  scale_y_continuous("Hours") +
  facet_wrap(~section + DayType, scales = "fixed", labeller = label_wrap_gen(multi_line = F), ncol = 2) +
  labs(
    title = "Cumulative estimated angler hours, strata-means to complete days",
    subtitle = "Section-time-strata-DayType-angler-type means * N-days")
```


# Catch estimates

```{r gt_catch}
gt_catch <- function(cg_string, negate = F){
  if(negate){
    d <- filter(pe$est_catch_s_ts_dt_at, !str_detect(catch_group, cg_string))
  } else {
    d <- filter(pe$est_catch_s_ts_dt_at, str_detect(catch_group, cg_string))
  }
  if(nrow(d)>0){
    bind_rows(
      d |> group_by(section, DayType, angler_type, catch_group) |> 
        summarise(across(c(est, var), ~round(sum(.), 1)), .groups = "drop") |> 
        pivot_wider(names_from = angler_type, values_from = c(est, var)) |> 
        select(section, DayType, catch_group, contains("bank"), contains("boat")) |> 
        mutate(est_total = est_bank + est_boat)
      ,
      d |> group_by(section, catch_group) |> 
        summarise(
          #angler_type = "total", 
          DayType = "total",
          est_total = round(sum(est), 1), .groups = "drop")
    ) |> 
      gt(groupname_col = c("section","catch_group")) |> 
      gt::fmt_number(columns = where(is.numeric), decimals = 1) |> 
      gt::fmt_missing(columns = where(is.numeric)) |>
      gt::tab_style(
        style = gt::cell_text(weight = "bold"),
        locations = cells_body(columns = starts_with("est_"), rows = DayType != "total")
      ) |> 
      gt::tab_style(
        style = gt::cell_fill(color = "#fc6508", alpha = 0.3),
        locations = cells_body(columns = contains("_bank"), rows = var_bank/est_bank > 5)
      ) |> 
      gt::tab_style(
        style = gt::cell_fill(color = "#fc6508", alpha = 0.3),
        locations = cells_body(columns = contains("_boat"), rows = var_boat/est_boat > 5)
      ) |> 
      gt::tab_style(
        style = gt::cell_borders(sides = "left"),
        locations = cells_body(columns = starts_with("est_"), rows = DayType != "total")
      ) |> 
      gt::tab_options(container.overflow.x = TRUE, container.overflow.y = TRUE)
  }
}

```


### Sockeye estimates by section

```{r sockeye_by_section}
d2 <- pe$est_catch_s_ts_dt_at |> filter(catch_group %in% c("Sockeye_Adult_AD_Kept", "Sockeye_Adult_UM_Kept"))
bind_rows(
  d2 |> group_by(section) |>
  summarise(
    catch = sum(est)
    # ,
    # var = sum(var),
    # se = sqrt(var)
  ) |> 
mutate(across(where(is.numeric), round, 3)) |>
left_join(
  lu_input$sections |> filter(location %in% c("From Hwy. 536 at Mt. Vernon (Memorial Hwy. Bridge) to mouth of Gilligan Creek", "From mouth of Gilligan Creek to the Dalles Bridge at Concrete"))
|> select(section,location)
) |> 
  select(section, location, catch) 
) |>
  gt(groupname_col = c("section")) |>
  gt::tab_options(container.overflow.x = TRUE, container.overflow.y = TRUE)


```

### Sockeye weekly

```{r sockeye_weekly}
d <- pe$est_catch_s_ts_dt_at |> filter(catch_group %in% c("Sockeye_Adult_AD_Kept", "Sockeye_Adult_UM_Kept"))
bind_rows(
  d |> group_by(time_strata, catch_group) |> 
    summarise(across(c(n_obs, est, var, se), ~round(sum(.), 0)), .groups = "drop")
) |> 
  gt(groupname_col = c("section","catch_group"), rowname_col = "angler_type") |> 
  gt::cols_hide("n_obs") |> 
  gt::fmt_integer(columns = where(is.numeric)) |> 
  gt::tab_options(container.overflow.x = TRUE, container.overflow.y = TRUE)
```


### Chinook marked

```{r chin_adult_ad}
gt_catch("Chinook_Adult_AD")
```

### Chinook unmarked

```{r chin_adult_um}
gt_catch("Chinook_Adult_UM")
```

### Coho

```{r coho}
gt_catch("Coho_Adult")
```

### Steelhead

```{r sthd}
gt_catch("Steelhead_Adult")
```

### Sockeye

```{r sockeye}
gt_catch("Sockeye_Adult")
```

### Jacks

```{r jacks}
gt_catch("Jack|Smolt|Steelhead_Unknown")
```

### Other species

```{r misc}
gt_catch(cg_string = "Chinook|Coho|Steelhead|Sockeye", negate = T)
```
