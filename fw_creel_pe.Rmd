---
title: "FW Creel Point Estimate"
date: "`r Sys.Date()`"
params:
  analysis_name: "District 14_Skagit River_summer_sockeye_2022"
  days_wkend: !r c('Saturday', 'Sunday')
  model_period: "Week"
  index_count_types: "Vehicle/Trailers Only"
  census_expansion: "Direct"
  int_ang_hrs_tot_min: 0.25
  dir_output: "T:/DFW-Team FP D14 FW Creel - General/"
output:
  html_document:
    fig_caption: yes
    theme: default
    toc: yes
    toc_depth: 3
    toc_float: yes
    code_folding: hide
---

```{r setup, include=FALSE}
library("tidyverse")
library("patchwork")
library("gt")

#base endpoints
dwg_base <- list(
  event = "https://data.wa.gov/resource/ui95-axtn.csv",
  effort = "https://data.wa.gov/resource/h9a6-g38s.csv",
  interview = "https://data.wa.gov/resource/rpax-ahqm.csv",
  catch = "https://data.wa.gov/resource/6y4e-8ftk.csv",
  gear = "https://data.wa.gov/resource/d2ks-afhz.csv" #currently unused?
)


input_analysis <- as_tibble(
  str_split_fixed(params$analysis_name, pattern = "_", n = 6),
  .name_repair = ~c("proj_name", "water_body", "season", "species", "year", "misc")
)

lu_input <- list() #focal river_lonlat, sections, census_exp and closures

lu_input$dates_holidays_2015_2030 <- read_lines("input_files/dates_holidays_2015_2030.txt") |>
  as.Date(format="%Y-%m-%d")

#!!Lon/lat only used in day-length calc?
#!!anywhere/anywhy that distinct() would be a problem?
#!!i.e., anyone realistically using this to run ests on widely spaced rivers?
lu_input$river_lonlat <- readr::read_csv("input_files/river_locations_master.csv") |> 
  dplyr::filter(River %in% input_analysis$water_body) |> 
  dplyr::distinct(River, .keep_all = T)

#!!note the current fetch drops/excludes effort and interview rows
#!!if no section assigned from section LU
lu_input$sections <- readr::read_csv(paste0("input_files/", params$analysis_name, "_sections.csv")) |> 
 dplyr::select(water_body_desc, location = location_code, section)

lu_input$census_exp <- readr::read_csv(paste0("input_files/", params$analysis_name, "_tiexp.csv")) |>  
  dplyr::mutate(cen_exp_meth = params$census_expansion)

lu_input$closures <- readr::read_csv(paste0("input_files/", params$analysis_name, "_closures.csv")) |> 
  tidyr::drop_na(event_date)


creel <- list() #data queried from DWG as list of tibbles
pe <- list() #intermediate objects wrangled from creel list elements

```

# `r paste(params$analysis_name)`

```{r}
gt(tibble(param = names(params), value = as.character(params)))
```

# Fetch data

```{r dwg_fetch, echo=FALSE}
creel$event <- paste0(
  dwg_base$event,
  "?$where=project_name in('", input_analysis$proj_name, "')",
  " AND water_body in('", paste0(input_analysis$water_body, collapse = "','"), "')", 
  " AND event_date between '", first(lu_input$closures$event_date),
  "T00:00:00' and '", last(lu_input$closures$event_date),
  "T00:00:00'&$limit=100000"
) |>
  utils::URLencode() |>
  readr::read_csv(show_col_types = F) |>
  dplyr::select(creel_event_id, water_body, event_date, tie_in_indicator)

##directly passing the desired section-locations works (with a double single quote)
#   " AND location in('", 
#   paste(str_replace_all(lu_input$sections$location, "'","''"), collapse = "','"),
##but the section field is still needed and so the join is also still needed... 
creel$effort <- paste0(
  dwg_base$effort,
  "?$where=creel_event_id in('",
  paste(creel$event$creel_event_id, collapse = "','"),
  "')&$limit=100000"
  ) |>
  utils::URLencode() |>
  readr::read_csv(show_col_types = F) |>
  dplyr::filter(!is.na(count_type)) |>
  dplyr::select(-created_datetime, -modified_datetime) |>
  dplyr::inner_join(lu_input$sections, by = c("location"))
  
#view has no field "location" corresponding to lu_input$sections
#must be created from interview_location or fishing_location
#so cannot pass directly to DWG API
creel$interview <- paste0(
  dwg_base$interview,
  "?$where=creel_event_id in('",
  paste(creel$event$creel_event_id, collapse = "','"),
  "')&$limit=100000"
  ) |>
  utils::URLencode() |>
  readr::read_csv(show_col_types = F) |>
  dplyr::select(
    -created_datetime, -modified_datetime,
    -state_residence, -zip_code) |>
  dplyr::mutate(
    location = if_else(is.na(interview_location), fishing_location, interview_location)
  ) |>
  dplyr::inner_join(lu_input$sections, by = c("location"))

#this needs to be filtered by the date-section applicable interviews or otherwise contains catch across entire project!
creel$catch <- paste0(
  dwg_base$catch,
  "?$where=creel_event_id in('",
  paste(creel$event$creel_event_id, collapse = "','"),"')",
  " AND interview_id in('", 
  paste(creel$interview$interview_id, collapse = "','"),
  "')&$limit=100000"
  ) |> 
  utils::URLencode() |>
  readr::read_csv(show_col_types = F) |>
  dplyr::select(interview_id, catch_id, species, run, life_stage, fin_mark, fate, fish_count) |> 
  dplyr::mutate(
    life_stage = replace_na(life_stage, "Adult"), # placeholder pending data corrections in fish apps 
    catch_group = paste(species, life_stage, fin_mark, fate, sep = "_") # fish catch groups to estimate catch of 
  )

creel$days <- tibble::tibble(
  event_date = lu_input$closures$event_date,
  Day = weekdays(event_date),
  DayType = if_else(
    Day %in% params$days_wkend | Day %in% lu_input$dates_holidays_2015_2030,
    "Weekend", "Weekday"),
  DayType_num = if_else(str_detect(DayType, "end"),1,0),
  DayL = suncalc::getSunlightTimes(
    date = event_date,
    tz = "America/Los_Angeles",
    lat = lu_input$river_lonlat$Lat,
    lon = lu_input$river_lonlat$Long,
    keep=c("sunrise", "sunset")
  ) |>
    mutate(DayL = as.numeric((sunset + 3600) - (sunrise - 3600))) |>
    pluck("DayL"),
  Week = as.numeric(format(event_date, "%V")),
  Month = as.numeric(format(event_date, "%m")),
  ModelPeriod = params$model_period,
  time_strata = if_else(ModelPeriod == "Month", Month, Week)
) |>
  tibble::rowid_to_column(var = "day_index") |>
  dplyr::left_join(lu_input$closures, by = "event_date")

# excluding specified closures, total number of days by section, weekday/end, and time strata for which to generate estimates
creel$days_total <- creel$days |>
  pivot_longer(
    cols = starts_with("open_section"), 
    names_to = "section", 
    values_to = "is_open") |>
  filter(is_open) |> 
  mutate(section = as.numeric(gsub("^.*_", "", section))) |>
  count(time_strata, DayType, section, name = "N_days")

  
```

## Days

```{r gt_creel_days}
creel$days_total |> pivot_wider(names_from = DayType, values_from = N_days) |> gt()
```

## Event

```{r gt_creel_event}
creel$event |> count(water_body, tie_in_indicator) |> gt()
```

## Effort

```{r gt_creel_effort}
creel$effort |> count(water_body, section, tie_in_indicator, location) |> gt()
```

## Interview

```{r gt_creel_interview}
creel$interview |> count(water_body, section, location) |> gt()
```

## Catch

```{r gt_creel_catch}
creel$catch |> count(catch_group) |> gt()
```


# Summarized observations

```{r calc_pe_ests, echo=FALSE}
#### pe$effort_census --------------
#Aggregate census (tie in) effort counts, associating to closest-in-time index count.
#take the initial effort_census, with all count_sequence == 1,
#add/overwrite the count_sequence val with that from closest temporal match from inline/anonymous paired counts object
pe$effort_census <- dplyr::left_join(
  #begin with focal census data
  creel$effort |> 
    dplyr::filter(tie_in_indicator == 1) |>
    dplyr::select(section, location, event_date, tie_in_indicator, count_type, count_quantity)
  ,
  #reassign count_seq from closest index
  dplyr::left_join(
    creel$effort |> dplyr::filter(tie_in_indicator == 1) |> 
      dplyr::distinct(section, location, event_date, tie_in_indicator, effort_start_time, count_sequence),
    creel$effort |> dplyr::filter(tie_in_indicator == 0) |> 
      dplyr::distinct(section, event_date, tie_in_indicator, effort_start_time, count_sequence),
    by = c( "section", "event_date"),
    suffix = c("_cen", "_ind")
  ) |>
    dplyr::group_by(section, event_date, location) |>
    dplyr::slice_min(abs(effort_start_time_cen - effort_start_time_ind), n = 1) |>
    dplyr::ungroup() |>
    dplyr::distinct(section, location, event_date, count_sequence = count_sequence_ind)
  ,
  by = c("section", "location", "event_date")
) |>
  dplyr::mutate(
    angler_type = dplyr::case_when(
      stringr::word(count_type, 1) %in% c("Bank","bank","Shore") ~ "bank",
      stringr::word(count_type, 1) %in% c("Boat","boat") ~ "boat" #Note "Boats" plural intentionally excluded
    )
  ) |>
  tidyr::drop_na(angler_type) |> 
  dplyr::select(section, event_date, tie_in_indicator, count_sequence, angler_type, count_census = count_quantity) |> 
  dplyr::arrange(section, event_date, count_sequence)

#### pe$effort_index --------------
# filters and aggregates over locations within count_seq & section
# mutate angler_type here creates a later join-by column
pe$effort_index <- dplyr::filter(
  creel$effort, 
  tie_in_indicator == 0,
  is.na(no_count_reason),
  !is.na(count_type)
) |>
  dplyr::left_join(creel$days |> select(event_date, DayType), by = "event_date") |> 
  dplyr::group_by(section, DayType, event_date, count_sequence, count_type) |>
  dplyr::summarise(count_index = sum(count_quantity), .groups = "drop") |>
  dplyr::mutate(
    angler_type = dplyr::case_when(
      count_type == "Boat Anglers" ~ "boat",
      count_type == "Bank Anglers" ~ "bank",
      count_type == "Trailers Only" ~ "boat",
      count_type == "Vehicle Only" ~ "total"
    )
  ) |> 
  dplyr::arrange(section, event_date, count_sequence)

#### pe$interview --------------
# #interview data have angler_count, vehicle_count, trailer_count, angler_type and boat_used
# #disallow NAs in angler_type, fill missing angler_type from boat_used
pe$interview <- dplyr::left_join(
  creel$interview, 
  creel$days |> select(event_date, time_strata, DayType), 
  by = "event_date"
) |>
  dplyr::mutate(
    dplyr::across(c(vehicle_count, trailer_count), ~replace_na(., 0)),
    trip_status = replace_na(trip_status, "Unknown"),
    
    angler_type = tolower(angler_type),
    angler_type = dplyr::if_else(is.na(angler_type), boat_used, angler_type),
    angler_type = dplyr::case_when( 
      angler_type == "boat" ~ "boat", #pass through
      angler_type == "bank" ~ "bank", #pass through
      angler_type == "Unk" ~ "bank",  #Kalama, others?
      angler_type == "No" ~ "bank",   #value from boat_used
      angler_type == "Yes" ~ "boat"   #value from boat_used
    ),
    angler_type_ind = as.integer(factor(angler_type)),
    
    fishing_end_time = dplyr::if_else(
      trip_status == "Incomplete" | is.na(fishing_end_time),
      interview_time,
      fishing_end_time),
    angler_hours = round(as.numeric(fishing_end_time - fishing_start_time) / 3600, 5),
    angler_hours_total = angler_count * angler_hours
  ) |>
  dplyr::filter(angler_hours_total >= params$int_ang_hrs_tot_min) |> 
  #drop a few unused cols for ease of dev
  dplyr::select(-creel_event_id, -water_body, -project_name, -interview_number,
                -crc_area, -fishing_location, -ends_with("_time"),
                -previously_interviewed, -comment_txt, -water_body_desc
  ) |> 
  dplyr::arrange(section, time_strata, event_date, angler_type, location)

#### pe$interview_and_catch --------------
# join catch data to interview after inferring complete cases (counts or 0s for all catch_groups encountered)
# note rows in creel$catch for "short" interviews are lost if filtered above 
# interview_ids in creel$interview/pe_interview with no reported encounters are not in creel$catch
# so the pivots ensure that no-encounter interviews get assigned 0 fish_count for each possible catch_group
# and are therefore included in the later CPUE
pe$interview_and_catch <- left_join(
  pe$interview |> 
    select(section, time_strata, DayType, event_date,
           interview_id, angler_type, ends_with("_count"), angler_hours, angler_hours_total)
  ,
  creel$catch |> 
    group_by(interview_id, catch_group) |> 
    summarise(fish_count = sum(fish_count, na.rm = T), .groups = "drop") |> 
    pivot_wider(names_from = catch_group, values_from = fish_count)
  ,
  by = "interview_id"
) |> 
  pivot_longer(cols = -c(section:angler_hours_total), names_to = "catch_group", values_to = "fish_count") |> 
  mutate(fish_count = replace_na(fish_count, 0))


#### pe$angler_hours_daily_mean --------------
# depending on the types of index counts, reach the calc: ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * TI_expan_final
# when index counts are already bank & boat, matching census counts,
#   then angler_hour daily means are just effort index counts of anglers expanded by day length,
#   which are multiplied against tie-in expanded census counts of anglers by type (per section)
# but when index counts are trailers & vehicles,
#   then angler_hour daily means require first using interviews to estimate anglers_per_vhcl_trlr by angler_type total & boat 
#   so anglers_per_vhcl_trlr can be multiplied against the trailer & vehicle counts in effort_index, releveled to boat/total
#   and then TI-expanded counts similarly require splitting, releveling and rebinding census to boat/total to allow join with effort_index
#   and THEN generating a final object with total, boat and derived-bank, including dealing with case of only-bank (e.g., Cascade)

if(str_detect(params$index_count_types, "Bank|Boat")) {
  #initial angler_hours_daily_mean: join day length against mean counts over count_seqs per section-day-angler_type
  pe$angler_hours_daily_mean <- left_join(
    pe$effort_index |> 
      dplyr::group_by(section, event_date, angler_type) |>
      dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop"),
    creel$days |> select(event_date, DayL),
    by = "event_date") |>
    mutate(angler_hours_daily_mean = count_index_mean * DayL) |>
    arrange(section, event_date)
  
  #census_TI_expan: left join effort index counts to census counts and expand by TI
  #count_census begins summed by event_date, section, tie_in_indicator, count_sequence, with angler_type in [bank, boat]
  #excluding date-section-anglers with missing (or negative) counts as invalid to support inferring point estimates
  pe$census_TI_expan <- left_join(
    pe$effort_census,
    pe$effort_index,
    by = c("section", "event_date", "count_sequence", "angler_type")
  ) |>
    filter(
      !is.na(count_census), !is.na(count_index),
      count_census >= 0, count_index >= 0
    ) |> 
    group_by(section, angler_type) |>
    summarise(
      TI_expan_weighted = sum(count_census) / sum(count_index),
      TI_expan_weighted = if_else(TI_expan_weighted == 0, 1, TI_expan_weighted) |> replace_na(1),
      .groups = "drop") |>
    left_join(
      lu_input$census_exp |>
        select(cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
      by = c("section", "angler_type")) |>
    mutate(
      cen_exp_meth = replace_na(cen_exp_meth, params$census_expansion),
      p_TI = replace_na(p_TI, 1),
      TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
      TI_expan_final = if_else(
        cen_exp_meth == "Direct",
        TI_expan_weighted / p_TI,
        TI_expan_indirect)
    )
  #now overwrite object, adding TI-expansions
  pe$angler_hours_daily_mean <- left_join(
    pe$angler_hours_daily_mean,
    pe$census_TI_expan,
    by = c("section", "angler_type")
  ) |>
    mutate(ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * replace_na(TI_expan_final, 1)) 
  
} else if(str_detect(params$index_count_types, "Vehicle|Trailer")) {
  #in this case, boat and bank counts must be indirectly calc'd
  #first the interviews are used to estimate anglers per vehicle, stratified by boat vs total (from boat|bank angler_type rows in interview)
  pe$interview_ang_per_vehic <- bind_rows(
    pe$interview |>
      group_by(section, DayType, event_date) |>
      summarize(angler_type = "total", anglers_per_vhcl_trlr = sum(angler_count) / sum(vehicle_count), .groups = "drop")
    ,
    pe$interview |>
      filter(angler_type == "boat") |>
      group_by(section, DayType, event_date) |>
      summarize(angler_type = "boat", anglers_per_vhcl_trlr = sum(angler_count) / sum(trailer_count), .groups = "drop")
  ) |> 
    arrange(section, event_date)
  
  # #note this left_join drops rows of index counts where a given date-section-angler_type is missing from interview data
  # pe$angler_hours_daily_mean <- left_join(
  #   pe$interview_ang_per_vehic, #coerced above to total/boat
  #   pe$effort_index |> #already in total/boat
  #     dplyr::group_by(section, event_date, angler_type) |>
  #     dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop")
  #   ,
  #   by = c( "section", "event_date", "angler_type")) |>
  #   left_join(creel$days |> select(event_date, DayL), by = "event_date") |>
  #   mutate(angler_hours_daily_mean = anglers_per_vhcl_trlr * count_index_mean * DayL) |>
  #   select(-DayL, -anglers_per_vhcl_trlr, -count_index_mean) |> 
  #   arrange(section, event_date)
  
  #replace with a version using means if no interviews available to assign angler numbers per vehicle/trailer on a given day?
  pe$angler_hours_daily_mean <- full_join(
    pe$interview_ang_per_vehic, #coerced above to total/boat
    pe$effort_index |> #already in total/boat
      dplyr::group_by(section, DayType, event_date, angler_type) |>
      dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop")
    ,
    by = c( "section", "DayType", "event_date", "angler_type")) |>
    group_by(section, DayType, angler_type) |> 
    mutate(
      anglers_per_vhcl_trlr = if_else(
        is.na(anglers_per_vhcl_trlr),
        mean(anglers_per_vhcl_trlr, na.rm=T),
        anglers_per_vhcl_trlr)) |> 
    ungroup() |> 
    left_join(creel$days |> select(event_date, DayL), by = "event_date") |>
    mutate(angler_hours_daily_mean = anglers_per_vhcl_trlr * count_index_mean * DayL) |>
    select(-DayL, -anglers_per_vhcl_trlr, -count_index_mean) |> 
    drop_na(angler_hours_daily_mean) |> 
    arrange(section, event_date)
  
  #now coerce back to angler_type bank/boat (unexpanded)
  if(any(pe$angler_hours_daily_mean$angler_type=="boat")){
    pe$angler_hours_daily_mean <- pe$angler_hours_daily_mean |> 
      pivot_wider(
        names_from = angler_type, 
        values_from = c(angler_hours_daily_mean), 
      ) |>
      mutate(
        boat = tidyr::replace_na(boat, 0),
        bank = total - boat, total = NULL) |> 
      pivot_longer(cols = c(boat, bank), names_to = "angler_type", values_to = "angler_hours_daily_mean") |> 
      #NAs and negatives here reflect inadequate or problematic data barring meaningful inference...
      filter(!is.na(angler_hours_daily_mean), angler_hours_daily_mean >= 0)
  } else {
    pe$angler_hours_daily_mean <- pe$angler_hours_daily_mean |> 
      mutate(angler_type = "bank")
  }
  
  if(is.null(pe$census_TI_expan)) {
    pe$census_TI_expan <- expand_grid(
      section = unique(pe$angler_hours_daily_mean$section), 
      angler_type = unique(pe$angler_hours_daily_mean$angler_type),
      TI_expan_final = 1)
  } else {
    #begin census expansion values object by joining census and index in terms of total & boat
    pe$census_TI_expan <- left_join(
      #census already grouped & summed by event_date, section, tie_in_indicator, count_sequence, and angler_type [bank, boat]
      #but as for interview above, first split and collapse to reassign angler_type as total & boat
      bind_rows(
        pe$effort_census |>
          group_by(section, event_date, count_sequence) |>
          summarize(angler_type = "total", count_census = sum(count_census),  .groups = "drop")
        ,
        pe$effort_census |>
          filter(angler_type == "boat") |>
          group_by(section, event_date, count_sequence) |>
          summarize(angler_type = "boat", count_census = sum(count_census), .groups = "drop")
      ),
      #index via interviews with angler_type already total & boat
      #this is very similar to initial pe$angler_hours_daily_mean, but not summarized to daily mean
      #note this will typically be an expanding left_join 
      #since interview_ang_per_vheic is per day-section but effort_index is per count_seq (per day-section)
      left_join(
        pe$interview_ang_per_vehic,
        pe$effort_index,
        by = c("section", "event_date", "angler_type")
      ) |>
        mutate(count_index = anglers_per_vhcl_trlr * count_index) |>
        select(section, event_date, count_sequence, angler_type, count_index)
      ,
      by = c("section", "event_date", "count_sequence", "angler_type")
    ) |> 
      tidyr::drop_na(count_index)
    
    #now overwrite, coercing angler_type back to bank/boat as above for pe$angler_hours_daily_mean
    #again dropping NAs and negatives as invalid for inferring estimates
    if(any(pe$census_TI_expan$angler_type=="boat")){
      pe$census_TI_expan <- pe$census_TI_expan |> 
        pivot_longer(cols = c(count_census, count_index), names_to = "count_type", values_to = "count") |> 
        pivot_wider(names_from = angler_type, values_from = count) |>
        mutate(bank = total - boat, total = NULL) |> #filter(is.na(boat) | is.na(bank) | bank < 0)
        pivot_longer(cols = c(boat, bank), names_to = "angler_type", values_to = "count") |>
        pivot_wider(names_from = count_type, values_from = count) |> 
        filter(
          !is.na(count_census), !is.na(count_index),
          count_census >= 0, count_index >= 0
        )      
    } else {
      pe$census_TI_expan <- pe$census_TI_expan |>
        mutate(angler_type = "bank")
    }
    
    pe$census_TI_expan <- pe$census_TI_expan |> 
      group_by(section, angler_type) |> 
      summarise(
        TI_expan_weighted = sum(count_census) / sum(count_index),
        TI_expan_weighted = if_else(TI_expan_weighted == 0, 1, TI_expan_weighted) |> replace_na(1),
        .groups = "drop") |> 
      #and now bring in the external expansion values if any
      left_join(
        lu_input$census_exp |>
          select(cen_exp_meth, angler_type, section, p_TI, TI_expan_indirect = Indirect_TI_Expan),
        by = c("section", "angler_type")) |>
      mutate(
        cen_exp_meth = replace_na(cen_exp_meth, params$census_expansion),
        p_TI = replace_na(p_TI, 1),
        TI_expan_indirect = as.numeric(TI_expan_indirect) |> replace_na(1),
        TI_expan_final = if_else(
          cen_exp_meth == "Direct",
          TI_expan_weighted / p_TI,
          TI_expan_indirect)
      )
  }
  
  #now multiply mean daily effort in angler_hours by tie-in ratio bias term 
  #aiming for event_date, section, angler_type [total, boat, bank (as total-boat)]
  pe$angler_hours_daily_mean <- left_join(
    pe$angler_hours_daily_mean, 
    pe$census_TI_expan |> select(section, angler_type, TI_expan_final),
    by = c("section", "angler_type")
  ) |>
    mutate(ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * TI_expan_final)
  
}

#### pe$daily_cpue_catch_est ------------------------

#aggregate interviews per day per strata of [week/month-weekend/day-section-bank/boat-catch_group]
#   here including only "mean of ratios" (mean over interviews)
#   dropping "ratio of the means" (actually sums): sum(fish_count) / sum(angler_hours_total)
#then multiply by TI-expanded effort estimate
#dropping any date-section-angler_type-catch_groups for which only interview-based CPUE is available
#but census-corrected effort estimates are not (various reasons why a day-section-angler_type hours could be NA)
pe$daily_cpue_catch_est <- pe$interview_and_catch |>
  mutate(cpue_interview = fish_count / angler_hours_total) |>
  group_by(section, time_strata, DayType, event_date, angler_type, catch_group) |>
  summarise(cpue_mor_daily = mean(cpue_interview), .groups = "drop") |> 
  left_join(
    pe$angler_hours_daily_mean, 
    by = c("section", "DayType", "event_date", "angler_type")
  ) |>
  tidyr::drop_na(ang_hrs_daily_mean_TI_expan) |> 
  mutate(catch_estimate = round(cpue_mor_daily * ang_hrs_daily_mean_TI_expan, 3)) |>
  arrange(section, event_date, angler_type, catch_group)

# #degrees of freedom by section and angler type to apply to time strata estimates
#!! should the count of days sampled account for DayType within a week/month-section-angler_type?
pe$df <- left_join(
  pe$angler_hours_daily_mean, #already has DayType
  creel$days |> select(event_date, time_strata),
  by = "event_date"
) |> 
  count(section, time_strata, DayType, angler_type, name = "n_days_samp") |> 
  #count(time_strata, section, angler_type, name = "n_days_samp") |> 
  group_by(section, angler_type) |>
  mutate(df = (min(n_days_samp - 1) + sum(n_days_samp))/2) |> 
  ungroup()
# #!! to recover section-angler_type level only...
#   pe$df |> distinct(section, angler_type, df)

#!!pending above...note still incorrect actual "df = " calc...will update if needed  
# #used in final set of objects, could move into pe or make inline?
# ests$degrees_freedom_total <- pe$angler_hours_daily_mean |>
#   distinct(section, angler_type, n_days = n_days_total) |>
#   group_by(section, angler_type) |>
#   summarize(
#     min_n_days = min(n_days),
#     sum_n_days = sum(n_days),
#     degrees_freedom = min_n_days + sum_n_days / 2,
#     .groups = "drop"
#   )


#### pe$est_effort and $est_catch ---------------------

#!!the intersection of section-day-angler_type interview and effort observations may differ...
#!!opting to derive summarized estimates from the object more likely to encompass more observations
#!!but could revert to using hours in cpue object, in order to stay fully consistent with catch info?
#!!     pe$daily_cpue_catch_est |> distinct(section, time_strata, DayType, event_date, angler_type, ang_hrs_daily_mean_TI_expan)

#calculate mean and variance for section-time_strata-dayType-angler_type
#this is the finest stratification above individual days 
#sample size is inherently small for a DayType within week stratification
# -the var() and sd() functions return NA when passed a length-1 vector (single obs)
# -variance has limited meaning even when n=3, e.g. if sampling Fri & Sat & Sun
#BUT sample design itself (and first principles) stratify on DayType
#such that pooling over weekend/weekday is counter to data collection protocol/design
#could pool over weeks (and perhaps angler_type) if a better variance is desired over the fishery duration

pe$est_effort_s_ts_dt_at <- left_join(
  #dates expanded to n-sections * n-angler_types * n-days, previously held as "creel$days_section_angler_type" but only used once
  creel$days |>
    select(time_strata, DayType, event_date, starts_with("open_section")) |> 
    pivot_longer(
      cols = starts_with("open_section"), 
      names_to = "section", 
      values_to = "is_open") |>
    filter(is_open) |> 
    mutate(
      section = as.numeric(gsub("^.*_", "", section)), 
      is_open = NULL,
      angler_type = list(unique(pe$angler_hours_daily_mean$angler_type)) 
    ) |> 
    unnest(cols = section) |> 
    unnest(cols = angler_type)
  ,
  #estimates of angler_hours possible to calculate for sampled dates-sections-angler_type 
  pe$angler_hours_daily_mean |> select(section, DayType, event_date, angler_type, ang_hrs_daily_mean_TI_expan)
  ,
  by = c("section", "DayType", "event_date", "angler_type")
) |>
  group_by(section, time_strata, DayType, angler_type) |>
  summarize(
    n_obs = sum(!is.na(ang_hrs_daily_mean_TI_expan)), #n_days = n(),
    across(
      .cols = c(ang_hrs_daily_mean_TI_expan),
      .fns = list(
        mean = ~mean(.x, na.rm = T),
        var = ~var(.x, na.rm = T)
      ), #sd = ~sd(.x, na.rm = T), med = ~median(.x, na.rm=T),
      .names = "ang_hrs_{.fn}"
    ), .groups = "drop") |> 
  right_join(creel$days_total, by = c("section", "time_strata", "DayType")) |> 
  #!!not sure this is correct - could/should recalc df for within-week/month?
  left_join(pe$df |> distinct(section, angler_type, df), by = c("section", "angler_type")) |> 
  #!!this carries forward the orig variance eqns but not sure if
  #!!1) eqns are correctly implemented or 
  #!!2) eqns are meaningful relative to the ang_hrs_var already present from base var() 
  #!! i.e., the 3rd term "adjustment coef" in the first case 
  #!! acts to reduce the first 2 terms' computed "variance", and is asymptotic to 0 for complete sampling
  #!! such that case logic prevents 0 total_effort_var at n_obs==N_days 
  mutate(
    ang_hrs_var = replace_na(ang_hrs_var, 0),
    est = N_days * ang_hrs_mean,
    var = if_else(
      n_obs < N_days,
      (N_days^2) * (ang_hrs_var / n_obs) * (1-(n_obs/N_days)),
      (N_days^2) * (ang_hrs_var / n_obs)
    ),
    l95 = est - qt(1-(0.05/2),df)*(var^0.5),
    u95 = est + qt(1-(0.05/2),df)*(var^0.5)
  ) 

pe$est_catch_s_ts_dt_at <- left_join(
  #dates expanded to n-sections * n-angler_types * n-days, previously held as "creel$days_section_angler_type" but only used once
  creel$days |>
    select(time_strata, DayType, event_date, starts_with("open_section")) |> 
    pivot_longer(
      cols = starts_with("open_section"), 
      names_to = "section", 
      values_to = "is_open") |>
    filter(is_open) |> 
    mutate(
      section = as.numeric(gsub("^.*_", "", section)), 
      is_open = NULL,
      angler_type = list(unique(pe$angler_hours_daily_mean$angler_type)) 
    ) |> 
    unnest(cols = section) |> 
    unnest(cols = angler_type)
  ,
  pe$daily_cpue_catch_est |> select(section, time_strata, DayType, event_date, angler_type, catch_group, catch_estimate)
  ,
  by = c("section", "time_strata", "DayType", "event_date", "angler_type")
) |> 
  group_by(section, time_strata, DayType, angler_type, catch_group) |>
  summarize(
    n_obs = sum(!is.na(catch_estimate)), #n_days = n(),
    across(
      .cols = c(catch_estimate),
      .fns = list(
        mean = ~mean(.x, na.rm = T),
        var = ~var(.x, na.rm = T)
      ), #sd = ~sd(.x, na.rm = T), med = ~median(.x, na.rm=T),
      .names = "catch_est_{.fn}"
    ), .groups = "drop") |> 
  right_join(creel$days_total, by = c("section", "time_strata", "DayType")) |> 
  left_join(pe$df |> distinct(section, angler_type, df), by = c("section", "angler_type")) |> 
  mutate(
    catch_est_var = replace_na(catch_est_var, 0),
    est = N_days * catch_est_mean,
    var = if_else(
      n_obs < N_days,
      (N_days^2) * (catch_est_var / n_obs) * (1-(n_obs/N_days)),
      (N_days^2) * (catch_est_var / n_obs)
    ),
    l95 = est - qt(1-(0.05/2),df)*(var^0.5),
    u95 = est + qt(1-(0.05/2),df)*(var^0.5)
  ) |> 
  drop_na(catch_group)

#### write out a workbook ----------------------------
writexl::write_xlsx(
  c(pe[rev(names(pe))], set_names(creel, paste0("dwg_", names(creel)))),
  path = file.path(params$dir_output, paste0(params$analysis_name,".xlsx"))
  )

```

## Census counts

```{r pe$effort_census}
pe$effort_census |>
  mutate(count_sequence = factor(count_sequence)) |> 
  ggplot(aes(event_date, count_census, fill = count_sequence, color = count_sequence)) +
  #geom_point() + geom_text(aes(label = count_census), nudge_y = 1, check_overlap = T) +
  geom_col(position = position_dodge(width = 0.7)) +
  scale_x_date("", date_breaks = "3 days") + scale_y_continuous("") +
  scale_color_brewer(palette = "Set2", aesthetics = c("color", "fill")) +
  facet_wrap(~section + angler_type, scales = "fixed", ncol = 1, labeller = label_wrap_gen(multi_line = F))

```

## Index counts

```{r pe$effort_index_col}
pe$effort_index |>
  mutate(count_sequence = factor(count_sequence)) |> 
  ggplot(aes(event_date, count_index, fill = count_sequence, color = count_sequence)) +
  #geom_point() + geom_text(aes(label = count_index), nudge_y = 1, check_overlap = T) +
  geom_col(position = position_dodge(width = 0.7)) +
  scale_x_date("", date_breaks = "3 days", date_labels =  "%m-%d") + scale_y_continuous("") +
  scale_color_brewer(palette = "Set2", aesthetics = c("color", "fill")) +
  facet_wrap(~section + count_type + angler_type, scales = "free", ncol = 1, labeller = label_wrap_gen(multi_line = F))

```

## Interview

```{r pe$interview_boxplot}
pe$interview |>
  mutate(event_date = format(event_date, "%m-%d")) |> 
  ggplot(aes(event_date, angler_hours_total, fill = angler_type)) +
  geom_boxplot(position = position_dodge(), outlier.shape = NA) +
  geom_jitter(width = 0.5) +
  scale_x_discrete(guide = guide_axis(angle = 90)) +
  facet_wrap(~section + angler_type, scales = "free", ncol = 2, labeller = label_wrap_gen(multi_line = F)) 

```

## Catch

```{r pe$interview_and_catch_dot}
pe$interview_and_catch |>
  group_by(section, time_strata, DayType, event_date, angler_type, catch_group) |> 
  summarise(fish_count = sum(fish_count), .groups = "drop") |> 
  filter(fish_count > 0) |> #scale_size_area still showing dots... 
  gt(groupname_col = "catch_group", rowname_col = "event_date")
  # ggplot(aes(event_date, catch_group, size = fish_count, color = fish_count)) +
  # geom_point() +
  # scale_size_area() + scale_color_binned() +
  # scale_x_date("") + scale_y_discrete("") +
  # facet_wrap(~section + angler_type, scales = "fixed", ncol = 2, labeller = label_wrap_gen(multi_line = F))

```

# Effort estimates

## Grand totals

```{r}
#by angler_type, summed over weekday/weekend and week/month
pe$est_effort_s_ts_dt_at |>
  group_by(section, angler_type) |>
  summarise(across(c(est, var), ~round(sum(., na.rm = T))), .groups = "drop") |> 
  gt() |> 
  gt::summary_rows(columns = est, fns = list(sum = ~round(sum(., na.rm = T),0)))

```

## Section-time_strata-DayType-angler_type 

```{r}
(
  ggplot(pe$angler_hours_daily_mean,
         aes(event_date, ang_hrs_daily_mean_TI_expan, fill = angler_type)) +
    geom_col(position = "dodge") +
    scale_x_date("", date_breaks = "1 week", guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous("Hours") +
    labs(
      title = "Daily angler hours, sampled days",
      subtitle = "Day length * (Census-adjusted and interview-informed index counts)")
) + (
  ggplot(pe$est_effort_s_ts_dt_at,
         aes(time_strata, est, fill = angler_type)) +
    geom_col(position = "dodge") +
    #scale_x_date("", date_breaks = "1 week", guide = guide_axis(n.dodge = 2)) +
    scale_y_continuous("Hours") +
    facet_wrap(~section + DayType, scales = "fixed", labeller = label_wrap_gen(multi_line = F), ncol = 2) +
    labs(
      title = "Daily estimated angler hours",
      subtitle = "Section-time-strata-DayType-angler-type means * N-days")
) + (
  ggplot(pe$est_effort_s_ts_dt_at |> 
           group_by(DayType, angler_type) |> mutate(effort_cml = cumsum(est)) |> ungroup(),
         aes(time_strata, effort_cml, color = angler_type)) +
    geom_line() +
    scale_y_continuous("Hours") +
    facet_wrap(~section + DayType, scales = "fixed", labeller = label_wrap_gen(multi_line = F), ncol = 2) +
    labs(
      title = "Cumulative angler hours, strata-means to complete days",
      subtitle = "Section-time-strata-DayType-angler-type means * N-days")
) + plot_layout(ncol = 1)
```


# Catch estimates

### Chinook marked

```{r chin_adult_ad}
d <- pe$est_catch_s_ts_dt_at |> filter(str_detect(catch_group, "Chinook_Adult_AD"))
bind_rows(
  d |> group_by(section, DayType, angler_type, catch_group) |> 
    summarise(across(c(n_obs, est, var), ~round(sum(.), 0)), .groups = "drop"),
  d |> group_by(section, catch_group) |> 
    summarise(angler_type = "total", DayType = "total", across(c(n_obs, est, var), ~round(sum(.), 0)), .groups = "drop")
) |> 
  gt(groupname_col = c("section","catch_group"), rowname_col = "angler_type") |> 
  gt::cols_hide("n_obs") |> 
  gt::fmt_integer(columns = where(is.numeric)) |> 
  gt::tab_options(container.overflow.x = TRUE, container.overflow.y = TRUE)
```

### Chinook unmarked

```{r chin_adult_um}
d <- pe$est_catch_s_ts_dt_at |> filter(str_detect(catch_group, "Chinook_Adult_UM"))
bind_rows(
  d |> group_by(section, DayType, angler_type, catch_group) |> 
    summarise(across(c(n_obs, est, var), ~round(sum(.), 0)), .groups = "drop"),
  d |> group_by(section, catch_group) |> 
    summarise(angler_type = "total", DayType = "total", across(c(n_obs, est, var), ~round(sum(.), 0)), .groups = "drop")
) |> 
  gt(groupname_col = c("section","catch_group"), rowname_col = "angler_type") |> 
  gt::cols_hide("n_obs") |> 
  gt::fmt_integer(columns = where(is.numeric)) |> 
  gt::tab_options(container.overflow.x = TRUE, container.overflow.y = TRUE)
```

### Coho

```{r coho}
d <- pe$est_catch_s_ts_dt_at |> filter(str_detect(catch_group, "Coho_Adult"))
bind_rows(
  d |> group_by(section, DayType, angler_type, catch_group) |> 
    summarise(across(c(n_obs, est, var), ~round(sum(.), 0)), .groups = "drop"),
  d |> group_by(section, catch_group) |> 
    summarise(angler_type = "total", DayType = "total", across(c(n_obs, est, var), ~round(sum(.), 0)), .groups = "drop")
) |> 
  gt(groupname_col = c("section","catch_group"), rowname_col = "angler_type") |>  
  gt::cols_hide("n_obs") |> 
  gt::fmt_integer(columns = where(is.numeric)) |> 
  gt::tab_options(container.overflow.x = TRUE, container.overflow.y = TRUE)
```

### Steelhead

```{r sthd}
d <- pe$est_catch_s_ts_dt_at |> filter(str_detect(catch_group, "Steelhead_Adult"))
bind_rows(
  d |> group_by(section, DayType, angler_type, catch_group) |> 
    summarise(across(c(n_obs, est, var), ~round(sum(.), 0)), .groups = "drop"),
  d |> group_by(section, catch_group) |> 
    summarise(angler_type = "total", DayType = "total", across(c(n_obs, est, var), ~round(sum(.), 0)), .groups = "drop")
) |> 
  gt(groupname_col = c("section","catch_group"), rowname_col = "angler_type") |> 
  gt::cols_hide("n_obs") |> 
  gt::fmt_integer(columns = where(is.numeric)) |> 
  gt::tab_options(container.overflow.x = TRUE, container.overflow.y = TRUE)
```

### Jacks

```{r chin_jack}
d <- pe$est_catch_s_ts_dt_at |> filter(str_detect(catch_group, "Chinook_Jack|Coho_Jack|Steelhead_Smolt_Steelhead_Unknown"))
bind_rows(
  d |> group_by(section, DayType, angler_type, catch_group) |> 
    summarise(across(c(n_obs, est, var), ~round(sum(.), 0)), .groups = "drop"),
  d |> group_by(section, catch_group) |> 
    summarise(angler_type = "total", DayType = "total", across(c(n_obs, est, var), ~round(sum(.), 0)), .groups = "drop")
) |> 
  gt(groupname_col = c("section","catch_group"), rowname_col = "angler_type") |> 
  gt::cols_hide("n_obs") |> 
  gt::fmt_integer(columns = where(is.numeric)) |> 
  gt::tab_options(container.overflow.x = TRUE, container.overflow.y = TRUE)
```

### Other species

```{r misc}
d <- pe$est_catch_s_ts_dt_at |> filter(!str_detect(catch_group, "Chinook|Coho|Steelhead")) 
bind_rows(
  d |> group_by(section, DayType, angler_type, catch_group) |> 
    summarise(across(c(n_obs, est, var), ~round(sum(.), 0)), .groups = "drop"),
  d |> group_by(section, catch_group) |> 
    summarise(angler_type = "total", DayType = "total", across(c(n_obs, est, var), ~round(sum(.), 0)), .groups = "drop")
) |> 
  gt(groupname_col = c("section","catch_group"), rowname_col = "angler_type") |> 
  gt::cols_hide("n_obs") |> 
  gt::fmt_integer(columns = where(is.numeric)) |> 
  gt::tab_options(container.overflow.x = TRUE, container.overflow.y = TRUE)
```

