---
title: "Freshater Creel Estimates"
date: "`r Sys.Date()`"
params:
  fishery_name: "Skagit fall salmon 2022"
  est_date_start: "2022-09-01"
  est_date_end: "2022-10-02"
  est_catch_groups: !r data.frame(rbind(
    c(species = 'Coho', life_stage = 'Adult', fin_mark = 'AD', fate = 'Kept'),
    c(species = 'Coho', life_stage = 'Adult', fin_mark = 'AD|UM|UNK|NA', fate = 'Kept'),
    c(species = 'Coho', life_stage = 'Adult', fin_mark = 'AD|UM|UNK|NA', fate = 'Released'),
    c(species = 'Coho', life_stage = 'Adult', fin_mark = 'AD|UM|UNK|NA', fate = 'Kept|Released'),
    c(species = 'Chinook', life_stage = 'Adult', fin_mark = 'UM|UNK|NA', fate = 'Kept'),
    c(species = 'Whitefish', life_stage = 'NA', fin_mark = 'AD|UM|UNK|NA', fate = 'Kept|Released|NA')
    ))
  person_count_type: "group"
  period_pe: "week"
  period_bss: "day"
  days_wkend: !r c('Saturday', 'Sunday')
  model_period: "Week"
  index_count_types: "Vehicle/Trailers Only"
  census_expansion: "Direct"
  min_fishing_time: 0.5
  dir_output: "model_output"
output:
  html_document:
    fig_caption: yes
    theme: default
    toc: yes
    toc_depth: 3
    toc_float: yes
    code_folding: hide
---

```{css, include=FALSE}
  .chart-shim {
    overflow: auto;
    }
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, fig.width = 10, fig.height = 8)

library("suncalc")
library("tidyverse")
library("patchwork")
library("gt")
theme_set(theme_light())

library("rstan")
rstan_options(auto_write = TRUE)

purrr::walk(list.files("R_functions/", full.names = T), source)

```

# `r paste(params$fishery_name)`

```{r}
gt(tibble(param = names(params), value = as.character(params)))
```

# Fetch raw data

```{r dwg_fetch, echo=FALSE}
dwg <- fetch_dwg(params$fishery_name)

# #!! TEMPORARY pending database table of same format...
# #!! will require extending fetch_dwg() when available
# #!! can reuse for other fishery existing _closure.csv files to add to main shared "closures.csv"
# lu_input$closures |> 
#   pivot_longer(names_to = "section", values_to = "open", cols =  -event_date) |> 
#   mutate(
#     fishery_name = params$fishery_name,
#     section = as.numeric(str_remove(section, "open_section_")),
#     closed = !open) |> 
#   filter(closed) |> 
#   select(fishery_name, section, event_date) |> 
#   arrange(event_date, section) |> 
#   write_csv("input_files/closures.csv")

# #to fix up Excel bunged date format
# read_csv("input_files/closures.csv", show_col_types = FALSE) |> 
#   mutate(event_date = as.Date(event_date, format = '%m/%d/%Y')) |> 
#   write_csv("input_files/closures.csv")

dwg$days <- prep_days(
  date_begin = params$est_date_start, #head(lu_input$closures$event_date, 1),
  date_end = params$est_date_end, #tail(lu_input$closures$event_date, 1),
  weekends = params$days_wkend,
  holidays = read_lines("input_files/dates_holidays_2015_2030.txt"), #lu_input$dates_holidays_2015_2030
  Lat = mean(dwg$ll$centroid_lat), #can/should consider smarter options
  Long = mean(dwg$ll$centroid_lon),#can/should consider smarter options 
  sections = unique(dwg$effort$section_num),
  closures = read_csv("input_files/closures.csv", show_col_types = FALSE) |> 
    filter(fishery_name == params$fishery_name)
  )
```

# Review fetched data

## Fishery sections

```{r table_sections}
dwg$effort |> 
  filter(location_type == "Section") |> 
  distinct(water_body, section_num, location) |> 
  arrange(section_num) |>
  select(`Water Body` = water_body, `Section Number` = section_num, `Location description` = location) |> 
  gt()
```

## Days

```{r gt_creel_days}

# BROKEN - This is a summary table of creel days similar to dwg$days_total above (which is also broken)
# creel$days_total |> pivot_wider(names_from = c(section, DayType), values_from = N_days) |> gt(rowname_col = "time_strata", caption = "Potential days of fishing by time strata, section and day type")
```

## Effort

```{r gt_creel_effort}
#NEEDS FINISHING
dwg$effort |> 
  distinct(section_num, location, event_date, tie_in_indicator, count_sequence) |> 
  count(section_num, location, tie_in_indicator)
  # mutate(tie_in_indicator = case_when(
  #   tie_in_indicator == 1 ~ "census",
  #   tie_in_indicator == 0 ~ "index"
  # )) |> 
  # pivot_wider(names_from = tie_in_indicator, values_from = n)
```

## Interview

```{r gt_creel_interview}
dwg$interview |> count(water_body, section_num, fishing_location) |> arrange(section_num) |> gt(caption = "Number of interviews by analysis section")
```

## Catch

```{r gt_creel_catch}
dwg$catch |> group_by(catch_group) |> summarise(fish_count = sum(fish_count), .groups = "drop") |> gt(caption = "Total reported encounters in interviews to date")
```

# Summarize observations

```{r prep_dwg_summ_shared_summary_objects, echo=FALSE}
dwg_summ <- list() #intermediate objects wrangled from creel list elements

#get count_type levels from interview to ensure alignment...?

#prep_interview() no longer excludes observations with NA vehicle_count/trailer_count
#requires handling during summarization for fisheries/records where these were not collected
dwg_summ$interview <- prep_dwg_interview(
  dwg_interview = dwg$interview |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))),
  dwg_catch = dwg$catch,
  person_count_type = params$person_count_type,
  min_fishing_time = params$min_fishing_time,
  est_catch_groups = params$est_catch_groups 
  )

#Aggregates census (tie in) effort counts, associating to closest-in-time index count
dwg_summ$effort_census <- prep_dwg_effort_census(
  eff = dwg$effort |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))))

#Aggregates index effort counts over locations within count_seq & section
dwg_summ$effort_index <- prep_dwg_effort_index(
  eff = dwg$effort |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))))
```

# BSS estimation

```{r prep_inputs_bss}
inputs_bss <- prep_inputs_bss(
  period = params$period_bss,
  days = dwg$days,
  dwg_summarized = dwg_summ,
  est_catch_group = unique(dwg_summ$interview$est_cg)[1],
  #likely warrants revision? targeting n-gears-rows by n-sections-cols matrix of values
  tie_in_mat = dwg$effort |> 
    filter(tie_in_indicator == 1) |> 
    distinct(section_num, p_census_bank, p_census_boat) |> 
    pivot_longer(starts_with("p_census"), names_to = "ang", values_to = "val") |> 
    arrange(section_num) |> 
    pivot_wider(names_from = section_num, values_from = val) |> 
    select(-ang) |> 
    as.matrix(),
  priors = c(
      value_cauchyDF_sigma_eps_C = 0.5,
      value_cauchyDF_sigma_eps_E = 0.5,
      value_cauchyDF_sigma_r_E = 0.5,  
      value_cauchyDF_sigma_r_C = 0.5,  
      value_cauchyDF_sigma_mu_C = 0.5, 
      value_cauchyDF_sigma_mu_E = 0.5, 
      value_normal_sigma_omega_C_0 = 1,
      value_normal_sigma_omega_E_0 = 3,
      value_lognormal_sigma_b = 1,
      value_normal_sigma_B1 = 5,  
      value_normal_mu_mu_C = log(0.02),
      value_normal_sigma_mu_C = 1.5,  
      value_normal_mu_mu_E = log(5),
      value_normal_sigma_mu_E = 2,  
      value_betashape_phi_E_scaled = 1, 
      value_betashape_phi_C_scaled = 1 
    )
)

```

```{r BSS_analysis, echo=FALSE}
bss_fit <- fit_bss(bss_inputs_list = inputs_bss
  #...override other default args here...
)

```

# PE estimation 

```{r PE_analysis_data, echo=FALSE}
pe_data <- list()

pe_data$days<-
  dwg$days  |>
  mutate(
    period = case_when(
      params$period_pe == "week" ~ Week,
      params$period_pe == "month" ~ Month,
      params$period_pe == "duration" ~ double(1)
    )
  )

pe_data$census_expan<-
  dwg$effort %>% 
  filter(location_type == "Section") %>% 
  distinct(section_num, p_census_bank, p_census_boat) %>%
  pivot_longer(
    cols = starts_with("p_census_"), 
    names_prefix = "p_census_",
    names_to = "angler_final",
    values_to = "p_census"
    ) %>% 
  dplyr::mutate(census_indir = 1) %>% 
  dplyr::mutate(cen_exp_meth = params$census_expansion) %>% 
  arrange(angler_final, section_num)

# Calculate total days the fishery was open per strata (strata = period, DayType, and section_num)
pe_data$days_total <- 
  pe_data$days |>
  pivot_longer(
    cols = starts_with("open_section"),
    names_to = "section_temp",
    values_to = "is_open") |>
  filter(is_open) |>
  mutate(section_num = as.numeric(gsub("^.*_", "", section_temp))) |>
  count(period, DayType, section_num, name = "N_days")

pe_data$effort_index<-   
  dwg_summ$effort_index |>
  left_join(pe_data$days |> select(event_date, DayType, period), by=c("event_date")) 

pe_data$effort_census<-
  dwg_summ$effort_census|>
   left_join(pe_data$days |> select(event_date, DayType, period), by=c("event_date"))
  
pe_data$interview<-
   dwg_summ$interview|>
   left_join(pe_data$days |> select(event_date, DayType, period), by=c("event_date"))

if(str_detect(params$index_count_types, "Bank|Boat")) {
  pe_data$effort_index <-
    pe_data$effort_index |>
    dplyr::mutate(
        angler_final = dplyr::case_when(
        count_type == "Boat Anglers" ~ "boat",
        count_type == "Bank Anglers" ~ "bank",
        )
    )
} else if(str_detect(params$index_count_types, "Vehicle|Trailer")) {
  pe_data$effort_index <-
    pe_data$effort_index |>
    dplyr::mutate(
      #angler_final = word(count_type, 1) |> tolower()
      angler_final = dplyr::case_when(
        count_type == "Trailers Only" ~ "boat",
        count_type == "Vehicle Only" ~ "total"
      )
    )
}
```
## Daily Effort
```{r PE_analysis_daily_effort, echo=FALSE}
pe_estimates <- list() 

#### pe_estimates$angler_hours_daily_mean --------------
# depending on the types of index counts, reach the calc: ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * TI_expan_final
# when index counts are already bank & boat, matching census counts,
#   then angler_hour daily means are just effort index counts of anglers expanded by day length,
#   which are multiplied against tie-in expanded census counts of anglers by type (per section_num)
# but when index counts are trailers & vehicles,
#   then angler_hour daily means require first using interviews to estimate anglers_per_vhcl_trlr by angler_final total & boat 
#   so anglers_per_vhcl_trlr can be multiplied against the trailer & vehicle counts in effort_index, releveled to boat/total
#   and then TI-expanded counts similarly require splitting, releveling and rebinding census to boat/total to allow join with effort_index
#   and THEN generating a final object with total, boat and derived-bank, including dealing with case of only-bank (e.g., Cascade)

if(str_detect(params$index_count_types, "Bank|Boat")) {
  #initial angler_hours_daily_mean: join day length against mean counts over count_seqs per section_num-day-angler_final
  pe_estimates$angler_hours_daily_mean <- left_join(
    pe_data$effort_index |> 
      dplyr::group_by(section_num, event_date, angler_final) |>
      dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop"),
    dwg$days |> select(event_date, DayL),
    by = "event_date") |>
    mutate(angler_hours_daily_mean = count_index_mean * DayL) |>
    arrange(section_num, event_date)
  
  #census_TI_expan: left join effort index counts to census counts and expand by TI
  #count_census begins summed by event_date, section_num, tie_in_indicator, count_sequence, with angler_final in [bank, boat]
  #excluding date-section_num-anglers with missing (or negative) counts as invalid to support inferring point estimates
  pe_estimates$census_TI_expan <- left_join(
    pe_data$effort_census,
    pe_data$effort_index,
    by = c("section_num", "event_date", "count_sequence", "angler_final")
  ) |>
    filter(
      !is.na(count_census), !is.na(count_index),
      count_census >= 0, count_index >= 0
    ) |> 
    group_by(section_num, angler_final) |>
    summarise(
      across(c(count_census, count_index), sum),
      TI_expan_weighted = count_census / count_index,
      TI_expan_weighted = if_else(TI_expan_weighted == 0, 1, TI_expan_weighted) |> replace_na(1),
      .groups = "drop",
      TI_expan_weighted = if_else(is.infinite(TI_expan_weighted), 1, TI_expan_weighted)
      ) |>
    left_join(
      pe_data$census_expan,
      by = c("section_num", "angler_final")) |>
    mutate(
      cen_exp_meth = replace_na(cen_exp_meth, params$census_expansion),
      p_census = replace_na(p_census, 1),
      census_indir = as.numeric(census_indir) |> replace_na(1),
      TI_expan_final = if_else(
        cen_exp_meth == "Direct",
        TI_expan_weighted / p_census,
        census_indir)
    )
  #now overwrite object, adding TI-expansions
  pe_estimates$angler_hours_daily_mean <- left_join(
    pe_estimates$angler_hours_daily_mean,
    pe_estimates$census_TI_expan,
    by = c("section_num", "angler_final")
  ) |>
    mutate(ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * replace_na(TI_expan_final, 1)) 
  
} else if(str_detect(params$index_count_types, "Vehicle|Trailer")) {
  #in this case, boat and bank counts must be indirectly calc'd
  #first the interviews are used to estimate anglers per vehicle, stratified by boat vs total (from boat|bank angler_final rows in interview)
  #note that further below the section_num-dayType-angler_final mean is used to infer missing values 
  #both where a given section_num-date has interviews but lacks an angler_final
  #and where a section_num-date index count is missing interview data for either/both angler_types
  #the full date range of observations is included in the sample distribution under the assumptions that
  #more observations will tend to stablize the mean and that major temporal trends in carpooling are unlikely over the fishery duration
  #note that this can still fail if no interviews are available within section_num-dayType-angler_final...
  ##7/15/22 - dropping stratification to avoid Inf from no-trailer boat anglers and to better match BSS 
  pe_estimates$interview_ang_per_vehic <- bind_rows(
    pe_data$interview |>
      #could re-introduce here: group_by(section_num)
      summarize(angler_final = "total", anglers_per_vhcl_trlr = sum(person_count_final) / sum(vehicle_count), .groups = "drop")
    ,
    pe_data$interview |>
      filter(angler_final == "boat") |>
      #could re-introduce here: group_by(section_num)
      summarize(angler_final = "boat", anglers_per_vhcl_trlr = sum(person_count_final) / sum(trailer_count), .groups = "drop")
    )
  
  #initially dropped rows of index counts where a given date-section_num-angler_final is missing from interview data
  #replace with a version using means if no interviews available to assign angler numbers per vehicle/trailer on a given day
  pe_estimates$angler_hours_daily_mean <- full_join(
    pe_estimates$interview_ang_per_vehic, #coerced above to total/boat
    pe_data$effort_index |> #already in total/boat
      dplyr::group_by(section_num, DayType, event_date, angler_final) |>
      dplyr::summarise(count_index_mean = mean(count_index), .groups = "drop")
    ,
    by = c("angler_final")) |>
    group_by(section_num, DayType, angler_final) |> 
    mutate(
      count_index_mean = replace_na(count_index_mean, 0 ), # noticed NA's in count_index_mean that I think should be 0's, but should double check this thought 
      anglers_per_vhcl_trlr = if_else(
        is.na(anglers_per_vhcl_trlr),
        mean(anglers_per_vhcl_trlr, na.rm=T),
        anglers_per_vhcl_trlr)) |> 
    ungroup() |> 
    left_join(dwg$days |> select(event_date, DayL), by = "event_date") |>
    mutate(angler_hours_daily_mean = anglers_per_vhcl_trlr * count_index_mean * DayL) |>
    select(-DayL, -anglers_per_vhcl_trlr, -count_index_mean) |> 
    drop_na(angler_hours_daily_mean) |> 
    arrange(section_num, event_date)
  
  #now coerce back to angler_final bank/boat (unexpanded)
  if(any(pe_estimates$angler_hours_daily_mean$angler_final=="boat")){
    pe_estimates$angler_hours_daily_mean <- pe_estimates$angler_hours_daily_mean |> 
      pivot_wider(
        names_from = angler_final, 
        values_from = c(angler_hours_daily_mean), 
      ) |>
      mutate(
        boat = tidyr::replace_na(boat, 0),
        bank = total - boat, total = NULL) |> 
      pivot_longer(cols = c(boat, bank), names_to = "angler_final", values_to = "angler_hours_daily_mean") |> 
      #NAs and negatives here reflect inadequate or problematic data barring meaningful inference...
      filter(!is.na(angler_hours_daily_mean), angler_hours_daily_mean >= 0)
  } else {
    pe_estimates$angler_hours_daily_mean <- pe_estimates$angler_hours_daily_mean |> 
      mutate(angler_final = "bank")
  }
  
  if(nrow(dwg_summ$effort_census) == 0) {
    pe_estimates$census_TI_expan <- expand_grid(
      section_num = unique(pe_estimates$angler_hours_daily_mean$section_num), 
      angler_final = unique(pe_estimates$angler_hours_daily_mean$angler_final),
      TI_expan_final = 1)
  } else {
    #begin census expansion values object by joining census and index in terms of total & boat
    pe_estimates$census_TI_expan <- left_join(
      #census already grouped & summed by event_date, section_num, tie_in_indicator, count_sequence, and angler_final [bank, boat]
      #but as for interview above, first split and collapse to reassign angler_final as total & boat
      bind_rows(
        pe_data$effort_census |>
          group_by(section_num, event_date, count_sequence) |>
          summarize(angler_final = "total", count_census = sum(count_census),  .groups = "drop")
        ,
        pe_data$effort_census |>
          filter(angler_final == "boat") |>
          group_by(section_num, event_date, count_sequence) |>
          summarize(angler_final = "boat", count_census = sum(count_census), .groups = "drop")
      ),
      #index counts via interviews for angler-per-vehic; angler_final already total & boat
      #this is very similar to above pe_estimates$angler_hours_daily_mean
      #but all count_seqs rather than summarized to daily mean
      #as above, applies mean ang-per-vehic within section_num-daytype-angtype
      #where interview missing an ang-type or no interviews on that date
      #prevents loss of use of census info b/c of a single day missing interviews...
      full_join(
        pe_estimates$interview_ang_per_vehic,
        pe_data$effort_index,
        by = c("angler_final")
        ) |>
        group_by(section_num, DayType, angler_final) |> 
        mutate(
          anglers_per_vhcl_trlr = if_else(
            is.na(anglers_per_vhcl_trlr),
            mean(anglers_per_vhcl_trlr, na.rm=T),
            anglers_per_vhcl_trlr)) |> 
        ungroup() |> 
        mutate(count_index = anglers_per_vhcl_trlr * count_index) |>
        select(section_num, event_date, count_sequence, angler_final, count_index)
      ,
      by = c("section_num", "event_date", "count_sequence", "angler_final")
    ) |> 
      tidyr::drop_na(count_index)
    
    #now overwrite, coercing angler_final back to bank/boat as above for pe_estimates$angler_hours_daily_mean
    #again dropping NAs and negatives as invalid for inferring estimates
    if(any(pe_estimates$census_TI_expan$angler_final=="boat")){
      pe_estimates$census_TI_expan <- pe_estimates$census_TI_expan |> 
        pivot_longer(cols = c(count_census, count_index), names_to = "count_type", values_to = "count") |> 
        pivot_wider(names_from = angler_final, values_from = count) |>
        mutate(boat = replace_na(boat, 0), # NA's here are implicit 0's due to lack of boat anglers in data  (example section_num = Cascade River, when grouped with other Skagit sections)
               bank = total - boat, total = NULL) |> #filter(is.na(boat) | is.na(bank) | bank < 0)
        pivot_longer(cols = c(boat, bank), names_to = "angler_final", values_to = "count") |>
        pivot_wider(names_from = count_type, values_from = count) |> 
        filter(
          !is.na(count_census), !is.na(count_index),
          count_census >= 0, count_index >= 0
        )      
    } else {
      pe_estimates$census_TI_expan <- pe_estimates$census_TI_expan |>
        mutate(angler_final = "bank")
    }
    
    pe_estimates$census_TI_expan <- pe_estimates$census_TI_expan |> 
      group_by(section_num, angler_final) |> 
      summarise(
        across(c(count_census, count_index), sum),
        TI_expan_weighted = count_census / count_index,
        TI_expan_weighted = if_else(TI_expan_weighted == 0, 1, TI_expan_weighted) |> replace_na(1),
        .groups = "drop",
      TI_expan_weighted = if_else(is.infinite(TI_expan_weighted), 1, TI_expan_weighted)
      ) |> 
      #and now bring in the external expansion values if any
      left_join(
        pe_data$census_expan ,
        by = c("section_num", "angler_final")) |>
      mutate(
        cen_exp_meth = replace_na(cen_exp_meth, params$census_expansion),
        p_census = replace_na(p_census, 1),
        census_indir = as.numeric(census_indir) |> replace_na(1),
        TI_expan_final = if_else(
          cen_exp_meth == "Direct",
          TI_expan_weighted / p_census,
          census_indir)
      )
  }
  
  #now multiply mean daily effort in fishing_time by tie-in ratio bias term 
  #aiming for event_date, section_num, angler_final [total, boat, bank (as total-boat)]
  pe_estimates$angler_hours_daily_mean <- left_join(
    pe_estimates$angler_hours_daily_mean, 
    pe_estimates$census_TI_expan |> select(section_num, angler_final, TI_expan_final),
    by = c("section_num", "angler_final")
  ) |>
    mutate(ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * TI_expan_final)
  
}
```
## Daily CPUE
```{r PE_analysis_daily_cpue, echo=FALSE}
#### pe_estimates$daily_cpue_catch_est ------------------------

#aggregate interviews per day per strata of [week/month-weekend/day-section_num-bank/boat-est_cg]
#   here including only "mean of ratios" (mean over interviews)
#   dropping "ratio of the means" (actually sums): sum(fish_count) / sum(fishing_time_total)
#then multiply by TI-expanded effort estimate
#dropping any date-section_num-angler_final-catch_groups for which only interview-based CPUE is available
#but census-corrected effort estimates are not (various reasons why a day-section_num-angler_final hours could be NA)
pe_estimates$daily_cpue_catch_est <- 
  pe_data$interview |>
  mutate(cpue_interview = fish_count / fishing_time_total) |>
  group_by(section_num, period, DayType, event_date, angler_final, est_cg) |>
  summarise(
    total_catch = sum(fish_count),
    total_hours = sum(fishing_time_total),
    cpue_rom_daily = total_catch / total_hours, .groups = "drop") |> 
  left_join(
    pe_estimates$angler_hours_daily_mean, 
    by = c("section_num", "DayType", "event_date", "angler_final")
  ) |>
  tidyr::drop_na(ang_hrs_daily_mean_TI_expan) |> 
  mutate(catch_estimate = round(cpue_rom_daily * ang_hrs_daily_mean_TI_expan, 3)) |>
  arrange(section_num, event_date, angler_final, est_cg)
```

## DF Table
```{r PE_analysis_df_table, echo=FALSE}
# #degrees of freedom by section_num and angler type to apply to time strata estimates
#!! should the count of days sampled account for DayType within a week/month-section_num-angler_final?
pe_estimates$df <- left_join(
  pe_estimates$angler_hours_daily_mean, #already has DayType
  pe_data$days |> select(event_date, period),
  by = "event_date"
) |> 
  count(section_num, period, DayType, angler_final, name = "n_days_samp") |> 
  #count(period, section_num, angler_final, name = "n_days_samp") |> 
  group_by(section_num, angler_final) |>
  mutate(df = (min(n_days_samp - 1) + sum(n_days_samp))/2) |> 
  ungroup()
# #!! to recover section_num-angler_final level only...
#   pe_estimates$df |> distinct(section_num, angler_final, df)

#!!pending above...note still incorrect actual "df = " calc...will update if needed  
# #used in final set of objects, could move into pe_estimates or make inline?
# ests$degrees_freedom_total <- pe_estimates$angler_hours_daily_mean |>
#   distinct(section_num, angler_final, n_days = n_days_total) |>
#   group_by(section_num, angler_final) |>
#   summarize(
#     min_n_days = min(n_days),
#     sum_n_days = sum(n_days),
#     degrees_freedom = min_n_days + sum_n_days / 2,
#     .groups = "drop"
#   )
```
## Expanded Effort
```{r PE_analysis_expanded_effort, echo=FALSE}

#### pe_estimates$est_effort and $est_catch ---------------------

#!!the intersection of section_num-day-angler_final interview and effort observations may differ...
#!!opting to derive summarized estimates from the object more likely to encompass more observations
#!!but could revert to using hours in cpue object, in order to stay fully consistent with catch info?
#!!     pe_estimates$daily_cpue_catch_est |> distinct(section_num, period, DayType, event_date, angler_final, ang_hrs_daily_mean_TI_expan)

#calculate mean and variance for section_num-period-dayType-angler_final
#this is the finest stratification above individual days 
#sample size is inherently small for a DayType within week stratification
# -the var() and sd() functions return NA when passed a length-1 vector (single obs)
# -variance has limited meaning even when n=3, e.g. if sampling Fri & Sat & Sun
#BUT sample design itself (and first principles) stratify on DayType
#such that pooling over weekend/weekday is counter to data collection protocol/design
#could pool over weeks (and perhaps angler_final) if a better variance is desired over the fishery duration

pe_estimates$est_effort_s_ts_dt_at <- left_join(
  #dates expanded to n-sections * n-angler_types * n-days, previously held as "creel$days_section_angler_type" but only used once
  pe_data$days |>
    select(period, DayType, event_date, starts_with("open_section")) |>
    pivot_longer(
      cols = starts_with("open_section"), 
      names_to = "section_num", 
      values_to = "is_open") |>
    filter(is_open) |> # what is this doing?
    mutate(
      section_num = as.numeric(gsub("^.*_", "", section_num)), 
      is_open = NULL,
      angler_final = list(unique(pe_estimates$angler_hours_daily_mean$angler_final)) 
    ) |> 
    # unnest(cols = section_num) |> 
    unnest(angler_final)
  ,
  #estimates of fishing_time possible to calculate for sampled dates-sections-angler_final 
  pe_estimates$angler_hours_daily_mean |> select(section_num, DayType, event_date, angler_final, ang_hrs_daily_mean_TI_expan)
  ,
  by = c("section_num", "DayType", "event_date", "angler_final")
) |>
  group_by(section_num, period, DayType, angler_final) |>
  summarize(
    n_obs = sum(!is.na(ang_hrs_daily_mean_TI_expan)), #n_days = n(),
    across(
      .cols = c(ang_hrs_daily_mean_TI_expan),
      .fns = list(
        mean = ~mean(.x, na.rm = T),
        var = ~var(.x, na.rm = T)
      ), #sd = ~sd(.x, na.rm = T), med = ~median(.x, na.rm=T),
      .names = "ang_hrs_{.fn}"
    ), .groups = "drop") |> 
  right_join(pe_data$days_total, by = c("section_num", "period", "DayType")) |> 
  #!!not sure this is correct - could/should recalc df for within-week/month?
  left_join(pe_estimates$df |> distinct(section_num, angler_final, df), by = c("section_num", "angler_final")) |> 
  #!!this carries forward the orig variance eqns but not sure if
  #!!1) eqns are correctly implemented or 
  #!!2) eqns are meaningful relative to the ang_hrs_var already present from base var() 
  #!! i.e., the 3rd term "adjustment coef" in the first case 
  #!! acts to reduce the first 2 terms' computed "variance", and is asymptotic to 0 for complete sampling
  #!! such that case logic prevents 0 total_effort_var at n_obs==N_days 
  mutate(
    ang_hrs_var = replace_na(ang_hrs_var, 0),
    est = N_days * ang_hrs_mean,
    var = if_else(
      n_obs < N_days,
      (N_days^2) * (ang_hrs_var / n_obs) * (1-(n_obs/N_days)),
      (N_days^2) * (ang_hrs_var / n_obs)
    ),
    l95 = est - qt(1-(0.05/2),df)*(var^0.5),
    u95 = est + qt(1-(0.05/2),df)*(var^0.5)
  ) 
```
## Expanded Catch
```{r PE_analysis_expanded_catch, echo=FALSE}
pe_estimates$est_catch_s_ts_dt_at <- left_join(
  #dates expanded to n-sections * n-angler_types * n-days
  pe_data$days |>
    select(period, DayType, event_date, starts_with("open_section")) |> 
    pivot_longer(
      cols = starts_with("open_section"), 
      names_to = "section_num", 
      values_to = "is_open") |>
    filter(is_open) |> 
    mutate(
      section_num = as.numeric(gsub("^.*_", "", section_num)), 
      is_open = NULL,
      angler_final = list(unique(pe_estimates$angler_hours_daily_mean$angler_final)) 
    ) |> 
    # unnest(cols = section_num) |> 
    unnest(angler_final)
  ,
  pe_estimates$daily_cpue_catch_est |> select(section_num, period, DayType, event_date, angler_final, est_cg, catch_estimate)
  ,
  by = c("section_num", "period", "DayType", "event_date", "angler_final")
) |> 
  group_by(section_num, period, DayType, angler_final, est_cg) |>
  summarize(
    n_obs = sum(!is.na(catch_estimate)), #n_days = n(),
    across(
      .cols = c(catch_estimate),
      .fns = list(
        mean = ~mean(.x, na.rm = T),
        var = ~var(.x, na.rm = T)
      ), #sd = ~sd(.x, na.rm = T), med = ~median(.x, na.rm=T),
      .names = "catch_est_{.fn}"
    ), .groups = "drop") |> 
  right_join(pe_data$days_total, by = c("section_num", "period", "DayType")) |> 
  left_join(pe_estimates$df |> distinct(section_num, angler_final, df), by = c("section_num", "angler_final")) |> 
  mutate(
    catch_est_var = replace_na(catch_est_var, 0),
    est = N_days * catch_est_mean,
    var = if_else(
      n_obs < N_days,
      (N_days^2) * (catch_est_var / n_obs) * (1-(n_obs/N_days)),
      (N_days^2) * (catch_est_var / n_obs)
    ),
    se = sqrt(var),
    l95 = est - qt(1-(0.05/2),df)*(var^0.5),
    u95 = est + qt(1-(0.05/2),df)*(var^0.5)
  ) |> 
  drop_na(est_cg)

# Next steps - 1.) wrap "Run PE Analysis" inside 1 or 5 functions, 2.) revisit creation and use of the "pe_data" object, 3.) update "pe_data$census_expan" object -- currenlty not using the indirect census expansion values from database due to naming issue in database (i.e., direct_census_bank should be indirect_census_boat) and ability/use of pivot_wider function to handle column header prefixes.

```




# Results

```{r BSS_summary, echo=FALSE}

# PLACEHOLDER - next steps 1.) save model output, save model warnings (divergent transition...), model run time, and very basic summary table (e.g., catch & effort by section, angler, and total), 2.) revisiting model diagnostics (posterior distribution plots, key parameters, shinystan), 3.) revisiting more detailed summaries (e.g., daily plots of CPUE, effort, catch) and re-generating

```

```{r BSS_summary, echo=FALSE}

# PLACEHOLDER - next steps 1.) incorporate/translate PE analysis script that is currently pasted in the file "DeleteMe - pe_model_summary_script.Rmd", 2.) wrap in 1 or more functions
```