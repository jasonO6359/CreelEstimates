---
title: "Freshater Creel Estimates"
date: "`r Sys.Date()`"
params:
  fishery_name: "Skagit fall salmon 2022"
  est_date_start: "2022-09-01"
  est_date_end: "2022-10-02"
  est_catch_groups: !r data.frame(rbind(
    c(species = 'Coho', life_stage = 'Adult', fin_mark = 'AD', fate = 'Kept'),
    c(species = 'Coho', life_stage = 'Adult', fin_mark = 'AD|UM|UNK|NA', fate = 'Kept'),
    c(species = 'Coho', life_stage = 'Adult', fin_mark = 'AD|UM|UNK|NA', fate = 'Released'),
    c(species = 'Coho', life_stage = 'Adult', fin_mark = 'AD|UM|UNK|NA', fate = 'Kept|Released'),
    c(species = 'Chinook', life_stage = 'Adult', fin_mark = 'UM|UNK|NA', fate = 'Kept'),
    c(species = 'Whitefish', life_stage = 'NA', fin_mark = 'AD|UM|UNK|NA', fate = 'Kept|Released|NA')
    ))
  person_count_type: "group"
  period_pe: "week"
  period_bss: "day"
  days_wkend: !r c('Saturday', 'Sunday')
  index_count_types: "Vehicle/Trailers Only"
  census_expansion: "Direct"
  min_fishing_time: 0.5
  dir_output: "model_output"
output:
  html_document:
    fig_caption: yes
    theme: default
    toc: yes
    toc_depth: 3
    toc_float: yes
    code_folding: hide
---

```{css, include=FALSE}
  .chart-shim {
    overflow: auto;
    }
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, fig.width = 10, fig.height = 8)

library("suncalc")
library("tidyverse")
library("patchwork")
library("gt")
theme_set(theme_light())

library("rstan")
rstan_options(auto_write = TRUE)

purrr::walk(list.files("R_functions/", full.names = T), source)

```

# `r paste(params$fishery_name)`

```{r}
gt(tibble(param = names(params), value = as.character(params)))
```

# Fetch raw data

```{r dwg_fetch, echo=FALSE}
dwg <- fetch_dwg(params$fishery_name)

# #!! TEMPORARY pending database table of same format...
# #!! will require extending fetch_dwg() when available
# #!! can reuse for other fishery existing _closure.csv files to add to main shared "closures.csv"
# lu_input$closures |> 
#   pivot_longer(names_to = "section", values_to = "open", cols =  -event_date) |> 
#   mutate(
#     fishery_name = params$fishery_name,
#     section = as.numeric(str_remove(section, "open_section_")),
#     closed = !open) |> 
#   filter(closed) |> 
#   select(fishery_name, section, event_date) |> 
#   arrange(event_date, section) |> 
#   write_csv("input_files/closures.csv")

# #to fix up Excel bunged date format
# read_csv("input_files/closures.csv", show_col_types = FALSE) |> 
#   mutate(event_date = as.Date(event_date, format = '%m/%d/%Y')) |> 
#   write_csv("input_files/closures.csv")


##!!if aggregating sections to coarser than provided by DWG
##!!can add function resection() or similar
##!!that takes a small LU tibble mapping 1,2,3,4... to 1,1,2,2... etc
##!!as a join+mututate or rows_update

dwg$days <- prep_days(
  date_begin = params$est_date_start, 
  date_end = params$est_date_end, 
  weekends = params$days_wkend,
  holidays = read_lines("input_files/dates_holidays_2015_2030.txt"),
  Lat = mean(dwg$ll$centroid_lat), #can/should consider smarter options
  Long = mean(dwg$ll$centroid_lon),#can/should consider smarter options 
  period_pe = params$period_pe,
  sections = unique(dwg$effort$section_num),
  closures = readr::read_csv("input_files/closures.csv", show_col_types = FALSE) |> 
    dplyr::filter(fishery_name == params$fishery_name)
  )
```

# Review fetched data

## Fishery sections

```{r table_sections}
dwg$effort |> 
  filter(location_type == "Section") |> 
  distinct(water_body, section_num, location) |> 
  arrange(section_num) |>
  select(`Water Body` = water_body, `Section Number` = section_num, `Location description` = location) |> 
  gt()
```

## Days

```{r gt_creel_days}
dwg$days |> 
  mutate(across(starts_with("open_"), ~if_else(., "open","closed"))) |> 
  rename_with(.cols = starts_with("open_"), .fn = ~str_remove_all(., "open_")) |> 
  gt::gt() |> 
  gt::data_color(
    columns = contains("section_"),
    colors = scales::col_factor(
      palette = c("#C3C7C3", "#78B574"),
      domain = c("closed","open")) 
  )
```

## Effort

```{r gt_creel_effort}
#NEEDS FINISHING
dwg$effort |> 
  distinct(section_num, location, event_date, tie_in_indicator, count_sequence) |> 
  count(section_num, location, tie_in_indicator)
  # mutate(tie_in_indicator = case_when(
  #   tie_in_indicator == 1 ~ "census",
  #   tie_in_indicator == 0 ~ "index"
  # )) |> 
  # pivot_wider(names_from = tie_in_indicator, values_from = n)
```

## Interview

```{r gt_creel_interview}
dwg$interview |> count(water_body, section_num, fishing_location) |> arrange(section_num) |> gt(caption = "Number of interviews by analysis section")
```

## Catch

```{r gt_creel_catch}
dwg$catch |> group_by(catch_group) |> summarise(fish_count = sum(fish_count), .groups = "drop") |> gt(caption = "Total reported encounters in interviews to date")
```

# Shared data aggregation

```{r prep_dwg_summ_shared_summary_objects, echo=FALSE}
dwg_summ <- list() #intermediate objects wrangled from creel list elements

#get count_type levels from interview to ensure alignment...?

#prep_interview() no longer excludes observations with NA vehicle_count/trailer_count
#requires handling during summarization for fisheries/records where these were not collected
dwg_summ$interview <- prep_dwg_interview(
  dwg_interview = dwg$interview |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))),
  dwg_catch = dwg$catch,
  person_count_type = params$person_count_type,
  min_fishing_time = params$min_fishing_time,
  est_catch_groups = params$est_catch_groups 
  )

#Aggregates census (tie in) effort counts, associating to closest-in-time index count
dwg_summ$effort_census <- prep_dwg_effort_census(
  eff = dwg$effort |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))))

#Aggregates index effort counts over locations within count_seq & section
dwg_summ$effort_index <- prep_dwg_effort_index(
  eff = dwg$effort |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))))
```

# PE estimation 

```{r prep_inputs_pe}
inputs_pe <- list()

#derive a table of potentially section-anglerType-specific values to modify census expansions
inputs_pe$census_expan <- prep_inputs_pe_census_expan(eff = dwg$effort, census_expansion = params$census_expansion)

# Calculate total days the fishery was open per strata (strata = period, DayType, and section_num)
inputs_pe$days_total <- prep_inputs_pe_days_total(days = dwg$days)

# depending on the types of index counts, reach the calc: ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * TI_expan_final
# when index counts are already bank & boat, matching census counts,
#   then angler_hour daily means are just effort index counts of anglers expanded by day length,
#   which are multiplied against tie-in expanded census counts of anglers by type (per section_num)
# but when index counts are trailers & vehicles,
#   then angler_hour daily means require first using interviews to estimate anglers_per_vhcl_trlr by angler_final total & boat 
#   so anglers_per_vhcl_trlr can be multiplied against the trailer & vehicle counts in effort_index, releveled to boat/total
#   and then TI-expanded counts similarly require splitting, re-leveling and rebinding census to boat/total to allow join with effort_index
#   and THEN generating a final object with total, boat and derived-bank, including dealing with case of only-bank (e.g., Cascade)
if(str_detect(params$index_count_types, "Bank|Boat")) {
  
  inputs_pe$ang_hrs_daily_mean <- prep_inputs_pe_ang_hrs_bank_boat(
    days = dwg$days, 
    dwg_summarized = dwg_summ,
    census_expan = inputs_pe$census_expan
    )
  
} else if(str_detect(params$index_count_types, "Vehicle|Trailer")) {
  
  #could skip retaining as list element and just pass as inline call in arg to next function
  inputs_pe$interview_ang_per_vhcl_trlr <- prep_inputs_pe_int_ang_per_vhcl_trlr(dwg_summarized = dwg_summ)
  
  inputs_pe$ang_hrs_daily_mean <- prep_inputs_pe_ang_hrs_vhcl_trlr(
    days = dwg$days, 
    dwg_summarized = dwg_summ,
    interview_ang_per_vehic = inputs_pe$interview_ang_per_vhcl_trlr,
    census_expan = inputs_pe$census_expan
    )
  
}

#aggregate interviews per day per strata of [week/month-weekend/day-section_num-bank/boat-est_cg]
#then multiply by TI-expanded effort estimate
#dropping any date-section_num-angler_final-catch_groups for which only interview-based CPUE is available
#but census-corrected effort estimates are not (various reasons why a day-section_num-angler_final hours could be NA)
inputs_pe$daily_cpue_catch_est <- prep_inputs_pe_daily_cpue_catch_est(
  days = dwg$days,
  dwg_summarized = dwg_summ,
  angler_hours_daily_mean = inputs_pe$ang_hrs_daily_mean
)

#THIS SEEMS WRONG/MISSING STRATA:  dplyr::group_by(section_num, angler_final)
inputs_pe$df <- prep_inputs_pe_df(
  days = dwg$days,
  angler_hours_daily_mean = inputs_pe$ang_hrs_daily_mean
)

```

```{r estimate_pe}
estimates_pe <- list() 

estimates_pe$effort <- est_pe_effort(
  days = dwg$days,
  pe_inputs_list = inputs_pe
)

estimates_pe$catch <- est_pe_catch(
  days = dwg$days,
  pe_inputs_list = inputs_pe
)
 

# Next steps - 3.) update "inputs_pe$census_expan" object -- currenlty not using the indirect census expansion values from database due to naming issue in database (i.e., direct_census_bank should be indirect_census_boat) and ability/use of pivot_wider function to handle column header prefixes.

```


# BSS estimation

```{r prep_inputs_bss, eval=FALSE}
#either a single element list for a single catch_group
#or a list of bss-input-lists, one for each catch_group
inputs_bss <- unique(dwg_summ$interview$est_cg)[2:3] |> 
  set_names() |> 
  map(
    ~prep_inputs_bss(
      est_catch_group = .x,
      period = params$period_bss,
      days = dwg$days,
      dwg_summarized = dwg_summ,
      #likely warrants revision? targeting n-gears-rows by n-sections-cols matrix of values
      tie_in_mat = dwg$effort |> 
        filter(tie_in_indicator == 1) |> 
        distinct(section_num, p_census_bank, p_census_boat) |> 
        pivot_longer(starts_with("p_census"), names_to = "ang", values_to = "val") |> 
        arrange(section_num) |> 
        pivot_wider(names_from = section_num, values_from = val) |> 
        select(-ang) |> 
        as.matrix(),
      priors = c(
        value_cauchyDF_sigma_eps_C = 0.5,
        value_cauchyDF_sigma_eps_E = 0.5,
        value_cauchyDF_sigma_r_E = 0.5,  
        value_cauchyDF_sigma_r_C = 0.5,  
        value_cauchyDF_sigma_mu_C = 0.5, 
        value_cauchyDF_sigma_mu_E = 0.5, 
        value_normal_sigma_omega_C_0 = 1,
        value_normal_sigma_omega_E_0 = 3,
        value_lognormal_sigma_b = 1,
        value_normal_sigma_B1 = 5,  
        value_normal_mu_mu_C = log(0.02),
        value_normal_sigma_mu_C = 1.5,  
        value_normal_mu_mu_E = log(5),
        value_normal_sigma_mu_E = 2,  
        value_betashape_phi_E_scaled = 1, 
        value_betashape_phi_C_scaled = 1 
      )
    )
  )

```

```{r estimate_bss, eval=FALSE}
#should work for either single or multiple catch_group 
estimates_bss <- list()

for(ecg in names(inputs_bss)) {
  gc(verbose = T)
  try(
    ecg_fit <- fit_bss(
      bss_inputs_list = inputs_bss[[ecg]],
      n_iter = 200
      )

    ecg_keep <- list()
    
    ecg_keep$overview <- get_bss_overview(
      bss_fit = ecg_fit, ecg = ecg
      )
    
    ecg_keep$catch_daily <- get_bss_catch_daily(
      bss_fit = ecg_fit, ecg = ecg
      )

    ecg_keep$effort_daily <- get_bss_effort_daily(
      bss_fit = ecg_fit, ecg = ecg
      )
    
    # #can write wrapper on tidybayes::spread_draws or write our own
    # #to repackage full posterior of key estimated quantities
    # #such as daily catch or something else?
    # ecg_keep$catch_daily_draws <- ecg_fit |> tidybayes::spread_draws(C[s][d,g]) #long, each index still a col 
    # ecg_keep$catch_daily_draws <- ecg_fit |> tidybayes::spread_draws(C[s][d,g] | g) #a bit wider, bank/boat pivoted wide 

    
    estimates_bss[[ecg]] <- ecg_keep
    #a little cleanup never hurts?
    rm(ecg_fit, ecg_keep); gc()
  )
}


```


# Results

```{r combo_overview}
#per-est_cg summary of total effort hours and catch/encounters


# #this first bit will change again when estimates_bss is already a list with the results of these calls...
# map_df(estimates_bss, ~.x$overview)

bind_rows(
  get_bss_overview(
    estimates_bss$`Coho_Adult_AD|UM|UNK|NA_Kept`,
    'Coho_Adult_AD|UM|UNK|NA_Kept')
  ,
  get_bss_overview(
    estimates_bss$`Coho_Adult_AD|UM|UNK|NA_Released`,
    'Coho_Adult_AD|UM|UNK|NA_Released')
) |> 

  left_join(
    bind_cols(
      estimates_pe$catch |> 
        group_by(est_cg) |>
        summarise(
          C_sum = sum(est),
          .groups = "drop"
        ),
      estimates_pe$effort |> 
        summarise(
          E_sum = sum(est, na.rm=T),
          .groups = "drop"
        )
    ) |> 
      pivot_longer(
        cols = -est_cg,
        names_to = "estimate",
        values_to = "PE"
      )
    ,
    by = c("estimate", "est_cg")
  ) |> 
  select(est_cg, estimate, PE, everything()) |> 
  gt(groupname_col = "est_cg") |>
  fmt_number(-c(estimate, est_cg), decimals = 1) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "PE")
  ) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "PE")
  )

  
##can delete whenever iterated select bss-fit elements done  
# get_bss_catch_daily(
#   estimates_bss$`Coho_Adult_AD|UM|UNK|NA_Kept`,
#   'Coho_Adult_AD|UM|UNK|NA_Kept')
# 
# get_bss_effort_daily(
#   estimates_bss$`Coho_Adult_AD|UM|UNK|NA_Kept`,
#   'Coho_Adult_AD|UM|UNK|NA_Kept')

```

