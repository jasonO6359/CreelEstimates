---
title: "Freshater Creel Estimates"
date: "`r Sys.Date()`"
params:
  fishery_name: "Skagit fall salmon 2022"
  est_date_start: "2022-09-01"
  est_date_end: "2022-10-02"
  est_catch_groups: !r data.frame(rbind(
    c(species = 'Coho', life_stage = 'Adult', fin_mark = 'AD', fate = 'Kept'),
    c(species = 'Coho', life_stage = 'Adult', fin_mark = 'AD|UM|UNK|NA', fate = 'Kept'),
    c(species = 'Coho', life_stage = 'Adult', fin_mark = 'AD|UM|UNK|NA', fate = 'Released'),
    c(species = 'Coho', life_stage = 'Adult', fin_mark = 'AD|UM|UNK|NA', fate = 'Kept|Released'),
    c(species = 'Chinook', life_stage = 'Adult', fin_mark = 'UM|UNK|NA', fate = 'Kept'),
    c(species = 'Whitefish', life_stage = 'NA', fin_mark = 'AD|UM|UNK|NA', fate = 'Kept|Released|NA')
    ))
  person_count_type: "group"
  period_pe: "week"
  period_bss: "day"
  analysis_name: "District 14_Skagit River,Cascade River_fall_salmon_2022"
  days_wkend: !r c('Saturday', 'Sunday')
  model_period: "Week"
  index_count_types: "Vehicle/Trailers Only"
  census_expansion: "Direct"
  min_fishing_time: 0.5
  dir_output: "model_output"
output:
  html_document:
    fig_caption: yes
    theme: default
    toc: yes
    toc_depth: 3
    toc_float: yes
    code_folding: hide
---


```{css, include=FALSE}
  .chart-shim {
    overflow: auto;
    }
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, fig.width = 10, fig.height = 8)

library("tidyverse")
library("patchwork")
library("gt")
theme_set(theme_light())

purrr::walk(list.files("R_functions/", full.names = T), source)

```

# `r paste(params$fishery_name)`

```{r}
gt(tibble(param = names(params), value = as.character(params)))
```

# Fetch data

```{r dwg_fetch, echo=FALSE}
dwg <- fetch_dwg(params$fishery_name)

# #!! TEMPORARY pending database table of same format...
# #!! will require extending fetch_dwg() when available
# #!! can reuse for other fishery existing _closure.csv files to add to main shared "closures.csv"
# lu_input$closures |> 
#   pivot_longer(names_to = "section", values_to = "open", cols =  -event_date) |> 
#   mutate(
#     fishery_name = params$fishery_name,
#     section = as.numeric(str_remove(section, "open_section_")),
#     closed = !open) |> 
#   filter(closed) |> 
#   select(fishery_name, section, event_date) |> 
#   arrange(event_date, section) |> 
#   write_csv("input_files/closures.csv")

# #to fix up Excel bunged date format
# read_csv("input_files/closures.csv", show_col_types = FALSE) |> 
#   mutate(event_date = as.Date(event_date, format = '%m/%d/%Y')) |> 
#   write_csv("input_files/closures.csv")

dwg$days <- prep_days(
  date_begin = params$est_date_start, #head(lu_input$closures$event_date, 1),
  date_end = params$est_date_end, #tail(lu_input$closures$event_date, 1),
  weekends = params$days_wkend,
  holidays = read_lines("input_files/dates_holidays_2015_2030.txt"), #lu_input$dates_holidays_2015_2030
  Lat = mean(dwg$ll$centroid_lat), #can/should consider smarter options
  Long = mean(dwg$ll$centroid_lon),#can/should consider smarter options 
  sections = unique(dwg$effort$section_num),
  closures = read_csv("input_files/closures.csv", show_col_types = FALSE) |> 
    filter(fishery_name == params$fishery_name)
  )

##LEAVING BROKEN (on time_strata dropped from prep_days() pending post-BSS stanlist completion)
# # excluding specified closures, total number of days by section, weekday/end, and time strata for which to generate estimates
# dwg$days_total <- dwg$days |>
#   pivot_longer(
#     cols = starts_with("open_section"), 
#     names_to = "section", 
#     values_to = "is_open") |>
#   filter(is_open) |> 
#   mutate(section = as.numeric(gsub("^.*_", "", section))) |>
#   count(time_strata, DayType, section, name = "N_days")

```

# Review data

## Fishery sections

```{r table_sections}
dwg$effort |> 
  filter(location_type == "Section") |> 
  distinct(water_body, section_num, location) |> 
  arrange(section_num) |>
  select(`Water Body` = water_body, `Section Number` = section_num, `Location description` = location) |> 
  gt()
```

## Days

```{r gt_creel_days}

# BROKEN - This is a summary table of creel days similar to dwg$days_total above (which is also broken)
# creel$days_total |> pivot_wider(names_from = c(section, DayType), values_from = N_days) |> gt(rowname_col = "time_strata", caption = "Potential days of fishing by time strata, section and day type")
```

## Effort

```{r gt_creel_effort}
#NEEDS FINISHING
dwg$effort |> 
  distinct(section_num, location, event_date, tie_in_indicator, count_sequence) |> 
  count(section_num, location, tie_in_indicator)
  # mutate(tie_in_indicator = case_when(
  #   tie_in_indicator == 1 ~ "census",
  #   tie_in_indicator == 0 ~ "index"
  # )) |> 
  # pivot_wider(names_from = tie_in_indicator, values_from = n)
```

## Interview

```{r gt_creel_interview}
dwg$interview |> count(water_body, section_num, fishing_location) |> arrange(section_num) |> gt(caption = "Number of interviews by analysis section")
```

## Catch

```{r gt_creel_catch}
dwg$catch |> group_by(catch_group) |> summarise(fish_count = sum(fish_count), .groups = "drop") |> gt(caption = "Total reported encounters in interviews to date")
```

# Summarized observations

```{r summarized_intermediates, echo=FALSE}
dwg_summ <- list() #intermediate objects wrangled from creel list elements

#get count_type levels from interview to ensure alignment...?

#prep_interview() no longer excludes observations with NA vehicle_count/trailer_count
#requires handling during summarization for fisheries/records where these were not collected
dwg_summ$interview <- prep_interview(
  dwg_interview = dwg$interview |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))),
  dwg_catch = dwg$catch,
  person_count_type = params$person_count_type,
  min_fishing_time = params$min_fishing_time,
  est_catch_groups = params$est_catch_groups 
  )

#Aggregates census (tie in) effort counts, associating to closest-in-time index count
dwg_summ$effort_census <- prep_effort_census(
  eff = dwg$effort |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))))

#Aggregates index effort counts over locations within count_seq & section
dwg_summ$effort_index <- prep_effort_index(
  eff = dwg$effort |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))))

#could pass single dwg_summ list rather than separate interview & effort_index & effort_census objects
#pretty simple to revise if desired...
#but would also probably want to pass est_catch_group argument to filter interview within function
#since function wants single catch_group, non-duplicated slice interview object
#similarly, could pass list of priors while including current values as default argument value
dwg_summ$stan_list <- prep_stan_list(
  period = params$period_bss,
  days = dwg$days,
  interview_cg = dwg_summ$interview |> 
    filter(est_cg == unique(dwg_summ$interview$est_cg)[1]),
  effort_census = dwg_summ$effort_census,
  effort_index = dwg_summ$effort_index,
  #likely warrants revision? targeting n-gears-rows by n-sections-cols matrix of values
  tie_in_mat = dwg$effort |> 
    filter(tie_in_indicator == 1) |> 
    distinct(section_num, p_census_bank, p_census_boat) |> 
    pivot_longer(starts_with("p_census"), names_to = "ang", values_to = "val") |> 
    arrange(section_num) |> 
    pivot_wider(names_from = section_num, values_from = val) |> 
    select(-ang) |> 
    as.matrix()
)

# BELOW IS ALTERNATIVE VERSION OF dwg_summ$stan_list ABOVE THAT COULD ACCOMMADATE >1 CATCH GROUPS TO ITERATE THROUGH VIA BSS ANALYSIS
# #this whole declaration can be mapped into a list of stan_lists per est_catch_group
# #and the encompassing list can then be iterated over...perhaps eventually in parallel?
# #but might be nicer to revise arguments a bit? only thing changing in this demo is the slice of interview rows... 
# dwg_summ$stan_list <- map(
#   set_names(unique(dwg_summ$interview$est_cg))[1:2]
#   ,
#   ~prep_stan_list(
#     period = params$period_bss,
#     days = dwg$days,
#     interview_cg = dwg_summ$interview |> filter(est_cg == .x),
#     effort_census = dwg_summ$effort_census,
#     effort_index = dwg_summ$effort_index,
#     tie_in_mat = dwg$effort |> 
#       filter(tie_in_indicator == 1) |> 
#       distinct(section_num, p_census_bank, p_census_boat) |> 
#       pivot_longer(starts_with("p_census"), names_to = "ang", values_to = "val") |> 
#       arrange(section_num) |> 
#       pivot_wider(names_from = section_num, values_from = val) |> 
#       select(-ang) |> 
#       as.matrix()
#   )
# )
```

# Run BSS model
```{r BSS_analysis, echo=FALSE}

# PLACEHOLDER - next steps: 1.) paste in code from "CreelAnalysis_dwg_1.1.Rmd" that runs BSS in stan (e.g., feeds in stan_dat along with priors, specifics model arguments, etc.) and 2.) create model input summaries (writing the stan_dat object, creating .txt of model arguments), 3.) wrap in a function

```

# Summarize BSS model output
```{r BSS_summary, echo=FALSE}

# PLACEHOLDER - next steps 1.) save model output, save model warnings (divergent transition...), model run time, and very basic summary table (e.g., catch & effort by section, angler, and total), 2.) revisiting model diagnostics (posterior distribution plots, key parameters, shinystan), 3.) revisiting more detailed summaries (e.g., daily plots of CPUE, effort, catch) and re-generating

```

# Run PE analysis 
```{r PE_analysis, echo=FALSE}

#Note PE will require coercing from count_type to angler_final...incomplete version:
dwg_summ$effort_index |>
    dplyr::mutate(
      angler_final = word(count_type, 1) |> tolower()
      # angler_final = dplyr::case_when(
      #   count_type == "Boat Anglers" ~ "boat",
      #   count_type == "Bank Anglers" ~ "bank",
      #   count_type == "Trailers Only" ~ "boat",
      #   count_type == "Vehicle Only" ~ "total"
      # )
    ) 
```
